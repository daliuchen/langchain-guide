{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# RAG 一些相关问题\n",
    "\n",
    "\n",
    "## RAG返回source\n",
    "返回本次回答引用了哪些文档。\n",
    "\n",
    "`通过create_retrieval_chain`来做，代码如下"
   ],
   "id": "3094ebb661febfb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T15:36:55.751601Z",
     "start_time": "2024-07-30T15:36:47.157839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import bs4\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.globals import set_debug\n",
    "set_debug(True)\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "# 1. Load, chunk and index the contents of the blog to create a retriever.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://guangzhengli.com/blog/zh/vector-database/\",),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 2. Incorporate the retriever into a question-answering chain.\n",
    "system_prompt = (\n",
    "    \"你是一个ai助手，回答用户的问题\"\n",
    "    \"使用下面的上下文来回答\"\n",
    "    \"如果你不知道，要回答我不知道\"\n",
    "    \"使用简短精炼的语句表单，最多三句话\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\" # 这里content的位置就是从向量数据库中找到数据之后，塞到Prompt的位置，\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ],
   "id": "f141da42984a440c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:03:13.379348Z",
     "start_time": "2024-07-29T15:03:13.371489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(rag_chain.get_prompts()[0].pretty_print())\n",
    "print(rag_chain.get_prompts()[1].pretty_print())"
   ],
   "id": "b48707afae6c48f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33;1m\u001B[1;3m{page_content}\u001B[0m\n",
      "None\n",
      "================================\u001B[1m System Message \u001B[0m================================\n",
      "\n",
      "你是一个ai助手，回答用户的问题使用下面的上下文来回答如果你不知道，要回答我不知道使用简短精炼的语句表单，最多三句话\n",
      "\n",
      "\u001B[33;1m\u001B[1;3m{context}\u001B[0m\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "\u001B[33;1m\u001B[1;3m{input}\u001B[0m\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:44:54.825684Z",
     "start_time": "2024-07-29T15:44:52.665411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = rag_chain.invoke({\"input\": \"向量数据库的优点是什么？\"})\n",
    "print(result)"
   ],
   "id": "881637120737ace6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:retrieval_chain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库的优点是什么？\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<context>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库的优点是什么？\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库的优点是什么？\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库的优点是什么？\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库的优点是什么？\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"向量数据库的优点是什么？\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents] [613ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context>] [616ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<context>] [619ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<answer>] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer>] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > chain:format_inputs] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > chain:format_inputs > chain:RunnableParallel<context>] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > chain:format_inputs > chain:RunnableParallel<context> > chain:format_docs] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > chain:format_inputs > chain:RunnableParallel<context> > chain:format_docs] [2ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"向量数据库\\n\\n\\n\\n主页\\n\\n向量数据库\\n\\n\\n\\n主页\\n\\n向量数据库\\n\\n\\n\\n主页\\n\\n向量数据库\\n\\n\\n\\n主页\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > chain:format_inputs > chain:RunnableParallel<context>] [4ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"context\": \"向量数据库\\n\\n\\n\\n主页\\n\\n向量数据库\\n\\n\\n\\n主页\\n\\n向量数据库\\n\\n\\n\\n主页\\n\\n向量数据库\\n\\n\\n\\n主页\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > chain:format_inputs] [7ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库的优点是什么？\",\n",
      "  \"context\": \"向量数据库\\n\\n\\n\\n主页\\n\\n向量数据库\\n\\n\\n\\n主页\\n\\n向量数据库\\n\\n\\n\\n主页\\n\\n向量数据库\\n\\n\\n\\n主页\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库的优点是什么？\",\n",
      "  \"context\": \"向量数据库\\n\\n\\n\\n主页\\n\\n向量数据库\\n\\n\\n\\n主页\\n\\n向量数据库\\n\\n\\n\\n主页\\n\\n向量数据库\\n\\n\\n\\n主页\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > prompt:ChatPromptTemplate] [3ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: 你是一个ai助手，回答用户的问题使用下面的上下文来回答如果你不知道，要回答我不知道使用简短精炼的语句表单，最多三句话\\n\\n向量数据库\\n\\n\\n\\n主页\\n\\n向量数据库\\n\\n\\n\\n主页\\n\\n向量数据库\\n\\n\\n\\n主页\\n\\n向量数据库\\n\\n\\n\\n主页\\nHuman: 向量数据库的优点是什么？\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > llm:ChatOpenAI] [1.48s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"向量数据库的优点包括高效的相似度搜索、支持高维数据的存储和查询、适用于大规模数据集等特点。\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"向量数据库的优点包括高效的相似度搜索、支持高维数据的存储和查询、适用于大规模数据集等特点。\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 44,\n",
      "                \"prompt_tokens\": 112,\n",
      "                \"total_tokens\": 156\n",
      "              },\n",
      "              \"model_name\": \"gpt-35-turbo\",\n",
      "              \"system_fingerprint\": \"fp_811936bd4f\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-742e3bbb-dbae-442b-8830-6f7a599b289d-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 112,\n",
      "              \"output_tokens\": 44,\n",
      "              \"total_tokens\": 156\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 44,\n",
      "      \"prompt_tokens\": 112,\n",
      "      \"total_tokens\": 156\n",
      "    },\n",
      "    \"model_name\": \"gpt-35-turbo\",\n",
      "    \"system_fingerprint\": \"fp_811936bd4f\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"向量数据库的优点包括高效的相似度搜索、支持高维数据的存储和查询、适用于大规模数据集等特点。\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain] [1.50s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"向量数据库的优点包括高效的相似度搜索、支持高维数据的存储和查询、适用于大规模数据集等特点。\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer>] [1.51s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"answer\": \"向量数据库的优点包括高效的相似度搜索、支持高维数据的存储和查询、适用于大规模数据集等特点。\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:retrieval_chain > chain:RunnableAssign<answer>] [1.51s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:retrieval_chain] [2.14s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "{'input': '向量数据库的优点是什么？', 'context': [Document(page_content='向量数据库\\n\\n\\n\\n主页', metadata={'description': 'Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。', 'language': 'zh', 'source': 'https://guangzhengli.com/blog/zh/vector-database/', 'title': '向量数据库'}), Document(page_content='向量数据库\\n\\n\\n\\n主页', metadata={'description': 'Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。', 'language': 'zh', 'source': 'https://guangzhengli.com/blog/zh/vector-database/', 'title': '向量数据库'}), Document(page_content='向量数据库\\n\\n\\n\\n主页', metadata={'description': 'Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。', 'language': 'zh', 'source': 'https://guangzhengli.com/blog/zh/vector-database/', 'title': '向量数据库'}), Document(page_content='向量数据库\\n\\n\\n\\n主页', metadata={'description': 'Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。', 'language': 'zh', 'source': 'https://guangzhengli.com/blog/zh/vector-database/', 'title': '向量数据库'})], 'answer': '向量数据库的优点包括高效的相似度搜索、支持高维数据的存储和查询、适用于大规模数据集等特点。'}\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:45:01.633312Z",
     "start_time": "2024-07-29T15:45:01.629348Z"
    }
   },
   "cell_type": "code",
   "source": "result[\"context\"][0]",
   "id": "35066abfdc024385",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='向量数据库\\n\\n\\n\\n主页', metadata={'description': 'Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。', 'language': 'zh', 'source': 'https://guangzhengli.com/blog/zh/vector-database/', 'title': '向量数据库'})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "如上所述。在返回值中，会返回完整的引用的document的切片",
   "id": "a8960d25f79acf0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 返回引用\n",
    "官网文档：\n",
    "https://python.langchain.com/v0.2/docs/how_to/qa_citations/\n",
    "\n",
    "在这里我演示前面两种方式\n",
    "1. 使用工具调用来引用文档 ID；\n",
    "2. 使用工具调用来引用文档 ID 并提供文本片段；"
   ],
   "id": "85d13d0fb8496080"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:46:42.216637Z",
     "start_time": "2024-07-29T15:46:42.209817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 在上面的例子中已经返回了这次回答所涉及的所有的文档内容，都是放在`context`中，在下面的两个例子中，会以这个例子为基础来做。\n",
    "result[\"context\"][0]"
   ],
   "id": "c736800e0fde4cbf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='向量数据库\\n\\n\\n\\n主页', metadata={'description': 'Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。', 'language': 'zh', 'source': 'https://guangzhengli.com/blog/zh/vector-database/', 'title': '向量数据库'})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 使用工具调用来引用文档\n",
    "\n",
    "原理：首先先给文档编号，指定文档id，通过模型支持的函数调用来实现,`with_structured_output`"
   ],
   "id": "3a39e9a0efec7ee4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:56:24.975130Z",
     "start_time": "2024-07-29T15:56:24.967132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# 规定模型调用的工具，之前说过，对于`with_structured_output`的实现也是通过`bind_tools`来实现的\n",
    "\n",
    "class CitedAnswer(BaseModel):\n",
    "    \"\"\"根据提供的来源回答用户问题，并引用所使用的来源。\"\"\"\n",
    "    answer: str = Field(\n",
    "        ...,\n",
    "        description=\"根据提供的来源，回答用户的问题。\",\n",
    "    )\n",
    "    citations: List[int] = Field(\n",
    "        ...,\n",
    "        description=\"回答这个问题所引用的文档id\",\n",
    "    )\n",
    "    "
   ],
   "id": "33f8d8726e06165c",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "下面是一个简单的原理说明demo，之后会将找到的document格式化为下面的样子，代入到promot中处理",
   "id": "118d577cd5b20872"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:57:20.644140Z",
     "start_time": "2024-07-29T15:57:18.780545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "structured_llm = llm.with_structured_output(CitedAnswer)\n",
    "\n",
    "example_q = \"\"\"What Brian's height?\n",
    "\n",
    "Source: 1\n",
    "Information: Suzy is 6'2\"\n",
    "\n",
    "Source: 2\n",
    "Information: Jeremiah is blonde\n",
    "\n",
    "Source: 3\n",
    "Information: Brian is 3 inches shorter than Suzy\"\"\"\n",
    "result = structured_llm.invoke(example_q)\n",
    "\n",
    "result"
   ],
   "id": "23a60d10d22d1361",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"What Brian's height?\\n\\nSource: 1\\nInformation: Suzy is 6'2\\\"\\n\\nSource: 2\\nInformation: Jeremiah is blonde\\n\\nSource: 3\\nInformation: Brian is 3 inches shorter than Suzy\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What Brian's height?\\n\\nSource: 1\\nInformation: Suzy is 6'2\\\"\\n\\nSource: 2\\nInformation: Jeremiah is blonde\\n\\nSource: 3\\nInformation: Brian is 3 inches shorter than Suzy\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:RunnableSequence > llm:ChatOpenAI] [1.84s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"tool_calls\": [\n",
      "                {\n",
      "                  \"id\": \"call_Ie6uBnlIKSQwoJAx9tsgjowW\",\n",
      "                  \"function\": {\n",
      "                    \"arguments\": \"{\\\"answer\\\":\\\"Brian is 6'2\\\\\\\" - 3 inches = 5'11\\\\\\\"\\\",\\\"citations\\\":[1,3]}\",\n",
      "                    \"name\": \"CitedAnswer\"\n",
      "                  },\n",
      "                  \"type\": \"function\"\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 28,\n",
      "                \"prompt_tokens\": 155,\n",
      "                \"total_tokens\": 183\n",
      "              },\n",
      "              \"model_name\": \"gpt-35-turbo\",\n",
      "              \"system_fingerprint\": \"fp_811936bd4f\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-6c9f0940-8e95-42d6-8874-b2d3878b781f-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"CitedAnswer\",\n",
      "                \"args\": {\n",
      "                  \"answer\": \"Brian is 6'2\\\" - 3 inches = 5'11\\\"\",\n",
      "                  \"citations\": [\n",
      "                    1,\n",
      "                    3\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"call_Ie6uBnlIKSQwoJAx9tsgjowW\"\n",
      "              }\n",
      "            ],\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 155,\n",
      "              \"output_tokens\": 28,\n",
      "              \"total_tokens\": 183\n",
      "            },\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 28,\n",
      "      \"prompt_tokens\": 155,\n",
      "      \"total_tokens\": 183\n",
      "    },\n",
      "    \"model_name\": \"gpt-35-turbo\",\n",
      "    \"system_fingerprint\": \"fp_811936bd4f\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > parser:PydanticToolsParser] [1ms] Exiting Parser run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence] [1.85s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CitedAnswer(answer='Brian is 6\\'2\" - 3 inches = 5\\'11\"', citations=[1, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:03:33.309561Z",
     "start_time": "2024-07-29T16:03:33.303838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "\n",
    "# 有了上面的demo，这里对文档做编号，实现和上面一样的效果\n",
    "\n",
    "def format_docs_with_id(docs: List[Document]) -> str:\n",
    "    \"\"\"这个函数是格式化输入文档，create_stuff_document 方法里面的实现和这个一样\"\"\"\n",
    "    formatted = [\n",
    "        f\"Source ID: {i}\\nArticle Title: {doc.metadata['title']}\\nArticle Snippet: {doc.page_content}\"\n",
    "        for i, doc in enumerate(docs)\n",
    "    ]\n",
    "    return \"\\n\\n\" + \"\\n\\n\".join(formatted)\n",
    "\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs_with_id(x[\"context\"])))\n",
    "    | prompt\n",
    "    | structured_llm\n",
    ")\n",
    "\n",
    "retrieve_docs = (lambda x: x[\"input\"]) | retriever\n",
    "\n",
    "chain = RunnablePassthrough.assign(context=retrieve_docs).assign(\n",
    "    answer=rag_chain_from_docs\n",
    ")"
   ],
   "id": "44d4a0ed9754478e",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:03:52.352882Z",
     "start_time": "2024-07-29T16:03:48.410123Z"
    }
   },
   "cell_type": "code",
   "source": "result = chain.invoke({\"input\": \"向量数据库的优点是什么？\"})",
   "id": "1a1f37761e3fa744",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库的优点是什么？\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<context>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库的优点是什么？\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库的优点是什么？\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库的优点是什么？\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库的优点是什么？\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"向量数据库的优点是什么？\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence] [1.56s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context>] [1.56s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<context>] [1.56s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<answer>] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<answer> > chain:RunnableParallel<answer>] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:RunnableSequence > chain:RunnableAssign<context>] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context>] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"\\n\\nSource ID: 0\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\\n\\nSource ID: 1\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\\n\\nSource ID: 2\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\\n\\nSource ID: 3\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context>] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"context\": \"\\n\\nSource ID: 0\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\\n\\nSource ID: 1\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\\n\\nSource ID: 2\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\\n\\nSource ID: 3\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:RunnableSequence > chain:RunnableAssign<context>] [3ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库的优点是什么？\",\n",
      "  \"context\": \"\\n\\nSource ID: 0\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\\n\\nSource ID: 1\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\\n\\nSource ID: 2\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\\n\\nSource ID: 3\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库的优点是什么？\",\n",
      "  \"context\": \"\\n\\nSource ID: 0\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\\n\\nSource ID: 1\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\\n\\nSource ID: 2\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\\n\\nSource ID: 3\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: 你是一个ai助手，回答用户的问题使用下面的上下文来回答如果你不知道，要回答我不知道使用简短精炼的语句表单，最多三句话\\n\\n\\n\\nSource ID: 0\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\\n\\nSource ID: 1\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\\n\\nSource ID: 2\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\\n\\nSource ID: 3\\nArticle Title: 向量数据库\\nArticle Snippet: 向量数据库\\n\\n\\n\\n主页\\nHuman: 向量数据库的优点是什么？\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:RunnableSequence > llm:ChatOpenAI] [2.33s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"tool_calls\": [\n",
      "                {\n",
      "                  \"id\": \"call_yQrLSlLUfQ2h2qdekfRr68Vm\",\n",
      "                  \"function\": {\n",
      "                    \"arguments\": \"{\\\"answer\\\":\\\"向量数据库具有高效的相似度搜索能力，适用于海量数据的快速查询和分析。\\\",\\\"citations\\\":[0,1,2,3]}\",\n",
      "                    \"name\": \"CitedAnswer\"\n",
      "                  },\n",
      "                  \"type\": \"function\"\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 47,\n",
      "                \"prompt_tokens\": 286,\n",
      "                \"total_tokens\": 333\n",
      "              },\n",
      "              \"model_name\": \"gpt-35-turbo\",\n",
      "              \"system_fingerprint\": \"fp_811936bd4f\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-5f5220ed-23f0-464f-90ba-6e4059ad412e-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"CitedAnswer\",\n",
      "                \"args\": {\n",
      "                  \"answer\": \"向量数据库具有高效的相似度搜索能力，适用于海量数据的快速查询和分析。\",\n",
      "                  \"citations\": [\n",
      "                    0,\n",
      "                    1,\n",
      "                    2,\n",
      "                    3\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"call_yQrLSlLUfQ2h2qdekfRr68Vm\"\n",
      "              }\n",
      "            ],\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 286,\n",
      "              \"output_tokens\": 47,\n",
      "              \"total_tokens\": 333\n",
      "            },\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 47,\n",
      "      \"prompt_tokens\": 286,\n",
      "      \"total_tokens\": 333\n",
      "    },\n",
      "    \"model_name\": \"gpt-35-turbo\",\n",
      "    \"system_fingerprint\": \"fp_811936bd4f\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:RunnableSequence > parser:PydanticToolsParser] [2ms] Exiting Parser run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:RunnableSequence] [2.34s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<answer> > chain:RunnableParallel<answer>] [2.35s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<answer>] [2.35s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence] [3.92s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:04:16.797227Z",
     "start_time": "2024-07-29T16:04:16.791762Z"
    }
   },
   "cell_type": "code",
   "source": "print(result[\"answer\"])",
   "id": "eed15cb9de17464e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer='向量数据库具有高效的相似度搜索能力，适用于海量数据的快速查询和分析。' citations=[0, 1, 2, 3]\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "如上所述，返回了本次回答所引用的文档。。\n",
    "这个例子对引用文档的id这个功能体现的不太明显，因为retriever是在向量数据库中找的，向量数据库只是返回了文章的片段。\n",
    "但是如果retrieve是一个`WikipediaRetriever`的呢？对一个问题可能会搜索出不同的答案，这个时候document就不是一个片段，而是一整个文章，这个时候就体现出来了（本次回答引用了哪些文章）\n",
    "\n",
    "比如豆包的在线搜索\n",
    "![](../resource/img_17.png)"
   ],
   "id": "d8492c212ce8d912"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 返回引用的原文\n",
    "\n",
    "和上面实现的原理一致，这里让返回的结构更加的复杂了一下，增加了`quote`字段来返回引用的原文。\n",
    "\n",
    "一般在经过chunk之后，文本已经变得小了，这里让模型直接返回文本会让结果变得更加的清晰。（ps：这里我觉得只是存在chunk的情况下，否则文本过大，也会增加token的消耗。）\n"
   ],
   "id": "54b16ebbab661e7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T15:37:23.307110Z",
     "start_time": "2024-07-30T15:37:23.304094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "class Citation(BaseModel):\n",
    "    \n",
    "    source_id: int = Field(\n",
    "        description=\"回答这个问题所引用的文档id\",\n",
    "    )\n",
    "    quote: str = Field(\n",
    "        description=\"从指定来源中引用的原文，证明答案的正确性。\",\n",
    "    )\n",
    "\n",
    "\n",
    "class QuotedAnswer(BaseModel):\n",
    "    \"\"\"根据提供的来源回答用户问题，并引用所使用的来源。\"\"\"\n",
    "\n",
    "    answer: str = Field(\n",
    "        description=\"根据提供的来源，回答用户的问题。\",\n",
    "    )\n",
    "    citations: List[Citation] = Field( description=\"从提供的来源中引用支持答案的内容。\"\n",
    "    )"
   ],
   "id": "8d54bab2d133f312",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T15:37:28.485176Z",
     "start_time": "2024-07-30T15:37:26.365599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "structured_llm = llm.with_structured_output(QuotedAnswer)\n",
    "\n",
    "example_q = \"\"\"What Brian's height?\n",
    "\n",
    "Source: 1\n",
    "Information: Suzy is 6'2\"\n",
    "\n",
    "Source: 2\n",
    "Information: Jeremiah is blonde\n",
    "\n",
    "Source: 3\n",
    "Information: Brian is 3 inches shorter than Suzy\"\"\"\n",
    "result = structured_llm.invoke(example_q)\n",
    "\n",
    "result"
   ],
   "id": "aa84db06d5258d73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"What Brian's height?\\n\\nSource: 1\\nInformation: Suzy is 6'2\\\"\\n\\nSource: 2\\nInformation: Jeremiah is blonde\\n\\nSource: 3\\nInformation: Brian is 3 inches shorter than Suzy\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What Brian's height?\\n\\nSource: 1\\nInformation: Suzy is 6'2\\\"\\n\\nSource: 2\\nInformation: Jeremiah is blonde\\n\\nSource: 3\\nInformation: Brian is 3 inches shorter than Suzy\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:RunnableSequence > llm:ChatOpenAI] [2.08s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"tool_calls\": [\n",
      "                {\n",
      "                  \"id\": \"call_kbWvfqseqY0RlY9iSObVPXjp\",\n",
      "                  \"function\": {\n",
      "                    \"arguments\": \"{\\\"answer\\\":\\\"Brian's height is 5'11\\\\\\\"\\\",\\\"citations\\\":[{\\\"source_id\\\":1,\\\"quote\\\":\\\"Suzy is 6'2\\\\\\\"\\\"},{\\\"source_id\\\":3,\\\"quote\\\":\\\"Brian is 3 inches shorter than Suzy\\\"}]}\",\n",
      "                    \"name\": \"QuotedAnswer\"\n",
      "                  },\n",
      "                  \"type\": \"function\"\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 50,\n",
      "                \"prompt_tokens\": 207,\n",
      "                \"total_tokens\": 257\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-368be01b-c80c-4f41-85ee-d7d67723f3fe-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"QuotedAnswer\",\n",
      "                \"args\": {\n",
      "                  \"answer\": \"Brian's height is 5'11\\\"\",\n",
      "                  \"citations\": [\n",
      "                    {\n",
      "                      \"source_id\": 1,\n",
      "                      \"quote\": \"Suzy is 6'2\\\"\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_id\": 3,\n",
      "                      \"quote\": \"Brian is 3 inches shorter than Suzy\"\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"call_kbWvfqseqY0RlY9iSObVPXjp\"\n",
      "              }\n",
      "            ],\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 207,\n",
      "              \"output_tokens\": 50,\n",
      "              \"total_tokens\": 257\n",
      "            },\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 50,\n",
      "      \"prompt_tokens\": 207,\n",
      "      \"total_tokens\": 257\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > parser:PydanticToolsParser] [1ms] Exiting Parser run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence] [2.10s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuotedAnswer(answer='Brian\\'s height is 5\\'11\"', citations=[Citation(source_id=1, quote='Suzy is 6\\'2\"'), Citation(source_id=3, quote='Brian is 3 inches shorter than Suzy')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "按照既定要求，模型返回的数据中已经包含了原文。同样的，也可以将上面的代码修改成这个样子。",
   "id": "152d957cc670b4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 在retriever的时候如何做用户的隔离\n",
    "\n",
    "LangChain有很多的retriever，LangChain并没有封装这样的能力，隔离的底层实现还得是各个retriever的能力。\n",
    "官网：https://python.langchain.com/v0.2/docs/how_to/qa_per_user/\n",
    "\n",
    "下面的demo中处理一个场景，不同的用户有不同的知识库。"
   ],
   "id": "d1d3c87fc597036e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T16:11:24.896816Z",
     "start_time": "2024-07-30T16:11:20.533595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import bs4\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.globals import set_debug\n",
    "set_debug(True)\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "# 1. Load, chunk and index the contents of the blog to create a retriever.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://guangzhengli.com/blog/zh/vector-database/\",),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(),collection_name=\"userA\")\n",
    "retrieverA = vectorstore.as_retriever()"
   ],
   "id": "40b916ebbdd5996",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T16:11:31.405501Z",
     "start_time": "2024-07-30T16:11:24.898315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 用户B 加载的是 https://daliuchen.github.io/langchain-guide/content/section_10.html\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://daliuchen.github.io/langchain-guide/content/section_10.html\",),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(),collection_name=\"userB\")\n",
    "retrieverB = vectorstore.as_retriever()\n",
    "retrieverB.invoke(\"chat History是什么？\")"
   ],
   "id": "379834ebbfa380e9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='{\\n  \"input\": \"向量数据库是什么\",\\n  \"chat_history\": []\\n}\\n[chain/start] [chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableLambda] Entering Chain run with input:\\n{\\n  \"input\": \"向量数据库是什么\",\\n  \"chat_history\": []\\n}\\n[chain/end] [chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableLambda] [0ms] Exiting Chain run with output:\\n{\\n  \"output\": true\\n}\\n[chain/start] [chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableSequence] Entering Chain run with input:\\n{\\n  \"input\": \"向量数据库是什么\",\\n  \"chat_history\": []\\n}', metadata={'language': 'en', 'source': 'https://daliuchen.github.io/langchain-guide/content/section_10.html', 'title': 'QA With RAG — langchan study guide'}),\n",
       " Document(page_content='{\\n  \"input\": \"向量数据库是什么\",\\n  \"chat_history\": []\\n}\\n[chain/start] [chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableLambda] Entering Chain run with input:\\n{\\n  \"input\": \"向量数据库是什么\",\\n  \"chat_history\": []\\n}\\n[chain/end] [chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableLambda] [0ms] Exiting Chain run with output:\\n{\\n  \"output\": true\\n}\\n[chain/start] [chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableSequence] Entering Chain run with input:\\n{\\n  \"input\": \"向量数据库是什么\",\\n  \"chat_history\": []\\n}', metadata={'language': 'en', 'source': 'https://daliuchen.github.io/langchain-guide/content/section_10.html', 'title': 'QA With RAG — langchan study guide'}),\n",
       " Document(page_content='}\\n[chain/start] [chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > prompt:ChatPromptTemplate] Entering Prompt run with input:\\n{\\n  \"input\": \"向量数据库是什么\",\\n  \"chat_history\": [],', metadata={'language': 'en', 'source': 'https://daliuchen.github.io/langchain-guide/content/section_10.html', 'title': 'QA With RAG — langchan study guide'}),\n",
       " Document(page_content='}\\n[chain/start] [chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > prompt:ChatPromptTemplate] Entering Prompt run with input:\\n{\\n  \"input\": \"向量数据库是什么\",\\n  \"chat_history\": [],', metadata={'language': 'en', 'source': 'https://daliuchen.github.io/langchain-guide/content/section_10.html', 'title': 'QA With RAG — langchan study guide'})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T16:11:38.977596Z",
     "start_time": "2024-07-30T16:11:36.400735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(retrieverA.invoke(\"向量数据库的特点是什么？\"))\n",
    "print(retrieverB.invoke(\"chat History是什么？\"))"
   ],
   "id": "401b699391c59f5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='向量数据库\\n\\n\\n\\n主页', metadata={'description': 'Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。', 'language': 'zh', 'source': 'https://guangzhengli.com/blog/zh/vector-database/', 'title': '向量数据库'}), Document(page_content='向量数据库\\n\\n\\n\\n主页', metadata={'description': 'Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。', 'language': 'zh', 'source': 'https://guangzhengli.com/blog/zh/vector-database/', 'title': '向量数据库'}), Document(page_content='& SDK对比上面的因素选择，API & SDK 可能是往往被忽略的因素，但是在实际的业务场景中，API & SDK 往往是开发者最关心的因素。因为 API & SDK 的设计直接影响了开发者的开发效率和使用体验。一个优秀良好的 API & SDK 设计，往往能够适应需求的不同变化，向量数据库是一个新的领域，在如今大部分人不太清楚这方面需求的当下，这一点容易被人忽视。选型截至目前，汇总到目前的向量数据库有以下几种选择：向量数据库URLGitHub StarLanguageCloudchromahttps://github.com/chroma-core/chroma7.4KPython❌milvushttps://github.com/milvus-io/milvus21.5KGo/Python/C++✅pineconehttps://www.pinecone.io/❌❌✅qdranthttps://github.com/qdrant/qdrant11.8KRust✅typesensehttps://github.com/typesense/typesense12.9KC++❌weaviatehttps://github.com/weaviate/weaviate6.9KGo✅传统数据的扩展除了选择专业的向量数据库，使用传统数据库进行扩展也是一种方法。类似 Redis 除了传统的 Key Value 数据库用途外，Redis 还提供了 Redis Modules，这是一种通过新功能、命令和数据类型扩展 Redis 的方式。例如使用 RediSearch 模块来扩展向量搜索的功能。同理的还有 PostgreSQL 的扩展，PostgreSQL 提供使用 extension 的方式来扩展数据库的功能，例如 pgvector 来开启向量搜索的功能。它不仅支持精确和相似性搜索，还支持余弦相似度等相似性测量算法。最重要的是，它是附加在 PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub', metadata={'description': 'Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。', 'language': 'zh', 'source': 'https://guangzhengli.com/blog/zh/vector-database/', 'title': '向量数据库'}), Document(page_content='& SDK对比上面的因素选择，API & SDK 可能是往往被忽略的因素，但是在实际的业务场景中，API & SDK 往往是开发者最关心的因素。因为 API & SDK 的设计直接影响了开发者的开发效率和使用体验。一个优秀良好的 API & SDK 设计，往往能够适应需求的不同变化，向量数据库是一个新的领域，在如今大部分人不太清楚这方面需求的当下，这一点容易被人忽视。选型截至目前，汇总到目前的向量数据库有以下几种选择：向量数据库URLGitHub StarLanguageCloudchromahttps://github.com/chroma-core/chroma7.4KPython❌milvushttps://github.com/milvus-io/milvus21.5KGo/Python/C++✅pineconehttps://www.pinecone.io/❌❌✅qdranthttps://github.com/qdrant/qdrant11.8KRust✅typesensehttps://github.com/typesense/typesense12.9KC++❌weaviatehttps://github.com/weaviate/weaviate6.9KGo✅传统数据的扩展除了选择专业的向量数据库，使用传统数据库进行扩展也是一种方法。类似 Redis 除了传统的 Key Value 数据库用途外，Redis 还提供了 Redis Modules，这是一种通过新功能、命令和数据类型扩展 Redis 的方式。例如使用 RediSearch 模块来扩展向量搜索的功能。同理的还有 PostgreSQL 的扩展，PostgreSQL 提供使用 extension 的方式来扩展数据库的功能，例如 pgvector 来开启向量搜索的功能。它不仅支持精确和相似性搜索，还支持余弦相似度等相似性测量算法。最重要的是，它是附加在 PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub', metadata={'description': 'Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。', 'language': 'zh', 'source': 'https://guangzhengli.com/blog/zh/vector-database/', 'title': '向量数据库'})]\n",
      "[Document(page_content='{\\n  \"input\": \"向量数据库是什么\",\\n  \"chat_history\": []\\n}\\n[chain/start] [chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableLambda] Entering Chain run with input:\\n{\\n  \"input\": \"向量数据库是什么\",\\n  \"chat_history\": []\\n}\\n[chain/end] [chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableLambda] [0ms] Exiting Chain run with output:\\n{\\n  \"output\": true\\n}\\n[chain/start] [chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableSequence] Entering Chain run with input:\\n{\\n  \"input\": \"向量数据库是什么\",\\n  \"chat_history\": []\\n}', metadata={'language': 'en', 'source': 'https://daliuchen.github.io/langchain-guide/content/section_10.html', 'title': 'QA With RAG — langchan study guide'}), Document(page_content='{\\n  \"input\": \"向量数据库是什么\",\\n  \"chat_history\": []\\n}\\n[chain/start] [chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableLambda] Entering Chain run with input:\\n{\\n  \"input\": \"向量数据库是什么\",\\n  \"chat_history\": []\\n}\\n[chain/end] [chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableLambda] [0ms] Exiting Chain run with output:\\n{\\n  \"output\": true\\n}\\n[chain/start] [chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableSequence] Entering Chain run with input:\\n{\\n  \"input\": \"向量数据库是什么\",\\n  \"chat_history\": []\\n}', metadata={'language': 'en', 'source': 'https://daliuchen.github.io/langchain-guide/content/section_10.html', 'title': 'QA With RAG — langchan study guide'}), Document(page_content='}\\n[chain/start] [chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > prompt:ChatPromptTemplate] Entering Prompt run with input:\\n{\\n  \"input\": \"向量数据库是什么\",\\n  \"chat_history\": [],', metadata={'language': 'en', 'source': 'https://daliuchen.github.io/langchain-guide/content/section_10.html', 'title': 'QA With RAG — langchan study guide'}), Document(page_content='}\\n[chain/start] [chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > prompt:ChatPromptTemplate] Entering Prompt run with input:\\n{\\n  \"input\": \"向量数据库是什么\",\\n  \"chat_history\": [],', metadata={'language': 'en', 'source': 'https://daliuchen.github.io/langchain-guide/content/section_10.html', 'title': 'QA With RAG — langchan study guide'})]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "如上所示，在Embedding之后，将结果存储在数据库，我采用的方式是使用不同的`collection name`来做，这是隔离的一个基本思路，在实际中也是，让用户连接，构建chain的时候，就可以指定该用户所对应的`collection name`，实现数据隔离。",
   "id": "27a8070453b5c7ed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 如何在提取时处理长文本\n",
    "文档：https://python.langchain.com/v0.2/docs/how_to/extraction_long_text/\n",
    "\n",
    "在处理文本的时候，会遇到文本太长超过llm的限制，有三种方式来处理\n",
    "1. 换一个模型（可能更加的简单且效果好）\n",
    "2. 将文本简单的分块，从每个块中提取内容\n",
    "3. 对文本做RAG，对每个块做index，和问题相关的块做提取\n",
    "\n",
    "下面的demo演示了2，3两个方法"
   ],
   "id": "724d88e70cab4536"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:03:17.561520Z",
     "start_time": "2024-07-31T15:03:17.199975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 准备\n",
    "import re\n",
    "\n",
    "import requests\n",
    "from langchain_community.document_loaders import BSHTMLLoader\n",
    "\n",
    "# Download the content\n",
    "response = requests.get(\"https://baike.baidu.com/item/比亚迪\")\n",
    "# Write it to a file\n",
    "with open(\"/tmp/car.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.text)\n",
    "# Load it with an HTML parser\n",
    "loader = BSHTMLLoader(\"/tmp/car.html\",bs_kwargs={\"features\": \"html\"})\n",
    "document = loader.load()[0]\n",
    "# Clean up code\n",
    "# Replace consecutive new lines with a single new line\n",
    "document.page_content = re.sub(\"\\n\\n+\", \"\\n\", document.page_content)"
   ],
   "id": "8cbce4d66ec204b3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cliu/.virtualenvs/langchain-guide/lib/python3.11/site-packages/langchain_community/document_loaders/html_bs.py:51: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 51 of the file /Users/cliu/.virtualenvs/langchain-guide/lib/python3.11/site-packages/langchain_community/document_loaders/html_bs.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(f, **self.bs_kwargs)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:03:30.245870Z",
     "start_time": "2024-07-31T15:03:30.243554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 这是直接加载了一个网页，他是一个超长文本，\n",
    "print(len(document.page_content))"
   ],
   "id": "c30a3b2bad751959",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36465\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:03:33.963142Z",
     "start_time": "2024-07-31T15:03:33.832174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class KeyDevelopment(BaseModel):\n",
    "    \"\"\"比亚迪车型的相关信息\"\"\"\n",
    "\n",
    "    year: int = Field(description=\"车的上市年份.\")\n",
    "    car_name: str = Field(description=\"车的名字\")\n",
    "\n",
    "\n",
    "class ExtractionData(BaseModel):\n",
    "    \"\"\"比亚迪汽车车型的提取信息。\"\"\"\n",
    "    key_developments: List[KeyDevelopment]\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"你擅长提取文本中比亚迪车型发布的重要节点，如果提取不到重要信息，则不提取任何内容\",\n",
    "        ),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")"
   ],
   "id": "22aea9be21a56885",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:04:46.222164Z",
     "start_time": "2024-07-31T15:04:22.602725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "extractor = prompt | llm.with_structured_output(\n",
    "    schema=ExtractionData,\n",
    "    include_raw=False,\n",
    ")\n",
    "extractor.invoke({\"text\":document.page_content})"
   ],
   "id": "7a6637e5943278fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtractionData(key_developments=[KeyDevelopment(year=2024, car_name='海鸥'), KeyDevelopment(year=2024, car_name='仰望U8越野玩家版'), KeyDevelopment(year=2024, car_name='海狮07EV'), KeyDevelopment(year=2024, car_name='SHARK'), KeyDevelopment(year=2024, car_name='秦L DM-i'), KeyDevelopment(year=2024, car_name='海豹06 DM-i'), KeyDevelopment(year=2024, car_name='海豹'), KeyDevelopment(year=2023, car_name='宋L'), KeyDevelopment(year=2023, car_name='驱逐舰07'), KeyDevelopment(year=2023, car_name='方程豹'), KeyDevelopment(year=2022, car_name='汉EV'), KeyDevelopment(year=2022, car_name='唐EV'), KeyDevelopment(year=2022, car_name='ATTO 3'), KeyDevelopment(year=2022, car_name='元PLUS'), KeyDevelopment(year=2022, car_name='海豚'), KeyDevelopment(year=2022, car_name='海豹')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "已经准备好了，下面开始干活",
   "id": "ab74dbad03f4689e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 直接分块提取\n",
    "\n",
    "这种方式比较简单，将各个结果分块，各自去调用llm，走上面的提取逻辑，再将结果合并"
   ],
   "id": "fa1e5c74e44acee4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:14:15.951843Z",
     "start_time": "2024-07-31T15:14:03.453268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(\n",
    "    # Controls the size of each chunk\n",
    "    chunk_size=2000,\n",
    "    # Controls overlap between chunks\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(document.page_content)\n",
    "# Limit just to the first 3 chunks\n",
    "# so the code can be re-run quickly\n",
    "first_few = texts[:3]\n",
    "\n",
    "extractions = extractor.batch(\n",
    "    [{\"text\": text} for text in first_few],\n",
    "    {\"max_concurrency\": 5},  # limit the concurrency by passing max concurrency!\n",
    ")"
   ],
   "id": "815ef35d1632bd2e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "合并结果",
   "id": "e642a792d9b1b844"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:15:56.475341Z",
     "start_time": "2024-07-31T15:15:56.471385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "key_developments = []\n",
    "\n",
    "for extraction in extractions:\n",
    "    key_developments.extend(extraction.key_developments)\n",
    "\n",
    "key_developments[:10]"
   ],
   "id": "9c0ee73e760e72e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KeyDevelopment(year=2024, car_name='比亚迪海鸥'),\n",
       " KeyDevelopment(year=2024, car_name='比亚迪仰望U8越野玩家版'),\n",
       " KeyDevelopment(year=2024, car_name='海狮07EV'),\n",
       " KeyDevelopment(year=2024, car_name='SHARK'),\n",
       " KeyDevelopment(year=2024, car_name='秦L DM-i'),\n",
       " KeyDevelopment(year=2024, car_name='海豹06 DM-i'),\n",
       " KeyDevelopment(year=2024, car_name='海豹'),\n",
       " KeyDevelopment(year=2015, car_name='比亚迪'),\n",
       " KeyDevelopment(year=2016, car_name='比亚迪'),\n",
       " KeyDevelopment(year=2017, car_name='比亚迪')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 对文本做RAG\n",
    "\n",
    "这种方式就是RAG，没什么新意可言。"
   ],
   "id": "6fa139284b60b5b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:18:59.308960Z",
     "start_time": "2024-07-31T15:18:50.547192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "texts = text_splitter.split_text(document.page_content)\n",
    "vectorstore = Chroma.from_texts(texts, embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 1}\n",
    ")  # Only extract from first document"
   ],
   "id": "c384c61943b665f2",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:19:17.627404Z",
     "start_time": "2024-07-31T15:19:02.307121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rag_extractor = {\n",
    "    \"text\": retriever | (lambda docs: docs[0].page_content)  # fetch content of top doc\n",
    "} | extractor\n",
    "\n",
    "results = rag_extractor.invoke(\"比亚迪有什么车型？\")"
   ],
   "id": "8dd1ab7873b0ae21",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:19:19.665259Z",
     "start_time": "2024-07-31T15:19:19.662524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for key_development in results.key_developments:\n",
    "    print(key_development)"
   ],
   "id": "5499707e10c8e68c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year=2023 car_name='BYD ATTO 3（元PLUS）'\n",
      "year=2023 car_name='比亚迪汉'\n",
      "year=2023 car_name='比亚迪唐'\n",
      "year=2023 car_name='仰望U9'\n",
      "year=2023 car_name='汉DM-i荣耀版'\n",
      "year=2023 car_name='汉EV荣耀版'\n",
      "year=2023 car_name='唐DM-i荣耀版'\n",
      "year=2023 car_name='2024款汉DM-p战神版'\n",
      "year=2023 car_name='宋PLUS DM-i荣耀版'\n",
      "year=2023 car_name='宋PLUS EV荣耀版'\n",
      "year=2023 car_name='Seal'\n",
      "year=2023 car_name='海鸥荣耀版'\n",
      "year=2023 car_name='海豹'\n",
      "year=2023 car_name='护卫舰 07 荣耀版'\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 只是使用Prompt不适用函数调用来生成结构化数据\n",
    "\n",
    "有些模型不支持函数调用（tool calling），想要返回结构化调用只能通过Prompt来做\n",
    "如果有的模型指令跟随是比较好的，通过Prompt能输出结构化数据\n",
    "通过下面的步骤来完成\n",
    "\n",
    "- 指示 LLM 按照预期格式生成文本\n",
    "- 使用输出解析器将模型的响应结构化为所需的 Python 对象。\n",
    "\n",
    "\n",
    "这里需要使用`PydanticOutputParser`"
   ],
   "id": "cd6144452ade8f89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:31:36.297171Z",
     "start_time": "2024-07-31T15:31:36.286872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"人的信息\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"人名\")\n",
    "    height_in_meters: float = Field(\n",
    "        ..., description=\"人的身高，单位M\"\n",
    "    )\n",
    "\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"文本中提取的关于人的所有信息\"\"\"\n",
    "\n",
    "    people: List[Person]\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=People)\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\",\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    "    # partial的意思是copy一份，并且渲染一部分\n",
    ").partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "print(\"format_instructions:\\n\",parser.get_format_instructions())\n",
    "print(\"*\"*50)\n",
    "print(prompt.invoke({\"query\": \"小明一米五，小高比小明高一米\"}).to_messages()[0])\n",
    "print(\"*\"*50)\n",
    "print(prompt.invoke({\"query\": \"小明一米五，小高比小明高一米\"}).to_messages()[1])\n",
    "print(\"*\"*50)"
   ],
   "id": "cf6bae20767e0f20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "format_instructions:\n",
      " The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"\\u6587\\u672c\\u4e2d\\u63d0\\u53d6\\u7684\\u5173\\u4e8e\\u4eba\\u7684\\u6240\\u6709\\u4fe1\\u606f\", \"properties\": {\"people\": {\"title\": \"People\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Person\"}}}, \"required\": [\"people\"], \"definitions\": {\"Person\": {\"title\": \"Person\", \"description\": \"\\u4eba\\u7684\\u4fe1\\u606f\", \"type\": \"object\", \"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"\\u4eba\\u540d\", \"type\": \"string\"}, \"height_in_meters\": {\"title\": \"Height In Meters\", \"description\": \"\\u4eba\\u7684\\u8eab\\u9ad8\\uff0c\\u5355\\u4f4dM\", \"type\": \"number\"}}, \"required\": [\"name\", \"height_in_meters\"]}}}\n",
      "```\n",
      "**************************************************\n",
      "content='Answer the user query. Wrap the output in `json` tags\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"description\": \"\\\\u6587\\\\u672c\\\\u4e2d\\\\u63d0\\\\u53d6\\\\u7684\\\\u5173\\\\u4e8e\\\\u4eba\\\\u7684\\\\u6240\\\\u6709\\\\u4fe1\\\\u606f\", \"properties\": {\"people\": {\"title\": \"People\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Person\"}}}, \"required\": [\"people\"], \"definitions\": {\"Person\": {\"title\": \"Person\", \"description\": \"\\\\u4eba\\\\u7684\\\\u4fe1\\\\u606f\", \"type\": \"object\", \"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"\\\\u4eba\\\\u540d\", \"type\": \"string\"}, \"height_in_meters\": {\"title\": \"Height In Meters\", \"description\": \"\\\\u4eba\\\\u7684\\\\u8eab\\\\u9ad8\\\\uff0c\\\\u5355\\\\u4f4dM\", \"type\": \"number\"}}, \"required\": [\"name\", \"height_in_meters\"]}}}\\n```'\n",
      "**************************************************\n",
      "content='小明一米五，小高比小明高一米'\n",
      "**************************************************\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "上面是完整的Prompt，通过`pydantic`定义的model，调用`get_format_instructions`方法后，会自动生成json的定义，所以这里不需要手动来做。\n",
    "\n",
    "在将上面的promot传递给LLM后，LLM会返回既定要求的文本（json格式），这里需要手动做解析，如下 "
   ],
   "id": "39ddf4ec6c0ea91c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:35:00.585138Z",
     "start_time": "2024-07-31T15:35:00.580318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "\n",
    "# 自定义\n",
    "## llm输出的值为 AIMessage\n",
    "def extract_json(message: AIMessage) -> List[dict]:\n",
    "    \"\"\"Extracts JSON content from a string where JSON is embedded between ```json and ``` tags.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text containing the JSON content.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of extracted JSON strings.\n",
    "    \"\"\"\n",
    "    text = message.content\n",
    "    # Define the regular expression pattern to match JSON blocks\n",
    "    pattern = r\"```json(.*?)```\"\n",
    "\n",
    "    # Find all non-overlapping matches of the pattern in the string\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "    # Return the list of matched JSON strings, stripping any leading or trailing whitespace\n",
    "    try:\n",
    "        return [json.loads(match.strip()) for match in matches]\n",
    "    except Exception:\n",
    "        raise ValueError(f\"Failed to parse: {message}\")"
   ],
   "id": "48c45f9b0de99b77",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:36:14.136369Z",
     "start_time": "2024-07-31T15:36:10.522134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"小明一米五，小高比小明高一米\"\n",
    "chain = prompt | llm | extract_json\n",
    "chain.invoke({\"query\": query})"
   ],
   "id": "a3033da840506716",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'people': [{'name': '小明', 'height_in_meters': 1.5},\n",
       "   {'name': '小高', 'height_in_meters': 2.5}]}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "查看LangSmith如下：\n",
    "![](../resource/img_18.png)\n",
    "\n",
    "done!"
   ],
   "id": "e709fa1535480aa9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
