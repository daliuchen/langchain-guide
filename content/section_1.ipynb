{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# happy path",
   "id": "f04300bfc08e0354"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```shell\n",
    "# 启动之前需要在命令行执行\n",
    " pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "# 做什么？\n",
    "让LLM做翻译"
   ],
   "id": "85815e3dc4dcc2e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 使用LLM",
   "id": "bbb710434633ed07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T16:25:39.397293Z",
     "start_time": "2024-06-13T16:25:39.241659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-********\"  去掉注释\n",
    "# os.environ[\"OPENAI_API_BASE\"] = \"https://ai-yyds.com/v1\"\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4\")"
   ],
   "id": "68830e9fc37b9a15",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "到此，创建了ChatOpenAI的model，他继承了langchain的`RunnableSerializable`接口，`RunnableSerializable`在langchain的表达式中很重要，他重写了 `__or__`方法，使得可以用 | 来实现管道符,并且规定了一系列标准方法，langchain的核心组件都实现了这个方法。之后细讲。在这里，就可以直接通过invoke方法来调用了。",
   "id": "f913afeb2b962a53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T16:26:25.793709Z",
     "start_time": "2024-06-13T16:26:20.614293Z"
    }
   },
   "cell_type": "code",
   "source": "model.invoke(\"hi,你是谁\")",
   "id": "2b1342e16e5b03b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好，我是OpenAI的人工智能助手。我可以帮助你回答各种问题，也可以在需要的时候提供帮助。', response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 13, 'total_tokens': 60}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8e096cbb-9382-4ba7-8c8c-1cddca3500d3-0', usage_metadata={'input_tokens': 13, 'output_tokens': 47, 'total_tokens': 60})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "如上所属，这种方式和之前直接调用openAI的接口是一样的，但是需要注意的是，返回值langchain做了包装，并且将入参也包装了， 将`str`变为`PromptValue`\n",
    "在和LLM交互的时候需要角色扮演，这里也支持，用下面的方式"
   ],
   "id": "c678bc63737fcfe6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:19:52.217780Z",
     "start_time": "2024-06-13T15:19:45.010014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "messages = [\n",
    "    SystemMessage(content=\"将下面的英文歌词翻译为中文\"),\n",
    "    HumanMessage(content=\"\"\"\n",
    "Look how they shine for you\n",
    "And everything you do\n",
    "Yeah' they were all Yellow\n",
    "I came along\n",
    "I wrote a song for you\n",
    "And all the things you do\n",
    "It was called Yellow\n",
    "So then I took my turn\n",
    "Oh what a thing to have done\n",
    "\"\"\")]\n",
    "# 传递给LLM\n",
    "res = model.invoke(messages)\n",
    "print(res)"
   ],
   "id": "dabd1ac3928cac5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='看他们如何为你闪耀\\n还有你所做的一切\\n是的，他们都是黄色的\\n我过来了\\n我为你写了一首歌\\n还有你做的所有事情\\n那首歌叫做“黄色”\\n然后轮到我了\\n哦，做这件事情真是太棒了' response_metadata={'token_usage': {'completion_tokens': 98, 'prompt_tokens': 87, 'total_tokens': 185}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-88b99115-3b2c-405b-abc5-27aa8899685c-0' usage_metadata={'input_tokens': 87, 'output_tokens': 98, 'total_tokens': 185}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 返回值解析\n",
    "\n",
    "现在需要从返回的`AIMessage`中拿到返回值，langchain已经帮我们封装好了`StrOutputParser`，可以直接读取到`content`属性"
   ],
   "id": "170e9ddb9138c950"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:19:52.235707Z",
     "start_time": "2024-06-13T15:19:52.231152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "parser.invoke(res)"
   ],
   "id": "694bba603eb15c2b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'看他们如何为你闪耀\\n还有你所做的一切\\n是的，他们都是黄色的\\n我过来了\\n我为你写了一首歌\\n还有你做的所有事情\\n那首歌叫做“黄色”\\n然后轮到我了\\n哦，做这件事情真是太棒了'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "如你看到的一样，`StrOutputParser`也继承了`RunnableSerializable`类，所以也可以通过invoke来调用。\n",
    "到这里已经拿到了结果了。前面说了，继承于`RunnableSerializable`的类，都可以通过 `|` 符号来实现管道流。 上面的代码就可以改写为"
   ],
   "id": "d0e0e599b968d21a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:21:29.712149Z",
     "start_time": "2024-06-13T15:21:13.466240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = model | parser\n",
    "chain.invoke(messages)"
   ],
   "id": "8b37d9290a5256f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'看他们如何为你闪耀\\n和你所做的一切\\n是的，他们都是黄色的\\n我走过来\\n我为你写了一首歌\\n和你所做的一切\\n这就是名为“黄色”的那首歌\\n然后我开始轮到我\\n哦，做了这样的事情真是太了不起了'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**体会到chain的意义了吗！！**\n",
    "不需要像之前一样，先组装prompt，在去调用llm的接口，自己做解析。langchain已经做好这样的功能了，我们做的事情是将组件拼接在一块，形成一个chain。快捷开发\n",
    "\n",
    "但是现在还有个问题，prompt不够灵活，如果想翻译为韩文的话，要怎么做"
   ],
   "id": "6329dff8ad0fd579"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Prompt Templates\n",
    "\n",
    "PromptTemplates 是 LangChain 中的一个重要概念，他可以做格式化模板，将消息分类（系统message，人类的message，ai的message）\n",
    "对于上面，需要有两个模板变量\n",
    "- language： 翻译为什么语言\n",
    "- input：要翻译的文本\n",
    "\n",
    "下面用`ChatPromptTemplate`来做，他是`BasePromptTemplate`的子类，用于创建灵活的聊天模型模板prompt"
   ],
   "id": "926383f19de80416"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:38:19.189956Z",
     "start_time": "2024-06-13T15:38:19.185742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 定义system message\n",
    "system_template = \"将下面的文本翻译为{language}:\"\n",
    "# 创建 ChatPromptTemplate，分为user和system\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{input}\")]\n",
    ")   "
   ],
   "id": "cda983a976bd0b4a",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`ChatPromptTemplate`继承了`RunnableSerializable`，可以直接调用`invoke`方法",
   "id": "99339df5588013f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:40:55.015489Z",
     "start_time": "2024-06-13T15:40:55.011524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_format_res = prompt_template.invoke({\"language\":\"韩文\",\"input\":\"\"\"\n",
    "Look how they shine for you\n",
    "And everything you do\n",
    "Yeah' they were all Yellow\n",
    "I came along\n",
    "I wrote a song for you\n",
    "And all the things you do\n",
    "It was called Yellow\n",
    "So then I took my turn\n",
    "Oh what a thing to have done\n",
    "\"\"\"})\n",
    "print(prompt_format_res)\n",
    "type(prompt_format_res)"
   ],
   "id": "b80e95a8bd658e42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='将下面的文本翻译为韩文:'), HumanMessage(content=\"\\nLook how they shine for you\\nAnd everything you do\\nYeah' they were all Yellow\\nI came along\\nI wrote a song for you\\nAnd all the things you do\\nIt was called Yellow\\nSo then I took my turn\\nOh what a thing to have done\\n\")]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "langchain_core.prompt_values.ChatPromptValue"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "如上所示，`prompt_template 调用 invoke`之后，得到的类型是`ChatPromptValue`,调用`messages`拿到messages，如下所示，这就和👆🏻是一样的。不过，灵活性大大提升",
   "id": "182fb5ed2d2e4c6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:40:38.185104Z",
     "start_time": "2024-06-13T15:40:38.181207Z"
    }
   },
   "cell_type": "code",
   "source": "prompt_format_res.messages",
   "id": "9ce91ea78691eeef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='将下面的文本翻译为韩文:'),\n",
       " HumanMessage(content=\"\\nLook how they shine for you\\nAnd everything you do\\nYeah' they were all Yellow\\nI came along\\nI wrote a song for you\\nAnd all the things you do\\nIt was called Yellow\\nSo then I took my turn\\nOh what a thing to have done\\n\")]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "它也实现了`RunnableSerializable`接口，所以可以用`|`拼接",
   "id": "4b00a0d568ff806"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:46:50.356501Z",
     "start_time": "2024-06-13T15:46:39.338836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = prompt_template | model | parser\n",
    "invoke_res = llm.invoke({\"language\":\"韩文\",\"input\":\"\"\"\n",
    "Look how they shine for you\n",
    "And everything you do\n",
    "Yeah' they were all Yellow\n",
    "I came along\n",
    "I wrote a song for you\n",
    "And all the things you do\n",
    "It was called Yellow\n",
    "So then I took my turn\n",
    "Oh what a thing to have done\n",
    "\"\"\"})\n",
    "print(invoke_res)"
   ],
   "id": "eff86f1a4ab59853",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "너를 위해 어떻게 빛나는지 봐\n",
      "그리고 네가 하는 모든 일에\n",
      "그래, 그들은 모두 노란색이었어\n",
      "나는 왔어\n",
      "나는 너를 위한 노래를 썼어\n",
      "그리고 너가 하는 모든 일에 대해\n",
      "그것은 '노란색'이라고 불렸어\n",
      "그래서 차례를 기다렸어\n",
      "오, 그런 일을 한 것이야\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "韩文看不懂，把韩文翻译为中文",
   "id": "946984716f6153b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:47:32.751931Z",
     "start_time": "2024-06-13T15:47:26.257325Z"
    }
   },
   "cell_type": "code",
   "source": "llm.invoke({\"language\":\"中文\",\"input\":invoke_res})",
   "id": "f321746aeeeb3e70",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'看看我如何为你闪耀\\n还有你做的所有事情\\n是的，它们都是黄色的\\n我来了\\n我为你写了一首歌\\n关于你做的所有事情\\n它被称为“黄色”\\n所以我等待着轮到我\\n哦，我做过这样的事情'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "！！看到了么，一个完整的chain出现了，prompt -> llm -> result parse。并且用`|` 连接了起来，实现了管道流。（是因为他们都继承了`RunnableSerializable`类），和原始的openai的chat api相比，代码简单了很多，灵活性也很高。\n",
    "\n",
    "**到这里happy path 结束了**\n",
    "\n",
    "上面支持开发，langchain是一站式的llm开发框架，下面介绍langsmith和langserver"
   ],
   "id": "914ba8c7d8886ba6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# lang server\n",
    "\n",
    "就是将chain通过REST api的形式暴露出来，并且提供了swagger文档和playground来调试chain"
   ],
   "id": "ccf6c60dae8e1709"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ! pip install \"langserve[all]\"\n",
    "# 我已经在requirements.txt中已经安装过了，这里不需要了"
   ],
   "id": "a1b1183955736351"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "他是基于FAST API的，这里需要创建fast的app，绑定路由，启动。",
   "id": "b7e21d291f347755"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from langserve import add_routes\n",
    "\n",
    "# 创建FastAPi app\n",
    "app = FastAPI(\n",
    "  title=\"LangChain Server\",\n",
    "  version=\"1.0\",\n",
    "  description=\"A simple API server using LangChain's Runnable interfaces\",\n",
    ")\n",
    "\n",
    "# 创建chain\n",
    "def translate_chain():\n",
    "    # 将上面的代码包装在这里\n",
    "    import os\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    # os.environ[\"OPENAI_API_KEY\"] = \"sk-********\"\n",
    "    # os.environ[\"OPENAI_API_BASE\"] = \"https://ai-yyds.com/v1\"\n",
    "    \n",
    "    model = ChatOpenAI(model=\"gpt-4\")\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "    parser = StrOutputParser()\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "    # 定义system message\n",
    "    system_template = \"将下面的文本翻译为{language}:\"\n",
    "    # 创建 ChatPromptTemplate，分为user和system\n",
    "    prompt_template = ChatPromptTemplate.from_messages(\n",
    "        [(\"system\", system_template), (\"user\", \"{input}\")]\n",
    "    ) \n",
    "    return prompt_template | model | parser\n",
    "\n",
    "# 绑定chain\n",
    "add_routes(\n",
    "    app,\n",
    "    translate_chain(),\n",
    "    path=\"/chain\",\n",
    ")\n",
    "print(\"这里的代码需要新建一个py文件来跑，因为jupyter-book里面不能再启动event loop了\")\n",
    "# if __name__ == '__main__':\n",
    "#     # 启动\n",
    "#     uvicorn.run(app, host=\"localhost\", port=8000)"
   ],
   "id": "ac3255e570257601",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**上面的代码需要新建一个py文件来跑，因为jupyter-book里面不能再启动event loop了**，具体可以看 src/section_1_lang_server.py\n",
    "\n",
    "他提供了功能如下\n",
    "\n",
    "## 将chain暴露为了REST API并且提供了swagger文档\n",
    "服务地址： http://localhost:8000 \n",
    "接口文档地址：http://localhost:8000/docs\n",
    "\n",
    "![](../resource/img_1.png)\n",
    "\n",
    "## 提供了playground来调试\n",
    "地址：http://localhost:8000/chain/playground/\n",
    "\n",
    "![](../resource/img_2.png)\n",
    "运行调试：\n",
    "\n",
    "\n",
    "\n",
    "![](../resource/img_3.png)\n"
   ],
   "id": "2e5e2cf33828e649"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
