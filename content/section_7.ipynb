{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Retrievers\n",
    "\n",
    "retriever是一个接口，它可以给定的查询返回相关的文档。它接受一个字符串查询作为输入，并返回一个`Document`列表作为输出。\n",
    "LangChain提供的Retrievers如下：\n",
    "https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/#advanced-retrieval-types\n",
    "\n",
    "LangChain社区也提供了很多的Retrieves，如下：\n",
    "https://python.langchain.com/v0.1/docs/integrations/retrievers/\n",
    "\n",
    "LangChain中Retrievers的代码定义在`langchain-guide/lib/python3.11/site-packages/langchain_community/vectorstores/__init__.py`中"
   ],
   "id": "18249217c4126b9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:28:21.539320Z",
     "start_time": "2024-07-03T14:28:20.071275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://daliuchen.github.io/langchain-guide/intro.html\",)\n",
    ")\n",
    "loader.load()"
   ],
   "id": "a6c1932490f63f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\n\\n\\n\\n\\n\\n欢迎来到我的langchain的学习手册 — langchan study guide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content\\n\\n\\nBack to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCtrl+K\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    欢迎来到我的langchain的学习手册\\n                \\n\\n\\n\\nhappy path\\nLangChain Expression Language\\nPrompt templates\\nExample selectors\\nOutput parsers\\nRAG检索增强\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRepository\\n\\n\\n\\n\\n\\n\\nOpen issue\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n.md\\n\\n\\n\\n\\n\\n\\n\\n.pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n欢迎来到我的langchain的学习手册\\n\\n\\n\\n\\n Contents \\n\\n\\n\\n欢迎来到我的langchain的学习手册\\nlangchain总述\\n一句话说清\\n是什么？\\n特点\\n整体架构\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n欢迎来到我的langchain的学习手册#\\nlangchain最近很火热，在这里记录我对langchain的学习。\\n欢迎大家一块添砖加瓦\\n\\n\\nlangchain总述#\\nlangchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n\\n一句话说清#\\n在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\\n有很多好用的东西，方便我们开发LLM的应用程序\\n\\n\\n是什么？#\\n\\n基于大语言模型的开发框架（LLM）\\n大语言模型的一站式开发框架\\n\\n\\n\\n特点#\\n\\n简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n提供了一站式的开发框架，包括开发，部署，观测\\n简化了llm应用生命周期阶段，包括\\n\\n开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n生产：LangSmith可以检查、监控和评估chain。\\n部署：LangServe可以将chain暴露给外部服务来使用（API）\\n\\n\\n\\n\\n\\n整体架构#\\n\\n如上图所示，langchain的库如下\\n\\nlangchain-core\\n对langchain的基础抽象和langchain表达式\\nlangchain-community\\n和第三方的整合（langchain是基于LLM的开发框架，他本身并不提供关于LLM的能力，它只是简化了和LLM交互的难度）\\n和一些模型的包（例如，langchain-openai、langchain-anthropic等），一些集成已经进一步分离为只依赖于langchain-core的独立轻量级包。\\nlangchain\\nChains、agents、和让应用程序有认知能力的检索策略（retrieval strategies）\\nlanggraph\\n通过将步骤建模为图中的边和节点，使用LLM构建健壮且有状态的多参与者应用程序。\\nlangserve\\n将chain变为REST APIs\\nLangSmith\\n一个开发者平台，让你调试、测试、评估和监控LLM应用程序。\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nnext\\nhappy path\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Contents\\n  \\n\\n\\n欢迎来到我的langchain的学习手册\\nlangchain总述\\n一句话说清\\n是什么？\\n特点\\n整体架构\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBy liuchen\\n\\n\\n\\n\\n    \\n      © Copyright 2023.\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://daliuchen.github.io/langchain-guide/intro.html', 'title': '欢迎来到我的langchain的学习手册 — langchan study guide', 'language': 'en'})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 向量存储检索器",
   "id": "ec4dbeb46b528ae2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "构建向量数据库，存储数据",
   "id": "67bbe094bdf69d5a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:28:24.126217Z",
     "start_time": "2024-07-03T14:28:21.540812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = Chroma.from_documents(texts, embeddings)\n",
    "print(db)"
   ],
   "id": "3d36047424cbd170",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_community.vectorstores.chroma.Chroma object at 0x1064cc7d0>\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "构建retriever查询",
   "id": "1ac99b8cb0981f61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:28:24.818874Z",
     "start_time": "2024-07-03T14:28:24.127173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever = db.as_retriever()\n",
    "# 默认使用的相似性计算\n",
    "retriever.invoke(\"LangChain的特点\")"
   ],
   "id": "c138641c04d7a453",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='欢迎来到我的langchain的学习手册#\\nlangchain最近很火热，在这里记录我对langchain的学习。\\n欢迎大家一块添砖加瓦\\n\\n\\nlangchain总述#\\nlangchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n\\n一句话说清#\\n在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\\n有很多好用的东西，方便我们开发LLM的应用程序\\n\\n\\n是什么？#\\n\\n基于大语言模型的开发框架（LLM）\\n大语言模型的一站式开发框架\\n\\n特点#\\n\\n简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n提供了一站式的开发框架，包括开发，部署，观测\\n简化了llm应用生命周期阶段，包括\\n\\n开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n生产：LangSmith可以检查、监控和评估chain。\\n部署：LangServe可以将chain暴露给外部服务来使用（API）', metadata={'language': 'en', 'source': 'https://daliuchen.github.io/langchain-guide/intro.html', 'title': '欢迎来到我的langchain的学习手册 — langchan study guide'}),\n",
       " Document(page_content='欢迎来到我的langchain的学习手册#\\nlangchain最近很火热，在这里记录我对langchain的学习。\\n欢迎大家一块添砖加瓦\\n\\n\\nlangchain总述#\\nlangchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n\\n一句话说清#\\n在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\\n有很多好用的东西，方便我们开发LLM的应用程序\\n\\n\\n是什么？#\\n\\n基于大语言模型的开发框架（LLM）\\n大语言模型的一站式开发框架\\n\\n特点#\\n\\n简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n提供了一站式的开发框架，包括开发，部署，观测\\n简化了llm应用生命周期阶段，包括\\n\\n开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n生产：LangSmith可以检查、监控和评估chain。\\n部署：LangServe可以将chain暴露给外部服务来使用（API）', metadata={'language': 'en', 'source': 'https://daliuchen.github.io/langchain-guide/intro.html', 'title': '欢迎来到我的langchain的学习手册 — langchan study guide'}),\n",
       " Document(page_content='欢迎来到我的langchain的学习手册#\\nlangchain最近很火热，在这里记录我对langchain的学习。\\n欢迎大家一块添砖加瓦\\n\\n\\nlangchain总述#\\nlangchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n\\n一句话说清#\\n在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\\n有很多好用的东西，方便我们开发LLM的应用程序\\n\\n\\n是什么？#\\n\\n基于大语言模型的开发框架（LLM）\\n大语言模型的一站式开发框架\\n\\n特点#\\n\\n简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n提供了一站式的开发框架，包括开发，部署，观测\\n简化了llm应用生命周期阶段，包括\\n\\n开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n生产：LangSmith可以检查、监控和评估chain。\\n部署：LangServe可以将chain暴露给外部服务来使用（API）', metadata={'language': 'en', 'source': 'https://daliuchen.github.io/langchain-guide/intro.html', 'title': '欢迎来到我的langchain的学习手册 — langchan study guide'}),\n",
       " Document(page_content='欢迎来到我的langchain的学习手册#\\nlangchain最近很火热，在这里记录我对langchain的学习。\\n欢迎大家一块添砖加瓦\\n\\n\\nlangchain总述#\\nlangchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n\\n一句话说清#\\n在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\\n有很多好用的东西，方便我们开发LLM的应用程序\\n\\n\\n是什么？#\\n\\n基于大语言模型的开发框架（LLM）\\n大语言模型的一站式开发框架\\n\\n特点#\\n\\n简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n提供了一站式的开发框架，包括开发，部署，观测\\n简化了llm应用生命周期阶段，包括\\n\\n开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n生产：LangSmith可以检查、监控和评估chain。\\n部署：LangServe可以将chain暴露给外部服务来使用（API）', metadata={'language': 'en', 'source': 'https://daliuchen.github.io/langchain-guide/intro.html', 'title': '欢迎来到我的langchain的学习手册 — langchan study guide'})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3aeea729ada40863"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "默认采用相似性来计算，可以修改为使用MMR来计算,并且规定只返回一条，设置相似性得分， 大于0.5的 才是符合条件的",
   "id": "4edf76795c996708"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:28:25.805410Z",
     "start_time": "2024-07-03T14:28:24.820501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever = db.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": 1,\"score_threshold\":0.8})\n",
    "retriever.invoke(\"LangChain的特点\")"
   ],
   "id": "dd140646e982d62e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 16, updating n_results = 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='欢迎来到我的langchain的学习手册#\\nlangchain最近很火热，在这里记录我对langchain的学习。\\n欢迎大家一块添砖加瓦\\n\\n\\nlangchain总述#\\nlangchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n\\n一句话说清#\\n在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\\n有很多好用的东西，方便我们开发LLM的应用程序\\n\\n\\n是什么？#\\n\\n基于大语言模型的开发框架（LLM）\\n大语言模型的一站式开发框架\\n\\n特点#\\n\\n简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n提供了一站式的开发框架，包括开发，部署，观测\\n简化了llm应用生命周期阶段，包括\\n\\n开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n生产：LangSmith可以检查、监控和评估chain。\\n部署：LangServe可以将chain暴露给外部服务来使用（API）', metadata={'language': 'en', 'source': 'https://daliuchen.github.io/langchain-guide/intro.html', 'title': '欢迎来到我的langchain的学习手册 — langchan study guide'})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## MultiQueryRetriever\n",
    "\n",
    "这是检索优化的方式，上面的retriever存在一个问题，检索不准确，这里的优化方式是通过LLM，将单一的搜索，拓展为多个维度的搜索。提高了搜索的精度，并且会将搜索到的结果合并在一起。"
   ],
   "id": "e8ef909b2926167d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:28:25.930767Z",
     "start_time": "2024-07-03T14:28:25.817087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever, DEFAULT_QUERY_PROMPT\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "question = \"LangChain的特点是什么\"\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=db.as_retriever(), llm=llm\n",
    ")\n",
    "print(retriever_from_llm)"
   ],
   "id": "505437c69598746c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x1064cc7d0>) llm_chain=PromptTemplate(input_variables=['question'], template='You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: {question}')\n",
      "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x1690b2090>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x147939a50>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='')\n",
      "| LineListOutputParser()\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "从上面可以看到，它是需要和模型做交互的，下面是他的promot",
   "id": "5b581bdcb00c453d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:28:25.954655Z",
     "start_time": "2024-07-03T14:28:25.938863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 下面是他的promot\n",
    "print(DEFAULT_QUERY_PROMPT.template)"
   ],
   "id": "b2ec8750cdf9f52f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI language model assistant. Your task is \n",
      "    to generate 3 different versions of the given user \n",
      "    question to retrieve relevant documents from a vector  database. \n",
      "    By generating multiple perspectives on the user question, \n",
      "    your goal is to help the user overcome some of the limitations \n",
      "    of distance-based similarity search. Provide these alternative \n",
      "    questions separated by newlines. Original question: {question}\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:28:30.322168Z",
     "start_time": "2024-07-03T14:28:25.966825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set logging for the queries\n",
    "import langchain\n",
    "langchain.debug=True\n",
    "# 查询\n",
    "unique_docs = retriever_from_llm.invoke(question)\n",
    "len(unique_docs) # 查找到了四个文档"
   ],
   "id": "24da228aab6a656e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[retriever:Retriever > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"question\": \"LangChain的特点是什么\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[retriever:Retriever > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"question\": \"LangChain的特点是什么\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[retriever:Retriever > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[retriever:Retriever > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: LangChain的特点是什么\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[retriever:Retriever > chain:RunnableSequence > llm:ChatOpenAI] [2.42s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"What are the characteristics of LangChain?\\nWhat features define LangChain?\\nCan you describe the key attributes of LangChain?\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"What are the characteristics of LangChain?\\nWhat features define LangChain?\\nCan you describe the key attributes of LangChain?\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 24,\n",
      "                \"prompt_tokens\": 99,\n",
      "                \"total_tokens\": 123\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-13a8345d-ce33-42db-8b22-e54fa7e568b8-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 99,\n",
      "              \"output_tokens\": 24,\n",
      "              \"total_tokens\": 123\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 24,\n",
      "      \"prompt_tokens\": 99,\n",
      "      \"total_tokens\": 123\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[retriever:Retriever > chain:RunnableSequence > parser:LineListOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[retriever:Retriever > chain:RunnableSequence > parser:LineListOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": [\n",
      "    \"What are the characteristics of LangChain?\",\n",
      "    \"What features define LangChain?\",\n",
      "    \"Can you describe the key attributes of LangChain?\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[retriever:Retriever > chain:RunnableSequence] [2.42s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": [\n",
      "    \"What are the characteristics of LangChain?\",\n",
      "    \"What features define LangChain?\",\n",
      "    \"Can you describe the key attributes of LangChain?\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 内容压缩检索器\n",
    "\n",
    "在检索的过程中，面临一个问题：数据有很多，一次查询可能会查出很多无关的数据，即使调整查询的score和方式也不能满足，不可能最少化的通过检索来找出想要的数据（信息密度太低），如果将整个文档全部塞给LLM，LLM生成的响应可能也有很多无用的话，甚至只是将你塞给他的数据，复述一遍，并且这还会花费很多的token。\n",
    "\n",
    "Contextual compression 就是解决了这个问题，这个想法很简单：不要返回检索到的原始数据，而是根据查询的上下文压缩文档，只返回相关的信息。这里的“压缩”指的是对单个文档内容进行压缩，同时也可以整体过滤掉一些文档。\n",
    "在LangChain里面`ContextualCompressionRetriever`要配合`Filter使用`，不同的`Filter`有不同的内容处理方式。"
   ],
   "id": "2b667c720773bc06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:28:33.104839Z",
     "start_time": "2024-07-03T14:28:30.322979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Helper function for printing docs\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "#   retriever 用户还是上面的  \n",
    "retriever = Chroma.from_documents(texts, OpenAIEmbeddings()).as_retriever(search_kwargs={'k': 2})\n",
    "docs = retriever.invoke(\"LangChain的特点是什么？\")\n",
    "pretty_print_docs(docs)"
   ],
   "id": "b266cace8aa16209",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "欢迎来到我的langchain的学习手册#\n",
      "langchain最近很火热，在这里记录我对langchain的学习。\n",
      "欢迎大家一块添砖加瓦\n",
      "\n",
      "\n",
      "langchain总述#\n",
      "langchain官网：\n",
      "https://python.langchain.com/v0.2/docs/introduction/\n",
      "\n",
      "一句话说清#\n",
      "在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\n",
      "有很多好用的东西，方便我们开发LLM的应用程序\n",
      "\n",
      "\n",
      "是什么？#\n",
      "\n",
      "基于大语言模型的开发框架（LLM）\n",
      "大语言模型的一站式开发框架\n",
      "\n",
      "特点#\n",
      "\n",
      "简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\n",
      "提供了一站式的开发框架，包括开发，部署，观测\n",
      "简化了llm应用生命周期阶段，包括\n",
      "\n",
      "开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\n",
      "生产：LangSmith可以检查、监控和评估chain。\n",
      "部署：LangServe可以将chain暴露给外部服务来使用（API）\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "欢迎来到我的langchain的学习手册#\n",
      "langchain最近很火热，在这里记录我对langchain的学习。\n",
      "欢迎大家一块添砖加瓦\n",
      "\n",
      "\n",
      "langchain总述#\n",
      "langchain官网：\n",
      "https://python.langchain.com/v0.2/docs/introduction/\n",
      "\n",
      "一句话说清#\n",
      "在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\n",
      "有很多好用的东西，方便我们开发LLM的应用程序\n",
      "\n",
      "\n",
      "是什么？#\n",
      "\n",
      "基于大语言模型的开发框架（LLM）\n",
      "大语言模型的一站式开发框架\n",
      "\n",
      "特点#\n",
      "\n",
      "简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\n",
      "提供了一站式的开发框架，包括开发，部署，观测\n",
      "简化了llm应用生命周期阶段，包括\n",
      "\n",
      "开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\n",
      "生产：LangSmith可以检查、监控和评估chain。\n",
      "部署：LangServe可以将chain暴露给外部服务来使用（API）\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 内容提取Filter(LLMChainExtractor)",
   "id": "2f7eaf620f29f3b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:28:44.085134Z",
     "start_time": "2024-07-03T14:28:33.105938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"LangChain的特点是什么？\"\n",
    ")\n",
    "pretty_print_docs(compressed_docs)"
   ],
   "id": "9c5824e00329b6e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"question\": \"LangChain的特点是什么？\",\n",
      "  \"context\": \"欢迎来到我的langchain的学习手册#\\nlangchain最近很火热，在这里记录我对langchain的学习。\\n欢迎大家一块添砖加瓦\\n\\n\\nlangchain总述#\\nlangchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n\\n一句话说清#\\n在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\\n有很多好用的东西，方便我们开发LLM的应用程序\\n\\n\\n是什么？#\\n\\n基于大语言模型的开发框架（LLM）\\n大语言模型的一站式开发框架\\n\\n特点#\\n\\n简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n提供了一站式的开发框架，包括开发，部署，观测\\n简化了llm应用生命周期阶段，包括\\n\\n开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n生产：LangSmith可以检查、监控和评估chain。\\n部署：LangServe可以将chain暴露给外部服务来使用（API）\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain > llm:OpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n> Question: LangChain的特点是什么？\\n> Context:\\n>>>\\n欢迎来到我的langchain的学习手册#\\nlangchain最近很火热，在这里记录我对langchain的学习。\\n欢迎大家一块添砖加瓦\\n\\n\\nlangchain总述#\\nlangchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n\\n一句话说清#\\n在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\\n有很多好用的东西，方便我们开发LLM的应用程序\\n\\n\\n是什么？#\\n\\n基于大语言模型的开发框架（LLM）\\n大语言模型的一站式开发框架\\n\\n特点#\\n\\n简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n提供了一站式的开发框架，包括开发，部署，观测\\n简化了llm应用生命周期阶段，包括\\n\\n开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n生产：LangSmith可以检查、监控和评估chain。\\n部署：LangServe可以将chain暴露给外部服务来使用（API）\\n>>>\\nExtracted relevant parts:\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain > llm:OpenAI] [5.88s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\\n- langchain最近很火热，在这里记录我对langchain的学习。\\n- langchain总述#\\n- langchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n- 一句话说清#\\n- 是什么？#\\n- 特点#\\n- 简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n- 提供了一站式的开发框架，包括开发，部署，观测\\n- 简化了llm应用生命周期阶段，包括\\n- 开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n- 生产：LangSmith可以检查、监控和评估chain。\\n- 部署：LangServe可以将chain暴露给外部服务来使用（API）\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"total_tokens\": 710,\n",
      "      \"prompt_tokens\": 464,\n",
      "      \"completion_tokens\": 246\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-instruct\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain] [5.89s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"\\n- langchain最近很火热，在这里记录我对langchain的学习。\\n- langchain总述#\\n- langchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n- 一句话说清#\\n- 是什么？#\\n- 特点#\\n- 简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n- 提供了一站式的开发框架，包括开发，部署，观测\\n- 简化了llm应用生命周期阶段，包括\\n- 开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n- 生产：LangSmith可以检查、监控和评估chain。\\n- 部署：LangServe可以将chain暴露给外部服务来使用（API）\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"question\": \"LangChain的特点是什么？\",\n",
      "  \"context\": \"欢迎来到我的langchain的学习手册#\\nlangchain最近很火热，在这里记录我对langchain的学习。\\n欢迎大家一块添砖加瓦\\n\\n\\nlangchain总述#\\nlangchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n\\n一句话说清#\\n在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\\n有很多好用的东西，方便我们开发LLM的应用程序\\n\\n\\n是什么？#\\n\\n基于大语言模型的开发框架（LLM）\\n大语言模型的一站式开发框架\\n\\n特点#\\n\\n简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n提供了一站式的开发框架，包括开发，部署，观测\\n简化了llm应用生命周期阶段，包括\\n\\n开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n生产：LangSmith可以检查、监控和评估chain。\\n部署：LangServe可以将chain暴露给外部服务来使用（API）\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain > llm:OpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n> Question: LangChain的特点是什么？\\n> Context:\\n>>>\\n欢迎来到我的langchain的学习手册#\\nlangchain最近很火热，在这里记录我对langchain的学习。\\n欢迎大家一块添砖加瓦\\n\\n\\nlangchain总述#\\nlangchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n\\n一句话说清#\\n在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\\n有很多好用的东西，方便我们开发LLM的应用程序\\n\\n\\n是什么？#\\n\\n基于大语言模型的开发框架（LLM）\\n大语言模型的一站式开发框架\\n\\n特点#\\n\\n简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n提供了一站式的开发框架，包括开发，部署，观测\\n简化了llm应用生命周期阶段，包括\\n\\n开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n生产：LangSmith可以检查、监控和评估chain。\\n部署：LangServe可以将chain暴露给外部服务来使用（API）\\n>>>\\nExtracted relevant parts:\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain > llm:OpenAI] [4.16s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\\n- langchain最近很火热，在这里记录我对langchain的学习。\\n- langchain总述#\\n- langchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n- 一句话说清#\\n- 是什么？#\\n- 特点#\\n- 简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n- 提供了一站式的开发框架，包括开发，部署，观测\\n- 简化了llm应用生命周期阶段，包括\\n- 开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n- 生产：LangSmith可以检查、监控和评估chain。\\n- 部署：LangServe可以将chain暴露给外部服务来使用（API）\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"total_tokens\": 710,\n",
      "      \"prompt_tokens\": 464,\n",
      "      \"completion_tokens\": 246\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-instruct\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain] [4.17s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"\\n- langchain最近很火热，在这里记录我对langchain的学习。\\n- langchain总述#\\n- langchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n- 一句话说清#\\n- 是什么？#\\n- 特点#\\n- 简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n- 提供了一站式的开发框架，包括开发，部署，观测\\n- 简化了llm应用生命周期阶段，包括\\n- 开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n- 生产：LangSmith可以检查、监控和评估chain。\\n- 部署：LangServe可以将chain暴露给外部服务来使用（API）\"\n",
      "}\n",
      "Document 1:\n",
      "\n",
      "- langchain最近很火热，在这里记录我对langchain的学习。\n",
      "- langchain总述#\n",
      "- langchain官网：\n",
      "https://python.langchain.com/v0.2/docs/introduction/\n",
      "- 一句话说清#\n",
      "- 是什么？#\n",
      "- 特点#\n",
      "- 简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\n",
      "- 提供了一站式的开发框架，包括开发，部署，观测\n",
      "- 简化了llm应用生命周期阶段，包括\n",
      "- 开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\n",
      "- 生产：LangSmith可以检查、监控和评估chain。\n",
      "- 部署：LangServe可以将chain暴露给外部服务来使用（API）\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "- langchain最近很火热，在这里记录我对langchain的学习。\n",
      "- langchain总述#\n",
      "- langchain官网：\n",
      "https://python.langchain.com/v0.2/docs/introduction/\n",
      "- 一句话说清#\n",
      "- 是什么？#\n",
      "- 特点#\n",
      "- 简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\n",
      "- 提供了一站式的开发框架，包括开发，部署，观测\n",
      "- 简化了llm应用生命周期阶段，包括\n",
      "- 开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\n",
      "- 生产：LangSmith可以检查、监控和评估chain。\n",
      "- 部署：LangServe可以将chain暴露给外部服务来使用（API）\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "从上面的执行过程可以看到，它会将每个搜索到的文档，和原始的问题，传递给LLM做汇总和内容整理。",
   "id": "6209ea77d3bd9b22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 内容相关Filter(LLMChainFilter)\n",
    "\n",
    "将找到的每一个文档的内容和原始的问题，传递给LLM，让LLM来决定两者是否有关，没有关系的文档直接过滤掉，有关系的直接返回，并且不会对文档的内容做提取"
   ],
   "id": "327c4536df3baab4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:28:54.908987Z",
     "start_time": "2024-07-03T14:28:44.087340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.retrievers.document_compressors import LLMChainFilter\n",
    "\n",
    "_filter = LLMChainFilter.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=_filter, base_retriever=retriever\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"LangChain的有什么组件？\"\n",
    ")\n",
    "pretty_print_docs(compressed_docs)"
   ],
   "id": "cec478387779033f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"question\": \"LangChain的有什么组件？\",\n",
      "  \"context\": \"欢迎来到我的langchain的学习手册#\\nlangchain最近很火热，在这里记录我对langchain的学习。\\n欢迎大家一块添砖加瓦\\n\\n\\nlangchain总述#\\nlangchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n\\n一句话说清#\\n在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\\n有很多好用的东西，方便我们开发LLM的应用程序\\n\\n\\n是什么？#\\n\\n基于大语言模型的开发框架（LLM）\\n大语言模型的一站式开发框架\\n\\n特点#\\n\\n简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n提供了一站式的开发框架，包括开发，部署，观测\\n简化了llm应用生命周期阶段，包括\\n\\n开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n生产：LangSmith可以检查、监控和评估chain。\\n部署：LangServe可以将chain暴露给外部服务来使用（API）\"\n",
      "}\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"question\": \"LangChain的有什么组件？\",\n",
      "  \"context\": \"欢迎来到我的langchain的学习手册#\\nlangchain最近很火热，在这里记录我对langchain的学习。\\n欢迎大家一块添砖加瓦\\n\\n\\nlangchain总述#\\nlangchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n\\n一句话说清#\\n在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\\n有很多好用的东西，方便我们开发LLM的应用程序\\n\\n\\n是什么？#\\n\\n基于大语言模型的开发框架（LLM）\\n大语言模型的一站式开发框架\\n\\n特点#\\n\\n简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n提供了一站式的开发框架，包括开发，部署，观测\\n简化了llm应用生命周期阶段，包括\\n\\n开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n生产：LangSmith可以检查、监控和评估chain。\\n部署：LangServe可以将chain暴露给外部服务来使用（API）\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain > llm:OpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Given the following question and context, return YES if the context is relevant to the question and NO if it isn't.\\n\\n> Question: LangChain的有什么组件？\\n> Context:\\n>>>\\n欢迎来到我的langchain的学习手册#\\nlangchain最近很火热，在这里记录我对langchain的学习。\\n欢迎大家一块添砖加瓦\\n\\n\\nlangchain总述#\\nlangchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n\\n一句话说清#\\n在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\\n有很多好用的东西，方便我们开发LLM的应用程序\\n\\n\\n是什么？#\\n\\n基于大语言模型的开发框架（LLM）\\n大语言模型的一站式开发框架\\n\\n特点#\\n\\n简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n提供了一站式的开发框架，包括开发，部署，观测\\n简化了llm应用生命周期阶段，包括\\n\\n开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n生产：LangSmith可以检查、监控和评估chain。\\n部署：LangServe可以将chain暴露给外部服务来使用（API）\\n>>>\\n> Relevant (YES / NO):\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain > llm:OpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Given the following question and context, return YES if the context is relevant to the question and NO if it isn't.\\n\\n> Question: LangChain的有什么组件？\\n> Context:\\n>>>\\n欢迎来到我的langchain的学习手册#\\nlangchain最近很火热，在这里记录我对langchain的学习。\\n欢迎大家一块添砖加瓦\\n\\n\\nlangchain总述#\\nlangchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n\\n一句话说清#\\n在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\\n有很多好用的东西，方便我们开发LLM的应用程序\\n\\n\\n是什么？#\\n\\n基于大语言模型的开发框架（LLM）\\n大语言模型的一站式开发框架\\n\\n特点#\\n\\n简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n提供了一站式的开发框架，包括开发，部署，观测\\n简化了llm应用生命周期阶段，包括\\n\\n开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n生产：LangSmith可以检查、监控和评估chain。\\n部署：LangServe可以将chain暴露给外部服务来使用（API）\\n>>>\\n> Relevant (YES / NO):\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain > llm:OpenAI] [949ms] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" YES\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"total_tokens\": 440,\n",
      "      \"prompt_tokens\": 439,\n",
      "      \"completion_tokens\": 1\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-instruct\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain] [952ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \" YES\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain > llm:OpenAI] [9.46s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" YES\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"total_tokens\": 440,\n",
      "      \"prompt_tokens\": 439,\n",
      "      \"completion_tokens\": 1\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-instruct\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain] [9.47s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \" YES\"\n",
      "}\n",
      "Document 1:\n",
      "\n",
      "欢迎来到我的langchain的学习手册#\n",
      "langchain最近很火热，在这里记录我对langchain的学习。\n",
      "欢迎大家一块添砖加瓦\n",
      "\n",
      "\n",
      "langchain总述#\n",
      "langchain官网：\n",
      "https://python.langchain.com/v0.2/docs/introduction/\n",
      "\n",
      "一句话说清#\n",
      "在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\n",
      "有很多好用的东西，方便我们开发LLM的应用程序\n",
      "\n",
      "\n",
      "是什么？#\n",
      "\n",
      "基于大语言模型的开发框架（LLM）\n",
      "大语言模型的一站式开发框架\n",
      "\n",
      "特点#\n",
      "\n",
      "简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\n",
      "提供了一站式的开发框架，包括开发，部署，观测\n",
      "简化了llm应用生命周期阶段，包括\n",
      "\n",
      "开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\n",
      "生产：LangSmith可以检查、监控和评估chain。\n",
      "部署：LangServe可以将chain暴露给外部服务来使用（API）\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "欢迎来到我的langchain的学习手册#\n",
      "langchain最近很火热，在这里记录我对langchain的学习。\n",
      "欢迎大家一块添砖加瓦\n",
      "\n",
      "\n",
      "langchain总述#\n",
      "langchain官网：\n",
      "https://python.langchain.com/v0.2/docs/introduction/\n",
      "\n",
      "一句话说清#\n",
      "在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\n",
      "有很多好用的东西，方便我们开发LLM的应用程序\n",
      "\n",
      "\n",
      "是什么？#\n",
      "\n",
      "基于大语言模型的开发框架（LLM）\n",
      "大语言模型的一站式开发框架\n",
      "\n",
      "特点#\n",
      "\n",
      "简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\n",
      "提供了一站式的开发框架，包括开发，部署，观测\n",
      "简化了llm应用生命周期阶段，包括\n",
      "\n",
      "开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\n",
      "生产：LangSmith可以检查、监控和评估chain。\n",
      "部署：LangServe可以将chain暴露给外部服务来使用（API）\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### EmbeddingsFilter\n",
    "\n",
    "上面的几个Filter，是要和LLM做交互的，虽然返回的内容精简了不少，但是花费一点都没有少。EmbeddingsFilter提供了一种便宜快速的选项，在从向量数据量中查找到数据后，对于每个文档再次Embedding，对query也再次Embedding，在计算一次相似度，只有满足的才能返回。"
   ],
   "id": "4f562bea0ad53974"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:29:02.829094Z",
     "start_time": "2024-07-03T14:28:54.909896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "retriever = db.as_retriever(search_kwargs={'k': 2})\n",
    "embeddings_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=embeddings_filter, base_retriever=retriever\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"LangChain的特点是什么\"\n",
    ")\n",
    "pretty_print_docs(compressed_docs)"
   ],
   "id": "8851f0c524f394b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "欢迎来到我的langchain的学习手册#\n",
      "langchain最近很火热，在这里记录我对langchain的学习。\n",
      "欢迎大家一块添砖加瓦\n",
      "\n",
      "\n",
      "langchain总述#\n",
      "langchain官网：\n",
      "https://python.langchain.com/v0.2/docs/introduction/\n",
      "\n",
      "一句话说清#\n",
      "在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\n",
      "有很多好用的东西，方便我们开发LLM的应用程序\n",
      "\n",
      "\n",
      "是什么？#\n",
      "\n",
      "基于大语言模型的开发框架（LLM）\n",
      "大语言模型的一站式开发框架\n",
      "\n",
      "特点#\n",
      "\n",
      "简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\n",
      "提供了一站式的开发框架，包括开发，部署，观测\n",
      "简化了llm应用生命周期阶段，包括\n",
      "\n",
      "开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\n",
      "生产：LangSmith可以检查、监控和评估chain。\n",
      "部署：LangServe可以将chain暴露给外部服务来使用（API）\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "欢迎来到我的langchain的学习手册#\n",
      "langchain最近很火热，在这里记录我对langchain的学习。\n",
      "欢迎大家一块添砖加瓦\n",
      "\n",
      "\n",
      "langchain总述#\n",
      "langchain官网：\n",
      "https://python.langchain.com/v0.2/docs/introduction/\n",
      "\n",
      "一句话说清#\n",
      "在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\n",
      "有很多好用的东西，方便我们开发LLM的应用程序\n",
      "\n",
      "\n",
      "是什么？#\n",
      "\n",
      "基于大语言模型的开发框架（LLM）\n",
      "大语言模型的一站式开发框架\n",
      "\n",
      "特点#\n",
      "\n",
      "简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\n",
      "提供了一站式的开发框架，包括开发，部署，观测\n",
      "简化了llm应用生命周期阶段，包括\n",
      "\n",
      "开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\n",
      "生产：LangSmith可以检查、监控和评估chain。\n",
      "部署：LangServe可以将chain暴露给外部服务来使用（API）\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 组合Filter(DocumentCompressorPipeline)\n",
    "一个组合各个Filter的Pipeline，在下面的例子中，从向量数据库中查出来原始的文档后，首先使用`CharacterTextSplitter`对文档做切分，按照`\\n`,之后使用`EmbeddingsRedundantFilter`剔除掉重复的文档，在使用`EmbeddingsFilter`做相似性查找，在使用`LLMChainExtractor`做内容提取和压缩。"
   ],
   "id": "d6f73ac709cf7b49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:29:05.862888Z",
     "start_time": "2024-07-03T14:29:02.830583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0, separator=\"\\n\")\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
    "relevant_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)\n",
    "\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    transformers=[splitter,redundant_filter,relevant_filter]\n",
    ")\n",
    "\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=pipeline_compressor, base_retriever=retriever\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"LangChain的特点是什么\"\n",
    ")\n",
    "pretty_print_docs(compressed_docs)"
   ],
   "id": "263b709f8223e378",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "大语言模型的一站式开发框架\n",
      "特点#\n",
      "简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\n",
      "提供了一站式的开发框架，包括开发，部署，观测\n",
      "简化了llm应用生命周期阶段，包括\n",
      "开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\n",
      "生产：LangSmith可以检查、监控和评估chain。\n",
      "部署：LangServe可以将chain暴露给外部服务来使用（API）\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "欢迎来到我的langchain的学习手册#\n",
      "langchain最近很火热，在这里记录我对langchain的学习。\n",
      "欢迎大家一块添砖加瓦\n",
      "langchain总述#\n",
      "langchain官网：\n",
      "https://python.langchain.com/v0.2/docs/introduction/\n",
      "一句话说清#\n",
      "在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\n",
      "有很多好用的东西，方便我们开发LLM的应用程序\n",
      "是什么？#\n",
      "基于大语言模型的开发框架（LLM）\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "上面没有添加压缩，下面增加压缩",
   "id": "248d28c5391a7bc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:29:22.993123Z",
     "start_time": "2024-07-03T14:29:05.863637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "compressor_fitler = LLMChainExtractor.from_llm(llm)\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    transformers=[splitter,redundant_filter,relevant_filter,compressor_fitler]\n",
    ")\n",
    "\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=pipeline_compressor, base_retriever=retriever\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"LangChain的特点是什么\"\n",
    ")\n",
    "pretty_print_docs(compressed_docs)"
   ],
   "id": "e3297319b64f7c17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"question\": \"LangChain的特点是什么\",\n",
      "  \"context\": \"大语言模型的一站式开发框架\\n特点#\\n简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n提供了一站式的开发框架，包括开发，部署，观测\\n简化了llm应用生命周期阶段，包括\\n开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n生产：LangSmith可以检查、监控和评估chain。\\n部署：LangServe可以将chain暴露给外部服务来使用（API）\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain > llm:OpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n> Question: LangChain的特点是什么\\n> Context:\\n>>>\\n大语言模型的一站式开发框架\\n特点#\\n简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n提供了一站式的开发框架，包括开发，部署，观测\\n简化了llm应用生命周期阶段，包括\\n开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n生产：LangSmith可以检查、监控和评估chain。\\n部署：LangServe可以将chain暴露给外部服务来使用（API）\\n>>>\\nExtracted relevant parts:\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain > llm:OpenAI] [10.44s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\\n- 简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n- 提供了一站式的开发框架，包括开发，部署，观测\\n- 简化了llm应用生命周期阶段，包括\\n- 开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n- 生产：LangSmith可以检查、监控和评估chain。\\n- 部署：LangServe可以将chain暴露给外部服务来使用（API）\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"total_tokens\": 430,\n",
      "      \"prompt_tokens\": 256,\n",
      "      \"completion_tokens\": 174\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-instruct\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain] [10.45s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"\\n- 简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\\n- 提供了一站式的开发框架，包括开发，部署，观测\\n- 简化了llm应用生命周期阶段，包括\\n- 开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\\n- 生产：LangSmith可以检查、监控和评估chain。\\n- 部署：LangServe可以将chain暴露给外部服务来使用（API）\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"question\": \"LangChain的特点是什么\",\n",
      "  \"context\": \"欢迎来到我的langchain的学习手册#\\nlangchain最近很火热，在这里记录我对langchain的学习。\\n欢迎大家一块添砖加瓦\\nlangchain总述#\\nlangchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n一句话说清#\\n在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\\n有很多好用的东西，方便我们开发LLM的应用程序\\n是什么？#\\n基于大语言模型的开发框架（LLM）\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain > llm:OpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n> Question: LangChain的特点是什么\\n> Context:\\n>>>\\n欢迎来到我的langchain的学习手册#\\nlangchain最近很火热，在这里记录我对langchain的学习。\\n欢迎大家一块添砖加瓦\\nlangchain总述#\\nlangchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n一句话说清#\\n在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\\n有很多好用的东西，方便我们开发LLM的应用程序\\n是什么？#\\n基于大语言模型的开发框架（LLM）\\n>>>\\nExtracted relevant parts:\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain > llm:OpenAI] [4.21s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\\n- langchain最近很火热，在这里记录我对langchain的学习。\\n- langchain总述#\\n- langchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n- 一句话说清#\\n- 在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\\n有很多好用的东西，方便我们开发LLM的应用程序\\n- 是什么？#\\n- 基于大语言模型的开发框架（LLM）\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"total_tokens\": 468,\n",
      "      \"prompt_tokens\": 284,\n",
      "      \"completion_tokens\": 184\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-instruct\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[retriever:Retriever > chain:LLMChain] [4.22s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"\\n- langchain最近很火热，在这里记录我对langchain的学习。\\n- langchain总述#\\n- langchain官网：\\nhttps://python.langchain.com/v0.2/docs/introduction/\\n- 一句话说清#\\n- 在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\\n有很多好用的东西，方便我们开发LLM的应用程序\\n- 是什么？#\\n- 基于大语言模型的开发框架（LLM）\"\n",
      "}\n",
      "Document 1:\n",
      "\n",
      "- 简化了大语言模型开发的难度，将和模型交互的各个阶段做抽象组合。\n",
      "- 提供了一站式的开发框架，包括开发，部署，观测\n",
      "- 简化了llm应用生命周期阶段，包括\n",
      "- 开发：Langchain提供了很多的组件，模块来构建应用程序，并且有有强大的社区生态。\n",
      "- 生产：LangSmith可以检查、监控和评估chain。\n",
      "- 部署：LangServe可以将chain暴露给外部服务来使用（API）\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "- langchain最近很火热，在这里记录我对langchain的学习。\n",
      "- langchain总述#\n",
      "- langchain官网：\n",
      "https://python.langchain.com/v0.2/docs/introduction/\n",
      "- 一句话说清#\n",
      "- 在和LLM交互的时候，首先需要写prompt，在调用LLM提供的API，解析输出。这里面就有三步，langchain将这三步抽象简化，并且提供了很多组件，他有强大的社区，\n",
      "有很多好用的东西，方便我们开发LLM的应用程序\n",
      "- 是什么？#\n",
      "- 基于大语言模型的开发框架（LLM）\n"
     ]
    }
   ],
   "execution_count": 43
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
