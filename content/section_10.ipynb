{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# QA With RAG\n",
    "\n",
    "官方文档：https://python.langchain.com/v0.2/docs/how_to/#qa-with-rag\n"
   ],
   "id": "db7f620149645700"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:00:48.679638Z",
     "start_time": "2024-07-18T14:00:43.290496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "import langchain\n",
    "\n",
    "langchain.debug = True  # 开启debug\n",
    "\n",
    "# 加载数据从webBase，这里也可以是使\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://guangzhengli.com/blog/zh/vector-database/\",),\n",
    ")\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "## 上面已经构建好了向量数据库，创建好了retriever\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"\"\"\n",
    "给你一个聊天历史和最新的用户问题，这个问题可能会引用聊天历史中的内容,如果聊天历史中有相关的内容，\n",
    "需要结合聊天内容，形成一个独立的问题，如果没有，原样复述。不要解释输出的内容，\n",
    "也不要尝试回答问题，否则你会受到惩罚。\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "print(contextualize_q_prompt.pretty_repr())"
   ],
   "id": "c81446f3017ddd47",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:00:48.683010Z",
     "start_time": "2024-07-18T14:00:48.680858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ],
   "id": "f64fa721f7a38ef",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`create_history_aware_retriever`创建的这个chan可以从retrieve中检索document。\n",
    "\n",
    "如果没有`chat_history`，会直接将输入传给`retriever`，如果有`chat_history`，会使用promot和llm生成一个search的query，然后再将query待入到retriever中去"
   ],
   "id": "406094292cb60df8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:00:48.685595Z",
     "start_time": "2024-07-18T14:00:48.683589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = \"\"\"\n",
    "你是一个问题回答任务的助理。\n",
    "使用以下检索到的上下文片段来回答问题。\n",
    "如果你不知道答案，说出你不知道。\n",
    "最多使用三个句子，并保持回答简洁。\n",
    "\n",
    "{context}\n",
    "\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "print(qa_prompt.pretty_repr())"
   ],
   "id": "c6521694ec94b071",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:00:48.687737Z",
     "start_time": "2024-07-18T14:00:48.686188Z"
    }
   },
   "cell_type": "code",
   "source": "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)",
   "id": "5ae458827ae8294a",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`create_stuff_documents_chain`是将传入chain的文档格式化全部塞给模型。",
   "id": "df8b24762756e739"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:00:48.690302Z",
     "start_time": "2024-07-18T14:00:48.688925Z"
    }
   },
   "cell_type": "code",
   "source": "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)",
   "id": "473c42951f06ae84",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`create_retrieval_chain`会创建一个检索的chain，他可以检索documents 并且传递给后面的chain",
   "id": "74f8e944ddb39a85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:00:53.518690Z",
     "start_time": "2024-07-18T14:00:48.690775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ChatMessageHistory 是将数据保存在内存中的，这里为了方便，需要一个map缓存一下\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "# 最终创建一个带有History的chain\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")\n",
    "\n",
    "res = conversational_rag_chain.invoke(\n",
    "    {\"input\": \"向量数据库是什么\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")\n",
    "print(res)"
   ],
   "id": "c9487ca649860147",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:01:00.350592Z",
     "start_time": "2024-07-18T14:00:53.519423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## 再次对话，会结合对话历史，答案形成一个新的问题，然后在用retrieve检索。\n",
    "res = conversational_rag_chain.invoke(\n",
    "    {\"input\": \"他的特点是什么？\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")"
   ],
   "id": "b8bcc99f0b5de3c1",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "可以从上面的执行过程中可以看到。从LangSmith中可以看到\n",
    "![](../resource/img_12.png)"
   ],
   "id": "d7b13d16f1fffe75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "上面的例子中，结合了检索，History，我们在来顺一下上面的流程\n",
    "\n",
    "1. 首先创建了`create_history_aware_retriever`，他本质上是一个`retriever`，他的作用是增强检索。也就是说，如果有对话历史，会将对话历史和输入的问题塞给llm，让llm结合对话历史提出一个新的问题，比如第一次问`向量数据库是什么？`，第二次问`他有什么特点？`，如果单独把最后一个问题代入到Retrieve中去，就会找到一些无效的答案。把这些对话历史给llm，llm就会知道这里的他指的是向量数据库。所以，新的问题是`向量数据库的特点？`，这样检索出来的内容就很丰富，很符合。\n",
    "2. 创建了`create_stuff_documents_chain` ，他本质上是一个`chain`,它的作用是将传入的`Document`对象格式化，然后将他传入到后面的流程中去，并且传入的key为`context`，\n",
    "所以，这就要求调用invoke的时候传入的dict中有key为context元素，并且value是Document的数组。它就是传入的文档（LangChain对外部数据做了封装，统称为Document）\n",
    "3. 创建了`create_retrieval_chain`,将前面`create_history_aware_retriever`,`create_stuff_documents_chain`包装在里面。他的作用是，将retrieve和chain结合在一起。并且在最终的返回值中，并且在最终的返回中有两个key `context`和`answer`,一个是retrieve的值，一个是chain的最终的结果. \n",
    "> `create_retrieval_chain`的源码不太好理解，下面会有demo解释，先在这里做一个说明\n",
    "> ```python\n",
    ">     retrieval_chain = (\n",
    ">        RunnablePassthrough.assign(\n",
    ">            context=retrieval_docs.with_config(run_name=\"retrieve_documents\"),\n",
    ">        ).assign(answer=combine_docs_chain)\n",
    ">    ).with_config(run_name=\"retrieval_chain\")\n",
    "> ```\n",
    "> 这里是用 `RunnablePassthrough`嵌套执行的方法，意思是：调用retrieval_chain的时候会先将所有的input代入到`retrieval_docs`执行，拿到结果，将所有的结果代入到`combine_docs_chain`中执行，最终输出的dict中会有`context`和`answer`\n",
    "4. 到这里，整体的chain已经结束了，使用`RunnableWithMessageHistory`来创建一个带有History的chain。\n",
    "\n",
    "感触：\n",
    "LangChain很强大，但是也很严格，比如参数的类型，比如说，Retrieve中的context比如和`stuff chain`中的context 这个key必须得一样，必须得有一个context的key，否则在`stuff chain`中就找不到了。\n",
    "还有类似的，`chat_history`的key，如果没有这个key,在`retrieve`的时候就不会去使用llm来做问题的增强了。因为在`create_history_aware_retriever`中key已经固定了。\n",
    "\n",
    "\n",
    "整体的流程是：当用户输入问题\n",
    "1. 先保存对话历史（用户输入的问题，通过session id）\n",
    "2. 做retrieve。\n",
    "    - 如果有对话历史就使用llm来增强，增强问题，再次查找\n",
    "    - 如果没有，就直接查找\n",
    "3. retrieve会返回Document，将这些document和chat_history会全部导入到prompt中和LLM交互\n",
    "4. 保存对话历史（AI返回值）\n",
    "5. 输出。"
   ],
   "id": "cac97c09b75f5288"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 解释RunnableParallel和RunnablePassthrough\n",
    "\n",
    "解释他的目的是为了更好的理解LangChain的LCEL，上面demo中源码里面有它。\n",
    "### RunnableParallel\n",
    "\n",
    "它是一个Runnable，我们一开始说了，Runnable就是一个LCEL的顶级接口。所以，它的使用方式和chain是一样的，按照这个思路理解是ok的。\n",
    "\n",
    "它的作用是，并行运行他里面每一个Runnable。"
   ],
   "id": "9308a4526a1f0afe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:57:23.241126Z",
     "start_time": "2024-07-18T14:57:23.220047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "def add_one(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "def mul_two(x: int) -> int:\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "def mul_three(x: int) -> int:\n",
    "    return x * 3\n",
    "\n",
    "\n",
    "# RunnableLambda 转化python代码（callable）为一个Runnable\n",
    "runnable_1 = RunnableLambda(add_one)\n",
    "runnable_2 = RunnableLambda(mul_two)\n",
    "runnable_3 = RunnableLambda(mul_three)\n",
    "\n",
    "sequence = runnable_1 | {  # this dict is coerced to a RunnableParallel\n",
    "    \"mul_two\": runnable_2,\n",
    "    \"mul_three\": runnable_3,\n",
    "}\n",
    "sequence.invoke(1)"
   ],
   "id": "a9a68981d179d0b1",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "这里面的代码就是首先将`1`传入到`add_one`返回2，之后将`2`各自输入到`mul_two`和`mul_three`，得到最终的代码，从上面的debug流程中也可以看到，上面的代码其实等于",
   "id": "6e9a2e53e7fde85d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:01:19.501531Z",
     "start_time": "2024-07-18T15:01:19.491847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# LangChain自动对dict做了包装\n",
    "chain = runnable_1 | RunnableParallel(\n",
    "    mul_two=runnable_2,\n",
    "    mul_three=runnable_3,\n",
    ")\n",
    "chain.invoke(1)"
   ],
   "id": "738dc3f5276ee199",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "实际的使用是，可以并行的调用两个chain，如下\n",
    "这里的demo会让LangChain将对一个主题，做两个事情。"
   ],
   "id": "8199d8ba7884dca3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:05:39.506659Z",
     "start_time": "2024-07-18T15:05:36.729464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "model = ChatOpenAI()\n",
    "joke_chain = (\n",
    "        ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    ")\n",
    "poem_chain = (\n",
    "        ChatPromptTemplate.from_template(\"write a 2-line poem about {topic}\")\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "parallel_chain = RunnableParallel(joke=joke_chain, poem=poem_chain)\n",
    "res = parallel_chain.invoke({\"topic\": \"太阳\"})\n",
    "print(res)"
   ],
   "id": "2c05f1ae39034c0f",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### RunnableSequence\n",
    "和上面相对应的是`RunnableSequence`，一个一个执行，前面的执行完了，前面的值作为后面的输入。\n",
    "\n",
    "`RunnableSequence`支持配置first，middle，last。按照执行顺序来"
   ],
   "id": "e1ecc50e7dbbf9d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:10:35.431074Z",
     "start_time": "2024-07-18T15:10:35.424380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableSequence\n",
    "\n",
    "\n",
    "def add_one(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "def add_two(x: int) -> int:\n",
    "    return x + 2\n",
    "\n",
    "\n",
    "def mul_two(x: int) -> int:\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "runnable_1 = RunnableLambda(add_one)\n",
    "runnable_2 = RunnableLambda(add_two)\n",
    "runnable_3 = RunnableLambda(mul_two)\n",
    "sequence = RunnableSequence(first=runnable_1, middle=[runnable_2], last=runnable_3)\n",
    "# Or equivalently:\n",
    "# sequence = runnable_1 | runnable_2\n",
    "sequence.invoke(1)"
   ],
   "id": "66927b6e4b63f5e3",
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "实际使用场景\n",
    "还记得 `prompt | model | SimpleJsonOutputParser()`不？，他本质上就是构建了一个`RunnableSequence`。\n",
    "\n",
    "### RunnablePassthrough\n",
    "\n",
    "他可以传递或者改变或者增加一个额外的key给后续的流程，都是要配合`RunnableSequence`或者`RunnableParallel`来使用的。否则没有意义。并且他也实现了`Runnable`"
   ],
   "id": "7b3702cb9eefac14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:14:41.860868Z",
     "start_time": "2024-07-18T15:14:41.842928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import (\n",
    "    RunnableLambda,\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    origin=RunnablePassthrough(),\n",
    "    modified=lambda x: x + 1\n",
    ")\n",
    "runnable.invoke(1)  # {'origin': 1, 'modified': 2}"
   ],
   "id": "74531c0657d88b78",
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在某些情况下，需要将输入透传给后面，并且在添加一些额外的key，这个情况下可以使用`assign`方法\n",
    "` RunnablePassthrough.assign()`意思就是，将原来的输入的input，传递给assign里面，在这里可以对输入值做二次加工。"
   ],
   "id": "5168d0e840578e01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:17:19.641610Z",
     "start_time": "2024-07-18T15:17:19.618500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def fake_llm(prompt: str) -> str:  # Fake LLM for the example\n",
    "    return \"completion\"\n",
    "\n",
    "\n",
    "runnable = {\n",
    "               'llm1': fake_llm,\n",
    "               'llm2': fake_llm,\n",
    "           } | RunnablePassthrough.assign(\n",
    "    total_chars=lambda inputs: len(inputs['llm1'] + inputs['llm2'])\n",
    ")\n",
    "\n",
    "runnable.invoke('hello')"
   ],
   "id": "8c0ae12062197829",
   "execution_count": 38,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "看一下`assign`方法的实现\n",
    "\n",
    "```python\n",
    "    @classmethod\n",
    "    def assign(\n",
    "        cls,\n",
    "        **kwargs: Union[\n",
    "            Runnable[Dict[str, Any], Any],\n",
    "            Callable[[Dict[str, Any]], Any],\n",
    "            Mapping[\n",
    "                str,\n",
    "                Union[Runnable[Dict[str, Any], Any], Callable[[Dict[str, Any]], Any]],\n",
    "            ],\n",
    "        ],\n",
    "    ) -> \"RunnableAssign\":\n",
    "        ### 滴滴滴，看这里，它是将传递进来的参数包装成了一个 RunnableParallel\n",
    "        return RunnableAssign(RunnableParallel(kwargs))\n",
    "```\n",
    "\n",
    "所以，他的assign方法就是手动构建了一个`RunnableParallel`,并且将inut传入到了里面。他传入的input就是当前他所在的RunnableParallel或者RunnableSequence的input。\n",
    "\n",
    "key看下面的例子，text_input 的输入就是 上一个阶段的输入。"
   ],
   "id": "ea0c7393d66ec45f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:22:23.432288Z",
     "start_time": "2024-07-18T15:22:23.403232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runnable = {\n",
    "               'llm1': fake_llm,\n",
    "               'llm2': fake_llm,\n",
    "           } | RunnablePassthrough.assign(\n",
    "    total_chars=lambda inputs: len(inputs['llm1'] + inputs['llm2']),\n",
    "    text_input=RunnablePassthrough()\n",
    ")\n",
    "runnable.invoke(1)"
   ],
   "id": "81a9c7bacc46464f",
   "execution_count": 40,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "那按照这个逻辑来说，就有下面的代码。",
   "id": "62e2ac92ede56707"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:27:29.477461Z",
     "start_time": "2024-07-18T15:27:29.451551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runnable = ({\n",
    "                'llm1': fake_llm,\n",
    "                'llm2': fake_llm,\n",
    "            }  # 1 \n",
    "            | RunnablePassthrough.assign(\n",
    "            total_chars=lambda inputs: len(inputs['llm1'] + inputs['llm2']),\n",
    "        )  # 2\n",
    "            .assign(  # 3\n",
    "            test=RunnablePassthrough()\n",
    "        ))\n",
    "runnable.invoke(1)"
   ],
   "id": "d620e98b0c17b8fe",
   "execution_count": 43,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "解释：\n",
    "在#1，创建的是RunnableParallel，有两个阶段`llm1`,`llm2`并行执行，拿到结果，将值传递给#2，#2拿到input之后，做了操作，增加了total_chars后，传递给了#3,#3，#3创建了一个key叫做test，test里面存放的是之前所有的输入。所以他的结果是\n",
    "```json\n",
    "{'llm1': 'completion',\n",
    " 'llm2': 'completion',\n",
    " 'total_chars': 20,\n",
    " 'test': {'llm1': 'completion', 'llm2': 'completion', 'total_chars': 20}}\n",
    "```\n",
    "\n",
    "end"
   ],
   "id": "d6d92b4ab2a731cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
