{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# QA With RAG\n",
    "\n",
    "官方文档：https://python.langchain.com/v0.2/docs/how_to/#qa-with-rag\n"
   ],
   "id": "db7f620149645700"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:00:48.679638Z",
     "start_time": "2024-07-18T14:00:43.290496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "import langchain\n",
    "\n",
    "langchain.debug = True  # 开启debug\n",
    "\n",
    "# 加载数据从webBase，这里也可以是使\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://guangzhengli.com/blog/zh/vector-database/\",),\n",
    ")\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "## 上面已经构建好了向量数据库，创建好了retriever\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"\"\"\n",
    "给你一个聊天历史和最新的用户问题，这个问题可能会引用聊天历史中的内容,如果聊天历史中有相关的内容，\n",
    "需要结合聊天内容，形成一个独立的问题，如果没有，原样复述。不要解释输出的内容，\n",
    "也不要尝试回答问题，否则你会受到惩罚。\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "print(contextualize_q_prompt.pretty_repr())"
   ],
   "id": "c81446f3017ddd47",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================ System Message ================================\n",
      "\n",
      "\n",
      "给你一个聊天历史和最新的用户问题，这个问题可能会引用聊天历史中的内容,如果聊天历史中有相关的内容，\n",
      "需要结合聊天内容，形成一个独立的问题，如果没有，原样复述。不要解释输出的内容，\n",
      "也不要尝试回答问题，否则你会受到惩罚。\n",
      "\n",
      "\n",
      "============================= Messages Placeholder =============================\n",
      "\n",
      "{chat_history}\n",
      "\n",
      "================================ Human Message =================================\n",
      "\n",
      "{input}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:00:48.683010Z",
     "start_time": "2024-07-18T14:00:48.680858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ],
   "id": "f64fa721f7a38ef",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`create_history_aware_retriever`创建的这个chan可以从retrieve中检索document。\n",
    "\n",
    "如果没有`chat_history`，会直接将输入传给`retriever`，如果有`chat_history`，会使用promot和llm生成一个search的query，然后再将query待入到retriever中去"
   ],
   "id": "406094292cb60df8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:00:48.685595Z",
     "start_time": "2024-07-18T14:00:48.683589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = \"\"\"\n",
    "你是一个问题回答任务的助理。\n",
    "使用以下检索到的上下文片段来回答问题。\n",
    "如果你不知道答案，说出你不知道。\n",
    "最多使用三个句子，并保持回答简洁。\n",
    "\n",
    "{context}\n",
    "\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "print(qa_prompt.pretty_repr())"
   ],
   "id": "c6521694ec94b071",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================ System Message ================================\n",
      "\n",
      "\n",
      "你是一个问题回答任务的助理。\n",
      "使用以下检索到的上下文片段来回答问题。\n",
      "如果你不知道答案，说出你不知道。\n",
      "最多使用三个句子，并保持回答简洁。\n",
      "\n",
      "{context}\n",
      "\n",
      "\n",
      "============================= Messages Placeholder =============================\n",
      "\n",
      "{chat_history}\n",
      "\n",
      "================================ Human Message =================================\n",
      "\n",
      "{input}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:00:48.687737Z",
     "start_time": "2024-07-18T14:00:48.686188Z"
    }
   },
   "cell_type": "code",
   "source": "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)",
   "id": "5ae458827ae8294a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`create_stuff_documents_chain`是将传入chain的文档格式化全部塞给模型。",
   "id": "df8b24762756e739"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:00:48.690302Z",
     "start_time": "2024-07-18T14:00:48.688925Z"
    }
   },
   "cell_type": "code",
   "source": "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)",
   "id": "473c42951f06ae84",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`create_retrieval_chain`会创建一个检索的chain，他可以检索documents 并且传递给后面的chain",
   "id": "74f8e944ddb39a85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:00:53.518690Z",
     "start_time": "2024-07-18T14:00:48.690775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ChatMessageHistory 是将数据保存在内存中的，这里为了方便，需要一个map缓存一下\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "# 最终创建一个带有History的chain\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")\n",
    "\n",
    "res = conversational_rag_chain.invoke(\n",
    "    {\"input\": \"向量数据库是什么\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")\n",
    "print(res)"
   ],
   "id": "c9487ca649860147",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库是什么\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:insert_history] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库是什么\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:insert_history > chain:RunnableParallel<chat_history>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库是什么\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:insert_history > chain:RunnableParallel<chat_history> > chain:load_history] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库是什么\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:insert_history > chain:RunnableParallel<chat_history> > chain:load_history] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": []\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:insert_history > chain:RunnableParallel<chat_history>] [2ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:insert_history] [4ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库是什么\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库是什么\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:RunnableWithMessageHistoryInAsyncMode] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库是什么\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:RunnableWithMessageHistoryInAsyncMode] [0ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": false\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库是什么\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库是什么\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库是什么\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库是什么\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库是什么\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": true\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库是什么\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库是什么\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"向量数据库是什么\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableSequence] [500ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents] [502ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"向量数据库\\n\\n\\n\\n主页\",\n",
      "        \"metadata\": {\n",
      "          \"description\": \"Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。\",\n",
      "          \"language\": \"zh\",\n",
      "          \"source\": \"https://guangzhengli.com/blog/zh/vector-database/\",\n",
      "          \"title\": \"向量数据库\"\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"& SDK对比上面的因素选择，API & SDK 可能是往往被忽略的因素，但是在实际的业务场景中，API & SDK 往往是开发者最关心的因素。因为 API & SDK 的设计直接影响了开发者的开发效率和使用体验。一个优秀良好的 API & SDK 设计，往往能够适应需求的不同变化，向量数据库是一个新的领域，在如今大部分人不太清楚这方面需求的当下，这一点容易被人忽视。选型截至目前，汇总到目前的向量数据库有以下几种选择：向量数据库URLGitHub StarLanguageCloudchromahttps://github.com/chroma-core/chroma7.4KPython❌milvushttps://github.com/milvus-io/milvus21.5KGo/Python/C++✅pineconehttps://www.pinecone.io/❌❌✅qdranthttps://github.com/qdrant/qdrant11.8KRust✅typesensehttps://github.com/typesense/typesense12.9KC++❌weaviatehttps://github.com/weaviate/weaviate6.9KGo✅传统数据的扩展除了选择专业的向量数据库，使用传统数据库进行扩展也是一种方法。类似 Redis 除了传统的 Key Value 数据库用途外，Redis 还提供了 Redis Modules，这是一种通过新功能、命令和数据类型扩展 Redis 的方式。例如使用 RediSearch 模块来扩展向量搜索的功能。同理的还有 PostgreSQL 的扩展，PostgreSQL 提供使用 extension 的方式来扩展数据库的功能，例如 pgvector 来开启向量搜索的功能。它不仅支持精确和相似性搜索，还支持余弦相似度等相似性测量算法。最重要的是，它是附加在 PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub\",\n",
      "        \"metadata\": {\n",
      "          \"description\": \"Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。\",\n",
      "          \"language\": \"zh\",\n",
      "          \"source\": \"https://guangzhengli.com/blog/zh/vector-database/\",\n",
      "          \"title\": \"向量数据库\"\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub 目前就暂时使用 pgvector 来实现向量搜索以实现 GPT 文档问答，基于 Supabase 提供的 PostgreSQL + pgvector 服务完成。总结本文主要介绍了向量数据库的原理和实现，包括向量数据库的基本概念、相似性搜索算法、相似性测量算法、过滤算法和向量数据库的选型等等。向量数据库是崭新的领域，目前大部分向量数据库公司的估值乘着 AI 和 GPT\",\n",
      "        \"metadata\": {\n",
      "          \"description\": \"Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。\",\n",
      "          \"language\": \"zh\",\n",
      "          \"source\": \"https://guangzhengli.com/blog/zh/vector-database/\",\n",
      "          \"title\": \"向量数据库\"\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"的东风从而飞速的增长，但是在实际的业务场景中，目前向量数据库的应用场景还比较少，抛开浮躁的外衣，向量数据库的应用场景还需要开发者们和业务专家们去挖掘。Referenceshttps://www.bilibili.com/video/BV11a4y1c7SWhttps://www.bilibili.com/video/BV1BM4y177Dkhttps://www.pinecone.io/learn/vector-database/https://github.com/guangzhengli/ChatFileshttps://github.com/guangzhengli/vectorhubhttps://www.anthropic.com/index/100k-context-windowshttps://js.langchain.com/docs/https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing/https://www.pinecone.io/learn/series/faiss/product-quantization/https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing-random-projection/https://www.youtube.com/watch?v=QvKMwLjdK-s&t=168s&ab_channel=JamesBriggshttps://www.pinecone.io/learn/series/faiss/faiss-tutorial/https://www.youtube.com/watch?v=sKyvsdEv6rk&ab_channel=JamesBriggshttps://www.pinecone.io/learn/vector-similarity/https://github.com/chroma-core/chromahttps://github.com/milvus-io/milvushttps://www.pinecone.io/https://github.com/qdrant/qdranthttps://github.com/type\",\n",
      "        \"metadata\": {\n",
      "          \"description\": \"Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。\",\n",
      "          \"language\": \"zh\",\n",
      "          \"source\": \"https://guangzhengli.com/blog/zh/vector-database/\",\n",
      "          \"title\": \"向量数据库\"\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context>] [505ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context>] [508ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer>] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer>] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > chain:format_inputs] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > chain:format_inputs > chain:RunnableParallel<context>] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > chain:format_inputs > chain:RunnableParallel<context> > chain:format_docs] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > chain:format_inputs > chain:RunnableParallel<context> > chain:format_docs] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"向量数据库\\n\\n\\n\\n主页\\n\\n& SDK对比上面的因素选择，API & SDK 可能是往往被忽略的因素，但是在实际的业务场景中，API & SDK 往往是开发者最关心的因素。因为 API & SDK 的设计直接影响了开发者的开发效率和使用体验。一个优秀良好的 API & SDK 设计，往往能够适应需求的不同变化，向量数据库是一个新的领域，在如今大部分人不太清楚这方面需求的当下，这一点容易被人忽视。选型截至目前，汇总到目前的向量数据库有以下几种选择：向量数据库URLGitHub StarLanguageCloudchromahttps://github.com/chroma-core/chroma7.4KPython❌milvushttps://github.com/milvus-io/milvus21.5KGo/Python/C++✅pineconehttps://www.pinecone.io/❌❌✅qdranthttps://github.com/qdrant/qdrant11.8KRust✅typesensehttps://github.com/typesense/typesense12.9KC++❌weaviatehttps://github.com/weaviate/weaviate6.9KGo✅传统数据的扩展除了选择专业的向量数据库，使用传统数据库进行扩展也是一种方法。类似 Redis 除了传统的 Key Value 数据库用途外，Redis 还提供了 Redis Modules，这是一种通过新功能、命令和数据类型扩展 Redis 的方式。例如使用 RediSearch 模块来扩展向量搜索的功能。同理的还有 PostgreSQL 的扩展，PostgreSQL 提供使用 extension 的方式来扩展数据库的功能，例如 pgvector 来开启向量搜索的功能。它不仅支持精确和相似性搜索，还支持余弦相似度等相似性测量算法。最重要的是，它是附加在 PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub\\n\\nPostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub 目前就暂时使用 pgvector 来实现向量搜索以实现 GPT 文档问答，基于 Supabase 提供的 PostgreSQL + pgvector 服务完成。总结本文主要介绍了向量数据库的原理和实现，包括向量数据库的基本概念、相似性搜索算法、相似性测量算法、过滤算法和向量数据库的选型等等。向量数据库是崭新的领域，目前大部分向量数据库公司的估值乘着 AI 和 GPT\\n\\n的东风从而飞速的增长，但是在实际的业务场景中，目前向量数据库的应用场景还比较少，抛开浮躁的外衣，向量数据库的应用场景还需要开发者们和业务专家们去挖掘。Referenceshttps://www.bilibili.com/video/BV11a4y1c7SWhttps://www.bilibili.com/video/BV1BM4y177Dkhttps://www.pinecone.io/learn/vector-database/https://github.com/guangzhengli/ChatFileshttps://github.com/guangzhengli/vectorhubhttps://www.anthropic.com/index/100k-context-windowshttps://js.langchain.com/docs/https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing/https://www.pinecone.io/learn/series/faiss/product-quantization/https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing-random-projection/https://www.youtube.com/watch?v=QvKMwLjdK-s&t=168s&ab_channel=JamesBriggshttps://www.pinecone.io/learn/series/faiss/faiss-tutorial/https://www.youtube.com/watch?v=sKyvsdEv6rk&ab_channel=JamesBriggshttps://www.pinecone.io/learn/vector-similarity/https://github.com/chroma-core/chromahttps://github.com/milvus-io/milvushttps://www.pinecone.io/https://github.com/qdrant/qdranthttps://github.com/type\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > chain:format_inputs > chain:RunnableParallel<context>] [2ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"context\": \"向量数据库\\n\\n\\n\\n主页\\n\\n& SDK对比上面的因素选择，API & SDK 可能是往往被忽略的因素，但是在实际的业务场景中，API & SDK 往往是开发者最关心的因素。因为 API & SDK 的设计直接影响了开发者的开发效率和使用体验。一个优秀良好的 API & SDK 设计，往往能够适应需求的不同变化，向量数据库是一个新的领域，在如今大部分人不太清楚这方面需求的当下，这一点容易被人忽视。选型截至目前，汇总到目前的向量数据库有以下几种选择：向量数据库URLGitHub StarLanguageCloudchromahttps://github.com/chroma-core/chroma7.4KPython❌milvushttps://github.com/milvus-io/milvus21.5KGo/Python/C++✅pineconehttps://www.pinecone.io/❌❌✅qdranthttps://github.com/qdrant/qdrant11.8KRust✅typesensehttps://github.com/typesense/typesense12.9KC++❌weaviatehttps://github.com/weaviate/weaviate6.9KGo✅传统数据的扩展除了选择专业的向量数据库，使用传统数据库进行扩展也是一种方法。类似 Redis 除了传统的 Key Value 数据库用途外，Redis 还提供了 Redis Modules，这是一种通过新功能、命令和数据类型扩展 Redis 的方式。例如使用 RediSearch 模块来扩展向量搜索的功能。同理的还有 PostgreSQL 的扩展，PostgreSQL 提供使用 extension 的方式来扩展数据库的功能，例如 pgvector 来开启向量搜索的功能。它不仅支持精确和相似性搜索，还支持余弦相似度等相似性测量算法。最重要的是，它是附加在 PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub\\n\\nPostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub 目前就暂时使用 pgvector 来实现向量搜索以实现 GPT 文档问答，基于 Supabase 提供的 PostgreSQL + pgvector 服务完成。总结本文主要介绍了向量数据库的原理和实现，包括向量数据库的基本概念、相似性搜索算法、相似性测量算法、过滤算法和向量数据库的选型等等。向量数据库是崭新的领域，目前大部分向量数据库公司的估值乘着 AI 和 GPT\\n\\n的东风从而飞速的增长，但是在实际的业务场景中，目前向量数据库的应用场景还比较少，抛开浮躁的外衣，向量数据库的应用场景还需要开发者们和业务专家们去挖掘。Referenceshttps://www.bilibili.com/video/BV11a4y1c7SWhttps://www.bilibili.com/video/BV1BM4y177Dkhttps://www.pinecone.io/learn/vector-database/https://github.com/guangzhengli/ChatFileshttps://github.com/guangzhengli/vectorhubhttps://www.anthropic.com/index/100k-context-windowshttps://js.langchain.com/docs/https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing/https://www.pinecone.io/learn/series/faiss/product-quantization/https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing-random-projection/https://www.youtube.com/watch?v=QvKMwLjdK-s&t=168s&ab_channel=JamesBriggshttps://www.pinecone.io/learn/series/faiss/faiss-tutorial/https://www.youtube.com/watch?v=sKyvsdEv6rk&ab_channel=JamesBriggshttps://www.pinecone.io/learn/vector-similarity/https://github.com/chroma-core/chromahttps://github.com/milvus-io/milvushttps://www.pinecone.io/https://github.com/qdrant/qdranthttps://github.com/type\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > chain:format_inputs] [3ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库是什么\",\n",
      "  \"chat_history\": [],\n",
      "  \"context\": \"向量数据库\\n\\n\\n\\n主页\\n\\n& SDK对比上面的因素选择，API & SDK 可能是往往被忽略的因素，但是在实际的业务场景中，API & SDK 往往是开发者最关心的因素。因为 API & SDK 的设计直接影响了开发者的开发效率和使用体验。一个优秀良好的 API & SDK 设计，往往能够适应需求的不同变化，向量数据库是一个新的领域，在如今大部分人不太清楚这方面需求的当下，这一点容易被人忽视。选型截至目前，汇总到目前的向量数据库有以下几种选择：向量数据库URLGitHub StarLanguageCloudchromahttps://github.com/chroma-core/chroma7.4KPython❌milvushttps://github.com/milvus-io/milvus21.5KGo/Python/C++✅pineconehttps://www.pinecone.io/❌❌✅qdranthttps://github.com/qdrant/qdrant11.8KRust✅typesensehttps://github.com/typesense/typesense12.9KC++❌weaviatehttps://github.com/weaviate/weaviate6.9KGo✅传统数据的扩展除了选择专业的向量数据库，使用传统数据库进行扩展也是一种方法。类似 Redis 除了传统的 Key Value 数据库用途外，Redis 还提供了 Redis Modules，这是一种通过新功能、命令和数据类型扩展 Redis 的方式。例如使用 RediSearch 模块来扩展向量搜索的功能。同理的还有 PostgreSQL 的扩展，PostgreSQL 提供使用 extension 的方式来扩展数据库的功能，例如 pgvector 来开启向量搜索的功能。它不仅支持精确和相似性搜索，还支持余弦相似度等相似性测量算法。最重要的是，它是附加在 PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub\\n\\nPostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub 目前就暂时使用 pgvector 来实现向量搜索以实现 GPT 文档问答，基于 Supabase 提供的 PostgreSQL + pgvector 服务完成。总结本文主要介绍了向量数据库的原理和实现，包括向量数据库的基本概念、相似性搜索算法、相似性测量算法、过滤算法和向量数据库的选型等等。向量数据库是崭新的领域，目前大部分向量数据库公司的估值乘着 AI 和 GPT\\n\\n的东风从而飞速的增长，但是在实际的业务场景中，目前向量数据库的应用场景还比较少，抛开浮躁的外衣，向量数据库的应用场景还需要开发者们和业务专家们去挖掘。Referenceshttps://www.bilibili.com/video/BV11a4y1c7SWhttps://www.bilibili.com/video/BV1BM4y177Dkhttps://www.pinecone.io/learn/vector-database/https://github.com/guangzhengli/ChatFileshttps://github.com/guangzhengli/vectorhubhttps://www.anthropic.com/index/100k-context-windowshttps://js.langchain.com/docs/https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing/https://www.pinecone.io/learn/series/faiss/product-quantization/https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing-random-projection/https://www.youtube.com/watch?v=QvKMwLjdK-s&t=168s&ab_channel=JamesBriggshttps://www.pinecone.io/learn/series/faiss/faiss-tutorial/https://www.youtube.com/watch?v=sKyvsdEv6rk&ab_channel=JamesBriggshttps://www.pinecone.io/learn/vector-similarity/https://github.com/chroma-core/chromahttps://github.com/milvus-io/milvushttps://www.pinecone.io/https://github.com/qdrant/qdranthttps://github.com/type\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库是什么\",\n",
      "  \"chat_history\": [],\n",
      "  \"context\": \"向量数据库\\n\\n\\n\\n主页\\n\\n& SDK对比上面的因素选择，API & SDK 可能是往往被忽略的因素，但是在实际的业务场景中，API & SDK 往往是开发者最关心的因素。因为 API & SDK 的设计直接影响了开发者的开发效率和使用体验。一个优秀良好的 API & SDK 设计，往往能够适应需求的不同变化，向量数据库是一个新的领域，在如今大部分人不太清楚这方面需求的当下，这一点容易被人忽视。选型截至目前，汇总到目前的向量数据库有以下几种选择：向量数据库URLGitHub StarLanguageCloudchromahttps://github.com/chroma-core/chroma7.4KPython❌milvushttps://github.com/milvus-io/milvus21.5KGo/Python/C++✅pineconehttps://www.pinecone.io/❌❌✅qdranthttps://github.com/qdrant/qdrant11.8KRust✅typesensehttps://github.com/typesense/typesense12.9KC++❌weaviatehttps://github.com/weaviate/weaviate6.9KGo✅传统数据的扩展除了选择专业的向量数据库，使用传统数据库进行扩展也是一种方法。类似 Redis 除了传统的 Key Value 数据库用途外，Redis 还提供了 Redis Modules，这是一种通过新功能、命令和数据类型扩展 Redis 的方式。例如使用 RediSearch 模块来扩展向量搜索的功能。同理的还有 PostgreSQL 的扩展，PostgreSQL 提供使用 extension 的方式来扩展数据库的功能，例如 pgvector 来开启向量搜索的功能。它不仅支持精确和相似性搜索，还支持余弦相似度等相似性测量算法。最重要的是，它是附加在 PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub\\n\\nPostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub 目前就暂时使用 pgvector 来实现向量搜索以实现 GPT 文档问答，基于 Supabase 提供的 PostgreSQL + pgvector 服务完成。总结本文主要介绍了向量数据库的原理和实现，包括向量数据库的基本概念、相似性搜索算法、相似性测量算法、过滤算法和向量数据库的选型等等。向量数据库是崭新的领域，目前大部分向量数据库公司的估值乘着 AI 和 GPT\\n\\n的东风从而飞速的增长，但是在实际的业务场景中，目前向量数据库的应用场景还比较少，抛开浮躁的外衣，向量数据库的应用场景还需要开发者们和业务专家们去挖掘。Referenceshttps://www.bilibili.com/video/BV11a4y1c7SWhttps://www.bilibili.com/video/BV1BM4y177Dkhttps://www.pinecone.io/learn/vector-database/https://github.com/guangzhengli/ChatFileshttps://github.com/guangzhengli/vectorhubhttps://www.anthropic.com/index/100k-context-windowshttps://js.langchain.com/docs/https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing/https://www.pinecone.io/learn/series/faiss/product-quantization/https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing-random-projection/https://www.youtube.com/watch?v=QvKMwLjdK-s&t=168s&ab_channel=JamesBriggshttps://www.pinecone.io/learn/series/faiss/faiss-tutorial/https://www.youtube.com/watch?v=sKyvsdEv6rk&ab_channel=JamesBriggshttps://www.pinecone.io/learn/vector-similarity/https://github.com/chroma-core/chromahttps://github.com/milvus-io/milvushttps://www.pinecone.io/https://github.com/qdrant/qdranthttps://github.com/type\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: \\n你是一个问题回答任务的助理。\\n使用以下检索到的上下文片段来回答问题。\\n如果你不知道答案，说出你不知道。\\n最多使用三个句子，并保持回答简洁。\\n\\n向量数据库\\n\\n\\n\\n主页\\n\\n& SDK对比上面的因素选择，API & SDK 可能是往往被忽略的因素，但是在实际的业务场景中，API & SDK 往往是开发者最关心的因素。因为 API & SDK 的设计直接影响了开发者的开发效率和使用体验。一个优秀良好的 API & SDK 设计，往往能够适应需求的不同变化，向量数据库是一个新的领域，在如今大部分人不太清楚这方面需求的当下，这一点容易被人忽视。选型截至目前，汇总到目前的向量数据库有以下几种选择：向量数据库URLGitHub StarLanguageCloudchromahttps://github.com/chroma-core/chroma7.4KPython❌milvushttps://github.com/milvus-io/milvus21.5KGo/Python/C++✅pineconehttps://www.pinecone.io/❌❌✅qdranthttps://github.com/qdrant/qdrant11.8KRust✅typesensehttps://github.com/typesense/typesense12.9KC++❌weaviatehttps://github.com/weaviate/weaviate6.9KGo✅传统数据的扩展除了选择专业的向量数据库，使用传统数据库进行扩展也是一种方法。类似 Redis 除了传统的 Key Value 数据库用途外，Redis 还提供了 Redis Modules，这是一种通过新功能、命令和数据类型扩展 Redis 的方式。例如使用 RediSearch 模块来扩展向量搜索的功能。同理的还有 PostgreSQL 的扩展，PostgreSQL 提供使用 extension 的方式来扩展数据库的功能，例如 pgvector 来开启向量搜索的功能。它不仅支持精确和相似性搜索，还支持余弦相似度等相似性测量算法。最重要的是，它是附加在 PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub\\n\\nPostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub 目前就暂时使用 pgvector 来实现向量搜索以实现 GPT 文档问答，基于 Supabase 提供的 PostgreSQL + pgvector 服务完成。总结本文主要介绍了向量数据库的原理和实现，包括向量数据库的基本概念、相似性搜索算法、相似性测量算法、过滤算法和向量数据库的选型等等。向量数据库是崭新的领域，目前大部分向量数据库公司的估值乘着 AI 和 GPT\\n\\n的东风从而飞速的增长，但是在实际的业务场景中，目前向量数据库的应用场景还比较少，抛开浮躁的外衣，向量数据库的应用场景还需要开发者们和业务专家们去挖掘。Referenceshttps://www.bilibili.com/video/BV11a4y1c7SWhttps://www.bilibili.com/video/BV1BM4y177Dkhttps://www.pinecone.io/learn/vector-database/https://github.com/guangzhengli/ChatFileshttps://github.com/guangzhengli/vectorhubhttps://www.anthropic.com/index/100k-context-windowshttps://js.langchain.com/docs/https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing/https://www.pinecone.io/learn/series/faiss/product-quantization/https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing-random-projection/https://www.youtube.com/watch?v=QvKMwLjdK-s&t=168s&ab_channel=JamesBriggshttps://www.pinecone.io/learn/series/faiss/faiss-tutorial/https://www.youtube.com/watch?v=sKyvsdEv6rk&ab_channel=JamesBriggshttps://www.pinecone.io/learn/vector-similarity/https://github.com/chroma-core/chromahttps://github.com/milvus-io/milvushttps://www.pinecone.io/https://github.com/qdrant/qdranthttps://github.com/type\\n\\nHuman: 向量数据库是什么\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > llm:ChatOpenAI] [4.12s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"向量数据库是一种专门用于存储和处理向量数据的数据库系统。它们具有专门的算法和数据结构，可以支持向量之间的相似性搜索和相关操作，适用于需要处理大量高维向量数据的场景，如机器学习、推荐系统等。\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"向量数据库是一种专门用于存储和处理向量数据的数据库系统。它们具有专门的算法和数据结构，可以支持向量之间的相似性搜索和相关操作，适用于需要处理大量高维向量数据的场景，如机器学习、推荐系统等。\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 85,\n",
      "                \"prompt_tokens\": 1318,\n",
      "                \"total_tokens\": 1403\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-fd07368f-e997-468a-89c4-309ca60f159a-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 1318,\n",
      "              \"output_tokens\": 85,\n",
      "              \"total_tokens\": 1403\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 85,\n",
      "      \"prompt_tokens\": 1318,\n",
      "      \"total_tokens\": 1403\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"向量数据库是一种专门用于存储和处理向量数据的数据库系统。它们具有专门的算法和数据结构，可以支持向量之间的相似性搜索和相关操作，适用于需要处理大量高维向量数据的场景，如机器学习、推荐系统等。\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain] [4.13s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"向量数据库是一种专门用于存储和处理向量数据的数据库系统。它们具有专门的算法和数据结构，可以支持向量之间的相似性搜索和相关操作，适用于需要处理大量高维向量数据的场景，如机器学习、推荐系统等。\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer>] [4.13s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"answer\": \"向量数据库是一种专门用于存储和处理向量数据的数据库系统。它们具有专门的算法和数据结构，可以支持向量之间的相似性搜索和相关操作，适用于需要处理大量高维向量数据的场景，如机器学习、推荐系统等。\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer>] [4.14s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain] [4.66s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch] [4.76s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"input\": \"向量数据库是什么\",\n",
      "  \"chat_history\": [],\n",
      "  \"context\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"向量数据库\\n\\n\\n\\n主页\",\n",
      "        \"metadata\": {\n",
      "          \"description\": \"Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。\",\n",
      "          \"language\": \"zh\",\n",
      "          \"source\": \"https://guangzhengli.com/blog/zh/vector-database/\",\n",
      "          \"title\": \"向量数据库\"\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"& SDK对比上面的因素选择，API & SDK 可能是往往被忽略的因素，但是在实际的业务场景中，API & SDK 往往是开发者最关心的因素。因为 API & SDK 的设计直接影响了开发者的开发效率和使用体验。一个优秀良好的 API & SDK 设计，往往能够适应需求的不同变化，向量数据库是一个新的领域，在如今大部分人不太清楚这方面需求的当下，这一点容易被人忽视。选型截至目前，汇总到目前的向量数据库有以下几种选择：向量数据库URLGitHub StarLanguageCloudchromahttps://github.com/chroma-core/chroma7.4KPython❌milvushttps://github.com/milvus-io/milvus21.5KGo/Python/C++✅pineconehttps://www.pinecone.io/❌❌✅qdranthttps://github.com/qdrant/qdrant11.8KRust✅typesensehttps://github.com/typesense/typesense12.9KC++❌weaviatehttps://github.com/weaviate/weaviate6.9KGo✅传统数据的扩展除了选择专业的向量数据库，使用传统数据库进行扩展也是一种方法。类似 Redis 除了传统的 Key Value 数据库用途外，Redis 还提供了 Redis Modules，这是一种通过新功能、命令和数据类型扩展 Redis 的方式。例如使用 RediSearch 模块来扩展向量搜索的功能。同理的还有 PostgreSQL 的扩展，PostgreSQL 提供使用 extension 的方式来扩展数据库的功能，例如 pgvector 来开启向量搜索的功能。它不仅支持精确和相似性搜索，还支持余弦相似度等相似性测量算法。最重要的是，它是附加在 PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub\",\n",
      "        \"metadata\": {\n",
      "          \"description\": \"Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。\",\n",
      "          \"language\": \"zh\",\n",
      "          \"source\": \"https://guangzhengli.com/blog/zh/vector-database/\",\n",
      "          \"title\": \"向量数据库\"\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub 目前就暂时使用 pgvector 来实现向量搜索以实现 GPT 文档问答，基于 Supabase 提供的 PostgreSQL + pgvector 服务完成。总结本文主要介绍了向量数据库的原理和实现，包括向量数据库的基本概念、相似性搜索算法、相似性测量算法、过滤算法和向量数据库的选型等等。向量数据库是崭新的领域，目前大部分向量数据库公司的估值乘着 AI 和 GPT\",\n",
      "        \"metadata\": {\n",
      "          \"description\": \"Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。\",\n",
      "          \"language\": \"zh\",\n",
      "          \"source\": \"https://guangzhengli.com/blog/zh/vector-database/\",\n",
      "          \"title\": \"向量数据库\"\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"的东风从而飞速的增长，但是在实际的业务场景中，目前向量数据库的应用场景还比较少，抛开浮躁的外衣，向量数据库的应用场景还需要开发者们和业务专家们去挖掘。Referenceshttps://www.bilibili.com/video/BV11a4y1c7SWhttps://www.bilibili.com/video/BV1BM4y177Dkhttps://www.pinecone.io/learn/vector-database/https://github.com/guangzhengli/ChatFileshttps://github.com/guangzhengli/vectorhubhttps://www.anthropic.com/index/100k-context-windowshttps://js.langchain.com/docs/https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing/https://www.pinecone.io/learn/series/faiss/product-quantization/https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing-random-projection/https://www.youtube.com/watch?v=QvKMwLjdK-s&t=168s&ab_channel=JamesBriggshttps://www.pinecone.io/learn/series/faiss/faiss-tutorial/https://www.youtube.com/watch?v=sKyvsdEv6rk&ab_channel=JamesBriggshttps://www.pinecone.io/learn/vector-similarity/https://github.com/chroma-core/chromahttps://github.com/milvus-io/milvushttps://www.pinecone.io/https://github.com/qdrant/qdranthttps://github.com/type\",\n",
      "        \"metadata\": {\n",
      "          \"description\": \"Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。\",\n",
      "          \"language\": \"zh\",\n",
      "          \"source\": \"https://guangzhengli.com/blog/zh/vector-database/\",\n",
      "          \"title\": \"向量数据库\"\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"answer\": \"向量数据库是一种专门用于存储和处理向量数据的数据库系统。它们具有专门的算法和数据结构，可以支持向量之间的相似性搜索和相关操作，适用于需要处理大量高维向量数据的场景，如机器学习、推荐系统等。\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory] [4.79s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "{'input': '向量数据库是什么', 'chat_history': [], 'context': [Document(page_content='向量数据库\\n\\n\\n\\n主页', metadata={'description': 'Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。', 'language': 'zh', 'source': 'https://guangzhengli.com/blog/zh/vector-database/', 'title': '向量数据库'}), Document(page_content='& SDK对比上面的因素选择，API & SDK 可能是往往被忽略的因素，但是在实际的业务场景中，API & SDK 往往是开发者最关心的因素。因为 API & SDK 的设计直接影响了开发者的开发效率和使用体验。一个优秀良好的 API & SDK 设计，往往能够适应需求的不同变化，向量数据库是一个新的领域，在如今大部分人不太清楚这方面需求的当下，这一点容易被人忽视。选型截至目前，汇总到目前的向量数据库有以下几种选择：向量数据库URLGitHub StarLanguageCloudchromahttps://github.com/chroma-core/chroma7.4KPython❌milvushttps://github.com/milvus-io/milvus21.5KGo/Python/C++✅pineconehttps://www.pinecone.io/❌❌✅qdranthttps://github.com/qdrant/qdrant11.8KRust✅typesensehttps://github.com/typesense/typesense12.9KC++❌weaviatehttps://github.com/weaviate/weaviate6.9KGo✅传统数据的扩展除了选择专业的向量数据库，使用传统数据库进行扩展也是一种方法。类似 Redis 除了传统的 Key Value 数据库用途外，Redis 还提供了 Redis Modules，这是一种通过新功能、命令和数据类型扩展 Redis 的方式。例如使用 RediSearch 模块来扩展向量搜索的功能。同理的还有 PostgreSQL 的扩展，PostgreSQL 提供使用 extension 的方式来扩展数据库的功能，例如 pgvector 来开启向量搜索的功能。它不仅支持精确和相似性搜索，还支持余弦相似度等相似性测量算法。最重要的是，它是附加在 PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub', metadata={'description': 'Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。', 'language': 'zh', 'source': 'https://guangzhengli.com/blog/zh/vector-database/', 'title': '向量数据库'}), Document(page_content='PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub 目前就暂时使用 pgvector 来实现向量搜索以实现 GPT 文档问答，基于 Supabase 提供的 PostgreSQL + pgvector 服务完成。总结本文主要介绍了向量数据库的原理和实现，包括向量数据库的基本概念、相似性搜索算法、相似性测量算法、过滤算法和向量数据库的选型等等。向量数据库是崭新的领域，目前大部分向量数据库公司的估值乘着 AI 和 GPT', metadata={'description': 'Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。', 'language': 'zh', 'source': 'https://guangzhengli.com/blog/zh/vector-database/', 'title': '向量数据库'}), Document(page_content='的东风从而飞速的增长，但是在实际的业务场景中，目前向量数据库的应用场景还比较少，抛开浮躁的外衣，向量数据库的应用场景还需要开发者们和业务专家们去挖掘。Referenceshttps://www.bilibili.com/video/BV11a4y1c7SWhttps://www.bilibili.com/video/BV1BM4y177Dkhttps://www.pinecone.io/learn/vector-database/https://github.com/guangzhengli/ChatFileshttps://github.com/guangzhengli/vectorhubhttps://www.anthropic.com/index/100k-context-windowshttps://js.langchain.com/docs/https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing/https://www.pinecone.io/learn/series/faiss/product-quantization/https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing-random-projection/https://www.youtube.com/watch?v=QvKMwLjdK-s&t=168s&ab_channel=JamesBriggshttps://www.pinecone.io/learn/series/faiss/faiss-tutorial/https://www.youtube.com/watch?v=sKyvsdEv6rk&ab_channel=JamesBriggshttps://www.pinecone.io/learn/vector-similarity/https://github.com/chroma-core/chromahttps://github.com/milvus-io/milvushttps://www.pinecone.io/https://github.com/qdrant/qdranthttps://github.com/type', metadata={'description': 'Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。', 'language': 'zh', 'source': 'https://guangzhengli.com/blog/zh/vector-database/', 'title': '向量数据库'})], 'answer': '向量数据库是一种专门用于存储和处理向量数据的数据库系统。它们具有专门的算法和数据结构，可以支持向量之间的相似性搜索和相关操作，适用于需要处理大量高维向量数据的场景，如机器学习、推荐系统等。'}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:01:00.350592Z",
     "start_time": "2024-07-18T14:00:53.519423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## 再次对话，会结合对话历史，答案形成一个新的问题，然后在用retrieve检索。\n",
    "res = conversational_rag_chain.invoke(\n",
    "    {\"input\": \"他的特点是什么？\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")"
   ],
   "id": "b8bcc99f0b5de3c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"他的特点是什么？\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:insert_history] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"他的特点是什么？\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:insert_history > chain:RunnableParallel<chat_history>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"他的特点是什么？\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:insert_history > chain:RunnableParallel<chat_history> > chain:load_history] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"他的特点是什么？\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:insert_history > chain:RunnableParallel<chat_history> > chain:load_history] [0ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:insert_history > chain:RunnableParallel<chat_history>] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:insert_history] [3ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:RunnableWithMessageHistoryInAsyncMode] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:RunnableWithMessageHistoryInAsyncMode] [0ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": false\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context>] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context>] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": false\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: \\n给你一个聊天历史和最新的用户问题，这个问题可能会引用聊天历史中的内容,如果聊天历史中有相关的内容，\\n需要结合聊天内容，形成一个独立的问题，如果没有，原样复述。不要解释输出的内容，\\n也不要尝试回答问题，否则你会受到惩罚。\\n\\nHuman: 向量数据库是什么\\nAI: 向量数据库是一种专门用于存储和处理向量数据的数据库系统。它们具有专门的算法和数据结构，可以支持向量之间的相似性搜索和相关操作，适用于需要处理大量高维向量数据的场景，如机器学习、推荐系统等。\\nHuman: 他的特点是什么？\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableSequence > llm:ChatOpenAI] [2.28s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"向量数据库的特点包括高效的向量相似性搜索、支持高维向量数据、能够处理大规模数据集、具有快速的索引和查询速度等。\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"向量数据库的特点包括高效的向量相似性搜索、支持高维向量数据、能够处理大规模数据集、具有快速的索引和查询速度等。\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 53,\n",
      "                \"prompt_tokens\": 224,\n",
      "                \"total_tokens\": 277\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-bbe127d1-7708-4c66-8b1f-c478489a6bc5-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 224,\n",
      "              \"output_tokens\": 53,\n",
      "              \"total_tokens\": 277\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 53,\n",
      "      \"prompt_tokens\": 224,\n",
      "      \"total_tokens\": 277\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableSequence > parser:StrOutputParser] [2ms] Exiting Parser run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"向量数据库的特点包括高效的向量相似性搜索、支持高维向量数据、能够处理大规模数据集、具有快速的索引和查询速度等。\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents > chain:RunnableSequence] [4.02s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:retrieve_documents] [4.03s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"ID、文档 ID 等信息。这样就可以在搜索的时候，根据元数据来过滤搜索结果，从而得到最终的结果。为此，向量数据库通常维护两个索引：一个是向量索引，另一个是元数据索引。然后，在进行相似性搜索本身之前或之后执行元数据过滤，但无论哪种情况下，都存在导致查询过程变慢的困难。过滤过程可以在向量搜索本身之前或之后执行，但每种方法都有自己的挑战，可能会影响查询性能：Pre-filtering：在向量搜索之前进行元数据过滤。虽然这可以帮助减少搜索空间，但也可能导致系统忽略与元数据筛选标准不匹配的相关结果。Post-filtering：在向量搜索完成后进行元数据过滤。这可以确保考虑所有相关结果，在搜索完成后将不相关的结果进行筛选。为了优化过滤流程，向量数据库使用各种技术，例如利用先进的索引方法来处理元数据或使用并行处理来加速过滤任务。平衡搜索性能和筛选精度之间的权衡对于提供高效且相关的向量数据库查询结果至关重要。向量数据库选型笔者在本文中，花费了大量的笔墨来介绍向量数据库的相似性搜索算法的原理和实现，相似性搜索算法固然是一个向量数据库的核心和关键点，但是在实际的业务场景中，往往还需要考虑其它的因素，例如向量数据库的可用性、扩展性、安全性等，还有代码是否开源、社区是否活跃等等。分布式一个成熟的向量数据库，往往需要支持分布式部署，这样才能满足大规模数据的存储和查询。数据拥有的越多，需要节点就越多，出现的错误和故障也就越多，所以分布式的向量数据库需要具备高可用性和容错性。数据库的高可用性和容错性，往往需要实现分片和复制能力，在传统的数据库中，往往通过数据的主键或者根据业务需求进行分片，但是在分布式的向量数据库中，就需要考虑根据向量的相似性进行分区，以便查询的时候能够保证结果的质量和速度。其它类似复制节点数据的一致性、数据的安全性等等，都是分布式向量数据库需要考虑的因素。访问控制和备份除此之外，访问控制设计的是否充足，例如当组织和业务快速发展时，是否能够快速的添加新的用户和权限控制，是否能够快速的添加新的节点，审计日志是否完善等等，都是需要考虑的因素。另外，数据库的监控和备份也是一个重要的因素，当数据出现故障时，能够快速的定位问题和恢复数据，是一个成熟的向量数据库必须要考虑的因素。API & SDK对比上面的因素选择，API & SDK\",\n",
      "        \"metadata\": {\n",
      "          \"description\": \"Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。\",\n",
      "          \"language\": \"zh\",\n",
      "          \"source\": \"https://guangzhengli.com/blog/zh/vector-database/\",\n",
      "          \"title\": \"向量数据库\"\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub 目前就暂时使用 pgvector 来实现向量搜索以实现 GPT 文档问答，基于 Supabase 提供的 PostgreSQL + pgvector 服务完成。总结本文主要介绍了向量数据库的原理和实现，包括向量数据库的基本概念、相似性搜索算法、相似性测量算法、过滤算法和向量数据库的选型等等。向量数据库是崭新的领域，目前大部分向量数据库公司的估值乘着 AI 和 GPT\",\n",
      "        \"metadata\": {\n",
      "          \"description\": \"Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。\",\n",
      "          \"language\": \"zh\",\n",
      "          \"source\": \"https://guangzhengli.com/blog/zh/vector-database/\",\n",
      "          \"title\": \"向量数据库\"\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"& SDK对比上面的因素选择，API & SDK 可能是往往被忽略的因素，但是在实际的业务场景中，API & SDK 往往是开发者最关心的因素。因为 API & SDK 的设计直接影响了开发者的开发效率和使用体验。一个优秀良好的 API & SDK 设计，往往能够适应需求的不同变化，向量数据库是一个新的领域，在如今大部分人不太清楚这方面需求的当下，这一点容易被人忽视。选型截至目前，汇总到目前的向量数据库有以下几种选择：向量数据库URLGitHub StarLanguageCloudchromahttps://github.com/chroma-core/chroma7.4KPython❌milvushttps://github.com/milvus-io/milvus21.5KGo/Python/C++✅pineconehttps://www.pinecone.io/❌❌✅qdranthttps://github.com/qdrant/qdrant11.8KRust✅typesensehttps://github.com/typesense/typesense12.9KC++❌weaviatehttps://github.com/weaviate/weaviate6.9KGo✅传统数据的扩展除了选择专业的向量数据库，使用传统数据库进行扩展也是一种方法。类似 Redis 除了传统的 Key Value 数据库用途外，Redis 还提供了 Redis Modules，这是一种通过新功能、命令和数据类型扩展 Redis 的方式。例如使用 RediSearch 模块来扩展向量搜索的功能。同理的还有 PostgreSQL 的扩展，PostgreSQL 提供使用 extension 的方式来扩展数据库的功能，例如 pgvector 来开启向量搜索的功能。它不仅支持精确和相似性搜索，还支持余弦相似度等相似性测量算法。最重要的是，它是附加在 PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub\",\n",
      "        \"metadata\": {\n",
      "          \"description\": \"Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。\",\n",
      "          \"language\": \"zh\",\n",
      "          \"source\": \"https://guangzhengli.com/blog/zh/vector-database/\",\n",
      "          \"title\": \"向量数据库\"\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"向量数据库\\n\\n\\n\\n主页\",\n",
      "        \"metadata\": {\n",
      "          \"description\": \"Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。\",\n",
      "          \"language\": \"zh\",\n",
      "          \"source\": \"https://guangzhengli.com/blog/zh/vector-database/\",\n",
      "          \"title\": \"向量数据库\"\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context> > chain:RunnableParallel<context>] [4.03s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<context>] [4.03s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer>] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer>] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > chain:format_inputs] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > chain:format_inputs > chain:RunnableParallel<context>] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > chain:format_inputs > chain:RunnableParallel<context> > chain:format_docs] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > chain:format_inputs > chain:RunnableParallel<context> > chain:format_docs] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"ID、文档 ID 等信息。这样就可以在搜索的时候，根据元数据来过滤搜索结果，从而得到最终的结果。为此，向量数据库通常维护两个索引：一个是向量索引，另一个是元数据索引。然后，在进行相似性搜索本身之前或之后执行元数据过滤，但无论哪种情况下，都存在导致查询过程变慢的困难。过滤过程可以在向量搜索本身之前或之后执行，但每种方法都有自己的挑战，可能会影响查询性能：Pre-filtering：在向量搜索之前进行元数据过滤。虽然这可以帮助减少搜索空间，但也可能导致系统忽略与元数据筛选标准不匹配的相关结果。Post-filtering：在向量搜索完成后进行元数据过滤。这可以确保考虑所有相关结果，在搜索完成后将不相关的结果进行筛选。为了优化过滤流程，向量数据库使用各种技术，例如利用先进的索引方法来处理元数据或使用并行处理来加速过滤任务。平衡搜索性能和筛选精度之间的权衡对于提供高效且相关的向量数据库查询结果至关重要。向量数据库选型笔者在本文中，花费了大量的笔墨来介绍向量数据库的相似性搜索算法的原理和实现，相似性搜索算法固然是一个向量数据库的核心和关键点，但是在实际的业务场景中，往往还需要考虑其它的因素，例如向量数据库的可用性、扩展性、安全性等，还有代码是否开源、社区是否活跃等等。分布式一个成熟的向量数据库，往往需要支持分布式部署，这样才能满足大规模数据的存储和查询。数据拥有的越多，需要节点就越多，出现的错误和故障也就越多，所以分布式的向量数据库需要具备高可用性和容错性。数据库的高可用性和容错性，往往需要实现分片和复制能力，在传统的数据库中，往往通过数据的主键或者根据业务需求进行分片，但是在分布式的向量数据库中，就需要考虑根据向量的相似性进行分区，以便查询的时候能够保证结果的质量和速度。其它类似复制节点数据的一致性、数据的安全性等等，都是分布式向量数据库需要考虑的因素。访问控制和备份除此之外，访问控制设计的是否充足，例如当组织和业务快速发展时，是否能够快速的添加新的用户和权限控制，是否能够快速的添加新的节点，审计日志是否完善等等，都是需要考虑的因素。另外，数据库的监控和备份也是一个重要的因素，当数据出现故障时，能够快速的定位问题和恢复数据，是一个成熟的向量数据库必须要考虑的因素。API & SDK对比上面的因素选择，API & SDK\\n\\nPostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub 目前就暂时使用 pgvector 来实现向量搜索以实现 GPT 文档问答，基于 Supabase 提供的 PostgreSQL + pgvector 服务完成。总结本文主要介绍了向量数据库的原理和实现，包括向量数据库的基本概念、相似性搜索算法、相似性测量算法、过滤算法和向量数据库的选型等等。向量数据库是崭新的领域，目前大部分向量数据库公司的估值乘着 AI 和 GPT\\n\\n& SDK对比上面的因素选择，API & SDK 可能是往往被忽略的因素，但是在实际的业务场景中，API & SDK 往往是开发者最关心的因素。因为 API & SDK 的设计直接影响了开发者的开发效率和使用体验。一个优秀良好的 API & SDK 设计，往往能够适应需求的不同变化，向量数据库是一个新的领域，在如今大部分人不太清楚这方面需求的当下，这一点容易被人忽视。选型截至目前，汇总到目前的向量数据库有以下几种选择：向量数据库URLGitHub StarLanguageCloudchromahttps://github.com/chroma-core/chroma7.4KPython❌milvushttps://github.com/milvus-io/milvus21.5KGo/Python/C++✅pineconehttps://www.pinecone.io/❌❌✅qdranthttps://github.com/qdrant/qdrant11.8KRust✅typesensehttps://github.com/typesense/typesense12.9KC++❌weaviatehttps://github.com/weaviate/weaviate6.9KGo✅传统数据的扩展除了选择专业的向量数据库，使用传统数据库进行扩展也是一种方法。类似 Redis 除了传统的 Key Value 数据库用途外，Redis 还提供了 Redis Modules，这是一种通过新功能、命令和数据类型扩展 Redis 的方式。例如使用 RediSearch 模块来扩展向量搜索的功能。同理的还有 PostgreSQL 的扩展，PostgreSQL 提供使用 extension 的方式来扩展数据库的功能，例如 pgvector 来开启向量搜索的功能。它不仅支持精确和相似性搜索，还支持余弦相似度等相似性测量算法。最重要的是，它是附加在 PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub\\n\\n向量数据库\\n\\n\\n\\n主页\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > chain:format_inputs > chain:RunnableParallel<context>] [2ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"context\": \"ID、文档 ID 等信息。这样就可以在搜索的时候，根据元数据来过滤搜索结果，从而得到最终的结果。为此，向量数据库通常维护两个索引：一个是向量索引，另一个是元数据索引。然后，在进行相似性搜索本身之前或之后执行元数据过滤，但无论哪种情况下，都存在导致查询过程变慢的困难。过滤过程可以在向量搜索本身之前或之后执行，但每种方法都有自己的挑战，可能会影响查询性能：Pre-filtering：在向量搜索之前进行元数据过滤。虽然这可以帮助减少搜索空间，但也可能导致系统忽略与元数据筛选标准不匹配的相关结果。Post-filtering：在向量搜索完成后进行元数据过滤。这可以确保考虑所有相关结果，在搜索完成后将不相关的结果进行筛选。为了优化过滤流程，向量数据库使用各种技术，例如利用先进的索引方法来处理元数据或使用并行处理来加速过滤任务。平衡搜索性能和筛选精度之间的权衡对于提供高效且相关的向量数据库查询结果至关重要。向量数据库选型笔者在本文中，花费了大量的笔墨来介绍向量数据库的相似性搜索算法的原理和实现，相似性搜索算法固然是一个向量数据库的核心和关键点，但是在实际的业务场景中，往往还需要考虑其它的因素，例如向量数据库的可用性、扩展性、安全性等，还有代码是否开源、社区是否活跃等等。分布式一个成熟的向量数据库，往往需要支持分布式部署，这样才能满足大规模数据的存储和查询。数据拥有的越多，需要节点就越多，出现的错误和故障也就越多，所以分布式的向量数据库需要具备高可用性和容错性。数据库的高可用性和容错性，往往需要实现分片和复制能力，在传统的数据库中，往往通过数据的主键或者根据业务需求进行分片，但是在分布式的向量数据库中，就需要考虑根据向量的相似性进行分区，以便查询的时候能够保证结果的质量和速度。其它类似复制节点数据的一致性、数据的安全性等等，都是分布式向量数据库需要考虑的因素。访问控制和备份除此之外，访问控制设计的是否充足，例如当组织和业务快速发展时，是否能够快速的添加新的用户和权限控制，是否能够快速的添加新的节点，审计日志是否完善等等，都是需要考虑的因素。另外，数据库的监控和备份也是一个重要的因素，当数据出现故障时，能够快速的定位问题和恢复数据，是一个成熟的向量数据库必须要考虑的因素。API & SDK对比上面的因素选择，API & SDK\\n\\nPostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub 目前就暂时使用 pgvector 来实现向量搜索以实现 GPT 文档问答，基于 Supabase 提供的 PostgreSQL + pgvector 服务完成。总结本文主要介绍了向量数据库的原理和实现，包括向量数据库的基本概念、相似性搜索算法、相似性测量算法、过滤算法和向量数据库的选型等等。向量数据库是崭新的领域，目前大部分向量数据库公司的估值乘着 AI 和 GPT\\n\\n& SDK对比上面的因素选择，API & SDK 可能是往往被忽略的因素，但是在实际的业务场景中，API & SDK 往往是开发者最关心的因素。因为 API & SDK 的设计直接影响了开发者的开发效率和使用体验。一个优秀良好的 API & SDK 设计，往往能够适应需求的不同变化，向量数据库是一个新的领域，在如今大部分人不太清楚这方面需求的当下，这一点容易被人忽视。选型截至目前，汇总到目前的向量数据库有以下几种选择：向量数据库URLGitHub StarLanguageCloudchromahttps://github.com/chroma-core/chroma7.4KPython❌milvushttps://github.com/milvus-io/milvus21.5KGo/Python/C++✅pineconehttps://www.pinecone.io/❌❌✅qdranthttps://github.com/qdrant/qdrant11.8KRust✅typesensehttps://github.com/typesense/typesense12.9KC++❌weaviatehttps://github.com/weaviate/weaviate6.9KGo✅传统数据的扩展除了选择专业的向量数据库，使用传统数据库进行扩展也是一种方法。类似 Redis 除了传统的 Key Value 数据库用途外，Redis 还提供了 Redis Modules，这是一种通过新功能、命令和数据类型扩展 Redis 的方式。例如使用 RediSearch 模块来扩展向量搜索的功能。同理的还有 PostgreSQL 的扩展，PostgreSQL 提供使用 extension 的方式来扩展数据库的功能，例如 pgvector 来开启向量搜索的功能。它不仅支持精确和相似性搜索，还支持余弦相似度等相似性测量算法。最重要的是，它是附加在 PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub\\n\\n向量数据库\\n\\n\\n\\n主页\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > chain:format_inputs] [3ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: \\n你是一个问题回答任务的助理。\\n使用以下检索到的上下文片段来回答问题。\\n如果你不知道答案，说出你不知道。\\n最多使用三个句子，并保持回答简洁。\\n\\nID、文档 ID 等信息。这样就可以在搜索的时候，根据元数据来过滤搜索结果，从而得到最终的结果。为此，向量数据库通常维护两个索引：一个是向量索引，另一个是元数据索引。然后，在进行相似性搜索本身之前或之后执行元数据过滤，但无论哪种情况下，都存在导致查询过程变慢的困难。过滤过程可以在向量搜索本身之前或之后执行，但每种方法都有自己的挑战，可能会影响查询性能：Pre-filtering：在向量搜索之前进行元数据过滤。虽然这可以帮助减少搜索空间，但也可能导致系统忽略与元数据筛选标准不匹配的相关结果。Post-filtering：在向量搜索完成后进行元数据过滤。这可以确保考虑所有相关结果，在搜索完成后将不相关的结果进行筛选。为了优化过滤流程，向量数据库使用各种技术，例如利用先进的索引方法来处理元数据或使用并行处理来加速过滤任务。平衡搜索性能和筛选精度之间的权衡对于提供高效且相关的向量数据库查询结果至关重要。向量数据库选型笔者在本文中，花费了大量的笔墨来介绍向量数据库的相似性搜索算法的原理和实现，相似性搜索算法固然是一个向量数据库的核心和关键点，但是在实际的业务场景中，往往还需要考虑其它的因素，例如向量数据库的可用性、扩展性、安全性等，还有代码是否开源、社区是否活跃等等。分布式一个成熟的向量数据库，往往需要支持分布式部署，这样才能满足大规模数据的存储和查询。数据拥有的越多，需要节点就越多，出现的错误和故障也就越多，所以分布式的向量数据库需要具备高可用性和容错性。数据库的高可用性和容错性，往往需要实现分片和复制能力，在传统的数据库中，往往通过数据的主键或者根据业务需求进行分片，但是在分布式的向量数据库中，就需要考虑根据向量的相似性进行分区，以便查询的时候能够保证结果的质量和速度。其它类似复制节点数据的一致性、数据的安全性等等，都是分布式向量数据库需要考虑的因素。访问控制和备份除此之外，访问控制设计的是否充足，例如当组织和业务快速发展时，是否能够快速的添加新的用户和权限控制，是否能够快速的添加新的节点，审计日志是否完善等等，都是需要考虑的因素。另外，数据库的监控和备份也是一个重要的因素，当数据出现故障时，能够快速的定位问题和恢复数据，是一个成熟的向量数据库必须要考虑的因素。API & SDK对比上面的因素选择，API & SDK\\n\\nPostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub 目前就暂时使用 pgvector 来实现向量搜索以实现 GPT 文档问答，基于 Supabase 提供的 PostgreSQL + pgvector 服务完成。总结本文主要介绍了向量数据库的原理和实现，包括向量数据库的基本概念、相似性搜索算法、相似性测量算法、过滤算法和向量数据库的选型等等。向量数据库是崭新的领域，目前大部分向量数据库公司的估值乘着 AI 和 GPT\\n\\n& SDK对比上面的因素选择，API & SDK 可能是往往被忽略的因素，但是在实际的业务场景中，API & SDK 往往是开发者最关心的因素。因为 API & SDK 的设计直接影响了开发者的开发效率和使用体验。一个优秀良好的 API & SDK 设计，往往能够适应需求的不同变化，向量数据库是一个新的领域，在如今大部分人不太清楚这方面需求的当下，这一点容易被人忽视。选型截至目前，汇总到目前的向量数据库有以下几种选择：向量数据库URLGitHub StarLanguageCloudchromahttps://github.com/chroma-core/chroma7.4KPython❌milvushttps://github.com/milvus-io/milvus21.5KGo/Python/C++✅pineconehttps://www.pinecone.io/❌❌✅qdranthttps://github.com/qdrant/qdrant11.8KRust✅typesensehttps://github.com/typesense/typesense12.9KC++❌weaviatehttps://github.com/weaviate/weaviate6.9KGo✅传统数据的扩展除了选择专业的向量数据库，使用传统数据库进行扩展也是一种方法。类似 Redis 除了传统的 Key Value 数据库用途外，Redis 还提供了 Redis Modules，这是一种通过新功能、命令和数据类型扩展 Redis 的方式。例如使用 RediSearch 模块来扩展向量搜索的功能。同理的还有 PostgreSQL 的扩展，PostgreSQL 提供使用 extension 的方式来扩展数据库的功能，例如 pgvector 来开启向量搜索的功能。它不仅支持精确和相似性搜索，还支持余弦相似度等相似性测量算法。最重要的是，它是附加在 PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub\\n\\n向量数据库\\n\\n\\n\\n主页\\n\\nHuman: 向量数据库是什么\\nAI: 向量数据库是一种专门用于存储和处理向量数据的数据库系统。它们具有专门的算法和数据结构，可以支持向量之间的相似性搜索和相关操作，适用于需要处理大量高维向量数据的场景，如机器学习、推荐系统等。\\nHuman: 他的特点是什么？\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > llm:ChatOpenAI] [2.70s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"向量数据库具有以下特点：\\n1. 支持高效的相似性搜索：能够快速准确地找到与查询向量最相似的向量数据。\\n2. 提供专门的数据结构和算法：针对向量数据的特点进行优化，以提高查询性能和准确度。\\n3. 支持高维向量数据：能够处理大规模的高维向量数据，适用于各种复杂的数据分析和应用场景。\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"向量数据库具有以下特点：\\n1. 支持高效的相似性搜索：能够快速准确地找到与查询向量最相似的向量数据。\\n2. 提供专门的数据结构和算法：针对向量数据的特点进行优化，以提高查询性能和准确度。\\n3. 支持高维向量数据：能够处理大规模的高维向量数据，适用于各种复杂的数据分析和应用场景。\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 134,\n",
      "                \"prompt_tokens\": 1978,\n",
      "                \"total_tokens\": 2112\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-65139bff-f369-4df6-8518-b1097a9de954-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 1978,\n",
      "              \"output_tokens\": 134,\n",
      "              \"total_tokens\": 2112\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 134,\n",
      "      \"prompt_tokens\": 1978,\n",
      "      \"total_tokens\": 2112\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain > parser:StrOutputParser] [2ms] Exiting Parser run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"向量数据库具有以下特点：\\n1. 支持高效的相似性搜索：能够快速准确地找到与查询向量最相似的向量数据。\\n2. 提供专门的数据结构和算法：针对向量数据的特点进行优化，以提高查询性能和准确度。\\n3. 支持高维向量数据：能够处理大规模的高维向量数据，适用于各种复杂的数据分析和应用场景。\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer> > chain:stuff_documents_chain] [2.72s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"向量数据库具有以下特点：\\n1. 支持高效的相似性搜索：能够快速准确地找到与查询向量最相似的向量数据。\\n2. 提供专门的数据结构和算法：针对向量数据的特点进行优化，以提高查询性能和准确度。\\n3. 支持高维向量数据：能够处理大规模的高维向量数据，适用于各种复杂的数据分析和应用场景。\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer> > chain:RunnableParallel<answer>] [2.72s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"answer\": \"向量数据库具有以下特点：\\n1. 支持高效的相似性搜索：能够快速准确地找到与查询向量最相似的向量数据。\\n2. 提供专门的数据结构和算法：针对向量数据的特点进行优化，以提高查询性能和准确度。\\n3. 支持高维向量数据：能够处理大规模的高维向量数据，适用于各种复杂的数据分析和应用场景。\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain > chain:RunnableAssign<answer>] [2.73s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch > chain:retrieval_chain] [6.77s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory > chain:RunnableBranch] [6.78s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"input\": \"他的特点是什么？\",\n",
      "  \"chat_history\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"HumanMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"向量数据库是什么\",\n",
      "        \"type\": \"human\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"向量数据库是一种专门用于存储和处理向量数据的数据库系统。它们具有专门的算法和数据结构，可以支持向量之间的相似性搜索和相关操作，适用于需要处理大量高维向量数据的场景，如机器学习、推荐系统等。\",\n",
      "        \"type\": \"ai\",\n",
      "        \"tool_calls\": [],\n",
      "        \"invalid_tool_calls\": []\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"context\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"ID、文档 ID 等信息。这样就可以在搜索的时候，根据元数据来过滤搜索结果，从而得到最终的结果。为此，向量数据库通常维护两个索引：一个是向量索引，另一个是元数据索引。然后，在进行相似性搜索本身之前或之后执行元数据过滤，但无论哪种情况下，都存在导致查询过程变慢的困难。过滤过程可以在向量搜索本身之前或之后执行，但每种方法都有自己的挑战，可能会影响查询性能：Pre-filtering：在向量搜索之前进行元数据过滤。虽然这可以帮助减少搜索空间，但也可能导致系统忽略与元数据筛选标准不匹配的相关结果。Post-filtering：在向量搜索完成后进行元数据过滤。这可以确保考虑所有相关结果，在搜索完成后将不相关的结果进行筛选。为了优化过滤流程，向量数据库使用各种技术，例如利用先进的索引方法来处理元数据或使用并行处理来加速过滤任务。平衡搜索性能和筛选精度之间的权衡对于提供高效且相关的向量数据库查询结果至关重要。向量数据库选型笔者在本文中，花费了大量的笔墨来介绍向量数据库的相似性搜索算法的原理和实现，相似性搜索算法固然是一个向量数据库的核心和关键点，但是在实际的业务场景中，往往还需要考虑其它的因素，例如向量数据库的可用性、扩展性、安全性等，还有代码是否开源、社区是否活跃等等。分布式一个成熟的向量数据库，往往需要支持分布式部署，这样才能满足大规模数据的存储和查询。数据拥有的越多，需要节点就越多，出现的错误和故障也就越多，所以分布式的向量数据库需要具备高可用性和容错性。数据库的高可用性和容错性，往往需要实现分片和复制能力，在传统的数据库中，往往通过数据的主键或者根据业务需求进行分片，但是在分布式的向量数据库中，就需要考虑根据向量的相似性进行分区，以便查询的时候能够保证结果的质量和速度。其它类似复制节点数据的一致性、数据的安全性等等，都是分布式向量数据库需要考虑的因素。访问控制和备份除此之外，访问控制设计的是否充足，例如当组织和业务快速发展时，是否能够快速的添加新的用户和权限控制，是否能够快速的添加新的节点，审计日志是否完善等等，都是需要考虑的因素。另外，数据库的监控和备份也是一个重要的因素，当数据出现故障时，能够快速的定位问题和恢复数据，是一个成熟的向量数据库必须要考虑的因素。API & SDK对比上面的因素选择，API & SDK\",\n",
      "        \"metadata\": {\n",
      "          \"description\": \"Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。\",\n",
      "          \"language\": \"zh\",\n",
      "          \"source\": \"https://guangzhengli.com/blog/zh/vector-database/\",\n",
      "          \"title\": \"向量数据库\"\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub 目前就暂时使用 pgvector 来实现向量搜索以实现 GPT 文档问答，基于 Supabase 提供的 PostgreSQL + pgvector 服务完成。总结本文主要介绍了向量数据库的原理和实现，包括向量数据库的基本概念、相似性搜索算法、相似性测量算法、过滤算法和向量数据库的选型等等。向量数据库是崭新的领域，目前大部分向量数据库公司的估值乘着 AI 和 GPT\",\n",
      "        \"metadata\": {\n",
      "          \"description\": \"Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。\",\n",
      "          \"language\": \"zh\",\n",
      "          \"source\": \"https://guangzhengli.com/blog/zh/vector-database/\",\n",
      "          \"title\": \"向量数据库\"\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"& SDK对比上面的因素选择，API & SDK 可能是往往被忽略的因素，但是在实际的业务场景中，API & SDK 往往是开发者最关心的因素。因为 API & SDK 的设计直接影响了开发者的开发效率和使用体验。一个优秀良好的 API & SDK 设计，往往能够适应需求的不同变化，向量数据库是一个新的领域，在如今大部分人不太清楚这方面需求的当下，这一点容易被人忽视。选型截至目前，汇总到目前的向量数据库有以下几种选择：向量数据库URLGitHub StarLanguageCloudchromahttps://github.com/chroma-core/chroma7.4KPython❌milvushttps://github.com/milvus-io/milvus21.5KGo/Python/C++✅pineconehttps://www.pinecone.io/❌❌✅qdranthttps://github.com/qdrant/qdrant11.8KRust✅typesensehttps://github.com/typesense/typesense12.9KC++❌weaviatehttps://github.com/weaviate/weaviate6.9KGo✅传统数据的扩展除了选择专业的向量数据库，使用传统数据库进行扩展也是一种方法。类似 Redis 除了传统的 Key Value 数据库用途外，Redis 还提供了 Redis Modules，这是一种通过新功能、命令和数据类型扩展 Redis 的方式。例如使用 RediSearch 模块来扩展向量搜索的功能。同理的还有 PostgreSQL 的扩展，PostgreSQL 提供使用 extension 的方式来扩展数据库的功能，例如 pgvector 来开启向量搜索的功能。它不仅支持精确和相似性搜索，还支持余弦相似度等相似性测量算法。最重要的是，它是附加在 PostgreSQL 上的，因此可以利用 PostgreSQL 的所有功能，例如 ACID 事务、并发控制、备份和恢复等。还拥有所有的 PostgreSQL 客户端库，因此可以使用任何语言的 PostgreSQL 客户端来访问它。可以减少开发者的学习成本和服务的维护成本。像笔者的开源项目 ChatFiles 和 VectorHub\",\n",
      "        \"metadata\": {\n",
      "          \"description\": \"Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。\",\n",
      "          \"language\": \"zh\",\n",
      "          \"source\": \"https://guangzhengli.com/blog/zh/vector-database/\",\n",
      "          \"title\": \"向量数据库\"\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"向量数据库\\n\\n\\n\\n主页\",\n",
      "        \"metadata\": {\n",
      "          \"description\": \"Ladder@也许你最近可能听过这样的新闻，某向量数据库的初创公司刚写好 PPT，就获得了几千万的投资，某公司的开源的向量数据库因其代码的简陋而登上了 Hackernews 等等。在过去几个月时间中， AI 应用的发展如火如荼，带动了 AI 应用技术栈上下游的火爆，而向量数据库就是其中最热门的之一。\\n笔者最近因为开发 ChatFiles 和 VectorHub 两款开源项目的需要从而对向量数据库（Vector Database）进行了学习，在对主流的向量数据库和搜索算法有了大概的了解后，笔者决定将这些知识整理成一篇文章，希望能够帮助到大家。\",\n",
      "          \"language\": \"zh\",\n",
      "          \"source\": \"https://guangzhengli.com/blog/zh/vector-database/\",\n",
      "          \"title\": \"向量数据库\"\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"answer\": \"向量数据库具有以下特点：\\n1. 支持高效的相似性搜索：能够快速准确地找到与查询向量最相似的向量数据。\\n2. 提供专门的数据结构和算法：针对向量数据的特点进行优化，以提高查询性能和准确度。\\n3. 支持高维向量数据：能够处理大规模的高维向量数据，适用于各种复杂的数据分析和应用场景。\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableWithMessageHistory] [6.81s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "可以从上面的执行过程中可以看到。从LangSmith中可以看到\n",
    "![](../resource/img_12.png)"
   ],
   "id": "d7b13d16f1fffe75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "上面的例子中，结合了检索，History，我们在来顺一下上面的流程\n",
    "\n",
    "1. 首先创建了`create_history_aware_retriever`，他本质上是一个`retriever`，他的作用是增强检索。也就是说，如果有对话历史，会将对话历史和输入的问题塞给llm，让llm结合对话历史提出一个新的问题，比如第一次问`向量数据库是什么？`，第二次问`他有什么特点？`，如果单独把最后一个问题代入到Retrieve中去，就会找到一些无效的答案。把这些对话历史给llm，llm就会知道这里的他指的是向量数据库。所以，新的问题是`向量数据库的特点？`，这样检索出来的内容就很丰富，很符合。\n",
    "2. 创建了`create_stuff_documents_chain` ，他本质上是一个`chain`,它的作用是将传入的`Document`对象格式化，然后将他传入到后面的流程中去，并且传入的key为`context`，\n",
    "所以，这就要求调用invoke的时候传入的dict中有key为context元素，并且value是Document的数组。它就是传入的文档（LangChain对外部数据做了封装，统称为Document）\n",
    "3. 创建了`create_retrieval_chain`,将前面`create_history_aware_retriever`,`create_stuff_documents_chain`包装在里面。他的作用是，将retrieve和chain结合在一起。并且在最终的返回值中，并且在最终的返回中有两个key `context`和`answer`,一个是retrieve的值，一个是chain的最终的结果. \n",
    "> `create_retrieval_chain`的源码不太好理解，下面会有demo解释，先在这里做一个说明\n",
    "> ```python\n",
    ">     retrieval_chain = (\n",
    ">        RunnablePassthrough.assign(\n",
    ">            context=retrieval_docs.with_config(run_name=\"retrieve_documents\"),\n",
    ">        ).assign(answer=combine_docs_chain)\n",
    ">    ).with_config(run_name=\"retrieval_chain\")\n",
    "> ```\n",
    "> 这里是用 `RunnablePassthrough`嵌套执行的方法，意思是：调用retrieval_chain的时候会先将所有的input代入到`retrieval_docs`执行，拿到结果，将所有的结果代入到`combine_docs_chain`中执行，最终输出的dict中会有`context`和`answer`\n",
    "4. 到这里，整体的chain已经结束了，使用`RunnableWithMessageHistory`来创建一个带有History的chain。\n",
    "\n",
    "感触：\n",
    "LangChain很强大，但是也很严格，比如参数的类型，比如说，Retrieve中的context比如和`stuff chain`中的context 这个key必须得一样，必须得有一个context的key，否则在`stuff chain`中就找不到了。\n",
    "还有类似的，`chat_history`的key，如果没有这个key,在`retrieve`的时候就不会去使用llm来做问题的增强了。因为在`create_history_aware_retriever`中key已经固定了。\n",
    "\n",
    "\n",
    "整体的流程是：当用户输入问题\n",
    "1. 先保存对话历史（用户输入的问题，通过session id）\n",
    "2. 做retrieve。\n",
    "    - 如果有对话历史就使用llm来增强，增强问题，再次查找\n",
    "    - 如果没有，就直接查找\n",
    "3. retrieve会返回Document，将这些document和chat_history会全部导入到prompt中和LLM交互\n",
    "4. 保存对话历史（AI返回值）\n",
    "5. 输出。"
   ],
   "id": "cac97c09b75f5288"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 解释RunnableParallel和RunnablePassthrough\n",
    "\n",
    "解释他的目的是为了更好的理解LangChain的LCEL，上面demo中源码里面有它。\n",
    "### RunnableParallel\n",
    "\n",
    "它是一个Runnable，我们一开始说了，Runnable就是一个LCEL的顶级接口。所以，它的使用方式和chain是一样的，按照这个思路理解是ok的。\n",
    "\n",
    "它的作用是，并行运行他里面每一个Runnable。"
   ],
   "id": "9308a4526a1f0afe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:57:23.241126Z",
     "start_time": "2024-07-18T14:57:23.220047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "def add_one(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "def mul_two(x: int) -> int:\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "def mul_three(x: int) -> int:\n",
    "    return x * 3\n",
    "\n",
    "\n",
    "# RunnableLambda 转化python代码（callable）为一个Runnable\n",
    "runnable_1 = RunnableLambda(add_one)\n",
    "runnable_2 = RunnableLambda(mul_two)\n",
    "runnable_3 = RunnableLambda(mul_three)\n",
    "\n",
    "sequence = runnable_1 | {  # this dict is coerced to a RunnableParallel\n",
    "    \"mul_two\": runnable_2,\n",
    "    \"mul_three\": runnable_3,\n",
    "}\n",
    "sequence.invoke(1)"
   ],
   "id": "a9a68981d179d0b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 1\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:add_one] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 1\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:add_one] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": 2\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<mul_two,mul_three>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 2\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<mul_two,mul_three> > chain:mul_two] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 2\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<mul_two,mul_three> > chain:mul_two] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": 4\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<mul_two,mul_three> > chain:mul_three] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 2\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<mul_two,mul_three> > chain:mul_three] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": 6\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<mul_two,mul_three>] [5ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"mul_two\": 4,\n",
      "  \"mul_three\": 6\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence] [8ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"mul_two\": 4,\n",
      "  \"mul_three\": 6\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mul_two': 4, 'mul_three': 6}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "这里面的代码就是首先将`1`传入到`add_one`返回2，之后将`2`各自输入到`mul_two`和`mul_three`，得到最终的代码，从上面的debug流程中也可以看到，上面的代码其实等于",
   "id": "6e9a2e53e7fde85d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:01:19.501531Z",
     "start_time": "2024-07-18T15:01:19.491847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# LangChain自动对dict做了包装\n",
    "chain = runnable_1 | RunnableParallel(\n",
    "    mul_two=runnable_2,\n",
    "    mul_three=runnable_3,\n",
    ")\n",
    "chain.invoke(1)"
   ],
   "id": "738dc3f5276ee199",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 1\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:add_one] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 1\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:add_one] [0ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": 2\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<mul_two,mul_three>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 2\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<mul_two,mul_three> > chain:mul_two] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 2\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<mul_two,mul_three> > chain:mul_two] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": 4\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<mul_two,mul_three> > chain:mul_three] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 2\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<mul_two,mul_three> > chain:mul_three] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": 6\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<mul_two,mul_three>] [3ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"mul_two\": 4,\n",
      "  \"mul_three\": 6\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence] [5ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"mul_two\": 4,\n",
      "  \"mul_three\": 6\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mul_two': 4, 'mul_three': 6}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "实际的使用是，可以并行的调用两个chain，如下\n",
    "这里的demo会让LangChain将对一个主题，做两个事情。"
   ],
   "id": "8199d8ba7884dca3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:05:39.506659Z",
     "start_time": "2024-07-18T15:05:36.729464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "model = ChatOpenAI()\n",
    "joke_chain = (\n",
    "        ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    ")\n",
    "poem_chain = (\n",
    "        ChatPromptTemplate.from_template(\"write a 2-line poem about {topic}\")\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "parallel_chain = RunnableParallel(joke=joke_chain, poem=poem_chain)\n",
    "res = parallel_chain.invoke({\"topic\": \"太阳\"})\n",
    "print(res)"
   ],
   "id": "2c05f1ae39034c0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableParallel<joke,poem>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"topic\": \"太阳\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableParallel<joke,poem> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"topic\": \"太阳\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableParallel<joke,poem> > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"topic\": \"太阳\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableParallel<joke,poem> > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:RunnableParallel<joke,poem> > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: write a 2-line poem about 太阳\"\n",
      "  ]\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableParallel<joke,poem> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"topic\": \"太阳\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableParallel<joke,poem> > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"topic\": \"太阳\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableParallel<joke,poem> > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:RunnableParallel<joke,poem> > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: tell me a joke about 太阳\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:RunnableParallel<joke,poem> > chain:RunnableSequence > llm:ChatOpenAI] [1.48s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Why did the sun go to school?\\nTo get a little brighter!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Why did the sun go to school?\\nTo get a little brighter!\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 14,\n",
      "                \"prompt_tokens\": 15,\n",
      "                \"total_tokens\": 29\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-bb9877e8-fb48-4dc5-abe2-88e7121c2ff2-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 15,\n",
      "              \"output_tokens\": 14,\n",
      "              \"total_tokens\": 29\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 14,\n",
      "      \"prompt_tokens\": 15,\n",
      "      \"total_tokens\": 29\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableParallel<joke,poem> > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableParallel<joke,poem> > chain:RunnableSequence > parser:StrOutputParser] [2ms] Exiting Parser run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"Why did the sun go to school?\\nTo get a little brighter!\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableParallel<joke,poem> > chain:RunnableSequence] [1.48s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"Why did the sun go to school?\\nTo get a little brighter!\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:RunnableParallel<joke,poem> > chain:RunnableSequence > llm:ChatOpenAI] [2.67s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"太阳升起，照亮大地，带来温暖和希望。\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"太阳升起，照亮大地，带来温暖和希望。\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 27,\n",
      "                \"prompt_tokens\": 17,\n",
      "                \"total_tokens\": 44\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-3c932ab5-8a1b-4877-9a10-1c75112f5f41-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 17,\n",
      "              \"output_tokens\": 27,\n",
      "              \"total_tokens\": 44\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 27,\n",
      "      \"prompt_tokens\": 17,\n",
      "      \"total_tokens\": 44\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableParallel<joke,poem> > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableParallel<joke,poem> > chain:RunnableSequence > parser:StrOutputParser] [2ms] Exiting Parser run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"太阳升起，照亮大地，带来温暖和希望。\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableParallel<joke,poem> > chain:RunnableSequence] [2.68s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"太阳升起，照亮大地，带来温暖和希望。\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableParallel<joke,poem>] [2.69s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"joke\": \"Why did the sun go to school?\\nTo get a little brighter!\",\n",
      "  \"poem\": \"太阳升起，照亮大地，带来温暖和希望。\"\n",
      "}\n",
      "{'joke': 'Why did the sun go to school?\\nTo get a little brighter!', 'poem': '太阳升起，照亮大地，带来温暖和希望。'}\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### RunnableSequence\n",
    "和上面相对应的是`RunnableSequence`，一个一个执行，前面的执行完了，前面的值作为后面的输入。\n",
    "\n",
    "`RunnableSequence`支持配置first，middle，last。按照执行顺序来"
   ],
   "id": "e1ecc50e7dbbf9d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:10:35.431074Z",
     "start_time": "2024-07-18T15:10:35.424380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableSequence\n",
    "\n",
    "\n",
    "def add_one(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "def add_two(x: int) -> int:\n",
    "    return x + 2\n",
    "\n",
    "\n",
    "def mul_two(x: int) -> int:\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "runnable_1 = RunnableLambda(add_one)\n",
    "runnable_2 = RunnableLambda(add_two)\n",
    "runnable_3 = RunnableLambda(mul_two)\n",
    "sequence = RunnableSequence(first=runnable_1, middle=[runnable_2], last=runnable_3)\n",
    "# Or equivalently:\n",
    "# sequence = runnable_1 | runnable_2\n",
    "sequence.invoke(1)"
   ],
   "id": "66927b6e4b63f5e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 1\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:add_one] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 1\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:add_one] [0ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": 2\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:add_two] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 2\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:add_two] [0ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": 4\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:mul_two] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 4\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:mul_two] [0ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": 8\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence] [2ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": 8\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "实际使用场景\n",
    "还记得 `prompt | model | SimpleJsonOutputParser()`不？，他本质上就是构建了一个`RunnableSequence`。\n",
    "\n",
    "### RunnablePassthrough\n",
    "\n",
    "他可以传递或者改变或者增加一个额外的key给后续的流程，都是要配合`RunnableSequence`或者`RunnableParallel`来使用的。否则没有意义。并且他也实现了`Runnable`"
   ],
   "id": "7b3702cb9eefac14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:14:41.860868Z",
     "start_time": "2024-07-18T15:14:41.842928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import (\n",
    "    RunnableLambda,\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    origin=RunnablePassthrough(),\n",
    "    modified=lambda x: x + 1\n",
    ")\n",
    "runnable.invoke(1)  # {'origin': 1, 'modified': 2}"
   ],
   "id": "74531c0657d88b78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableParallel<origin,modified>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 1\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableParallel<origin,modified> > chain:RunnablePassthrough] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 1\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableParallel<origin,modified> > chain:RunnablePassthrough] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": 1\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableParallel<origin,modified> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 1\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableParallel<origin,modified> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": 2\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableParallel<origin,modified>] [7ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"origin\": 1,\n",
      "  \"modified\": 2\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'origin': 1, 'modified': 2}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在某些情况下，需要将输入透传给后面，并且在添加一些额外的key，这个情况下可以使用`assign`方法\n",
    "` RunnablePassthrough.assign()`意思就是，将原来的输入的input，传递给assign里面，在这里可以对输入值做二次加工。"
   ],
   "id": "5168d0e840578e01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:17:19.641610Z",
     "start_time": "2024-07-18T15:17:19.618500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def fake_llm(prompt: str) -> str:  # Fake LLM for the example\n",
    "    return \"completion\"\n",
    "\n",
    "\n",
    "runnable = {\n",
    "               'llm1': fake_llm,\n",
    "               'llm2': fake_llm,\n",
    "           } | RunnablePassthrough.assign(\n",
    "    total_chars=lambda inputs: len(inputs['llm1'] + inputs['llm2'])\n",
    ")\n",
    "\n",
    "runnable.invoke('hello')"
   ],
   "id": "8c0ae12062197829",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"hello\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<llm1,llm2>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"hello\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<llm1,llm2> > chain:fake_llm] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"hello\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<llm1,llm2> > chain:fake_llm] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"completion\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<llm1,llm2> > chain:fake_llm] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"hello\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<llm1,llm2> > chain:fake_llm] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"completion\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<llm1,llm2>] [4ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars> > chain:RunnableParallel<total_chars>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars> > chain:RunnableParallel<total_chars> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars> > chain:RunnableParallel<total_chars> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": 20\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars> > chain:RunnableParallel<total_chars>] [2ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"total_chars\": 20\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars>] [4ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\",\n",
      "  \"total_chars\": 20\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence] [12ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\",\n",
      "  \"total_chars\": 20\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'llm1': 'completion', 'llm2': 'completion', 'total_chars': 20}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "看一下`assign`方法的实现\n",
    "\n",
    "```python\n",
    "    @classmethod\n",
    "    def assign(\n",
    "        cls,\n",
    "        **kwargs: Union[\n",
    "            Runnable[Dict[str, Any], Any],\n",
    "            Callable[[Dict[str, Any]], Any],\n",
    "            Mapping[\n",
    "                str,\n",
    "                Union[Runnable[Dict[str, Any], Any], Callable[[Dict[str, Any]], Any]],\n",
    "            ],\n",
    "        ],\n",
    "    ) -> \"RunnableAssign\":\n",
    "        ### 滴滴滴，看这里，它是将传递进来的参数包装成了一个 RunnableParallel\n",
    "        return RunnableAssign(RunnableParallel(kwargs))\n",
    "```\n",
    "\n",
    "所以，他的assign方法就是手动构建了一个`RunnableParallel`,并且将inut传入到了里面。他传入的input就是当前他所在的RunnableParallel或者RunnableSequence的input。\n",
    "\n",
    "key看下面的例子，text_input 的输入就是 上一个阶段的输入。"
   ],
   "id": "ea0c7393d66ec45f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:22:23.432288Z",
     "start_time": "2024-07-18T15:22:23.403232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runnable = {\n",
    "               'llm1': fake_llm,\n",
    "               'llm2': fake_llm,\n",
    "           } | RunnablePassthrough.assign(\n",
    "    total_chars=lambda inputs: len(inputs['llm1'] + inputs['llm2']),\n",
    "    text_input=RunnablePassthrough()\n",
    ")\n",
    "runnable.invoke(1)"
   ],
   "id": "81a9c7bacc46464f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 1\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<llm1,llm2>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 1\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<llm1,llm2> > chain:fake_llm] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 1\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<llm1,llm2> > chain:fake_llm] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"completion\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<llm1,llm2> > chain:fake_llm] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 1\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<llm1,llm2> > chain:fake_llm] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"completion\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<llm1,llm2>] [5ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars,text_input>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars,text_input> > chain:RunnableParallel<total_chars,text_input>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars,text_input> > chain:RunnableParallel<total_chars,text_input> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars,text_input> > chain:RunnableParallel<total_chars,text_input> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": 20\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars,text_input> > chain:RunnableParallel<total_chars,text_input> > chain:RunnablePassthrough] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars,text_input> > chain:RunnableParallel<total_chars,text_input> > chain:RunnablePassthrough] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars,text_input> > chain:RunnableParallel<total_chars,text_input>] [3ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"total_chars\": 20,\n",
      "  \"text_input\": {\n",
      "    \"llm1\": \"completion\",\n",
      "    \"llm2\": \"completion\"\n",
      "  }\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars,text_input>] [5ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\",\n",
      "  \"total_chars\": 20,\n",
      "  \"text_input\": {\n",
      "    \"llm1\": \"completion\",\n",
      "    \"llm2\": \"completion\"\n",
      "  }\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence] [15ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\",\n",
      "  \"total_chars\": 20,\n",
      "  \"text_input\": {\n",
      "    \"llm1\": \"completion\",\n",
      "    \"llm2\": \"completion\"\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'llm1': 'completion',\n",
       " 'llm2': 'completion',\n",
       " 'total_chars': 20,\n",
       " 'text_input': {'llm1': 'completion', 'llm2': 'completion'}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "那按照这个逻辑来说，就有下面的代码。",
   "id": "62e2ac92ede56707"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:27:29.477461Z",
     "start_time": "2024-07-18T15:27:29.451551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runnable = ({\n",
    "                'llm1': fake_llm,\n",
    "                'llm2': fake_llm,\n",
    "            }  # 1 \n",
    "            | RunnablePassthrough.assign(\n",
    "            total_chars=lambda inputs: len(inputs['llm1'] + inputs['llm2']),\n",
    "        )  # 2\n",
    "            .assign(  # 3\n",
    "            test=RunnablePassthrough()\n",
    "        ))\n",
    "runnable.invoke(1)"
   ],
   "id": "d620e98b0c17b8fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 1\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<llm1,llm2>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 1\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<llm1,llm2> > chain:fake_llm] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 1\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<llm1,llm2> > chain:fake_llm] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"completion\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<llm1,llm2> > chain:fake_llm] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": 1\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<llm1,llm2> > chain:fake_llm] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"completion\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<llm1,llm2>] [4ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars> > chain:RunnableParallel<total_chars>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars> > chain:RunnableParallel<total_chars> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars> > chain:RunnableParallel<total_chars> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": 20\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars> > chain:RunnableParallel<total_chars>] [2ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"total_chars\": 20\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<total_chars>] [4ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\",\n",
      "  \"total_chars\": 20\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<test>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\",\n",
      "  \"total_chars\": 20\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<test> > chain:RunnableParallel<test>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\",\n",
      "  \"total_chars\": 20\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<test> > chain:RunnableParallel<test> > chain:RunnablePassthrough] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\",\n",
      "  \"total_chars\": 20\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<test> > chain:RunnableParallel<test> > chain:RunnablePassthrough] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\",\n",
      "  \"total_chars\": 20\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<test> > chain:RunnableParallel<test>] [2ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"test\": {\n",
      "    \"llm1\": \"completion\",\n",
      "    \"llm2\": \"completion\",\n",
      "    \"total_chars\": 20\n",
      "  }\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableAssign<test>] [3ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\",\n",
      "  \"total_chars\": 20,\n",
      "  \"test\": {\n",
      "    \"llm1\": \"completion\",\n",
      "    \"llm2\": \"completion\",\n",
      "    \"total_chars\": 20\n",
      "  }\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence] [15ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"llm1\": \"completion\",\n",
      "  \"llm2\": \"completion\",\n",
      "  \"total_chars\": 20,\n",
      "  \"test\": {\n",
      "    \"llm1\": \"completion\",\n",
      "    \"llm2\": \"completion\",\n",
      "    \"total_chars\": 20\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'llm1': 'completion',\n",
       " 'llm2': 'completion',\n",
       " 'total_chars': 20,\n",
       " 'test': {'llm1': 'completion', 'llm2': 'completion', 'total_chars': 20}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "解释：\n",
    "在#1，创建的是RunnableParallel，有两个阶段`llm1`,`llm2`并行执行，拿到结果，将值传递给#2，#2拿到input之后，做了操作，增加了total_chars后，传递给了#3,#3，#3创建了一个key叫做test，test里面存放的是之前所有的输入。所以他的结果是\n",
    "```json\n",
    "{'llm1': 'completion',\n",
    " 'llm2': 'completion',\n",
    " 'total_chars': 20,\n",
    " 'test': {'llm1': 'completion', 'llm2': 'completion', 'total_chars': 20}}\n",
    "```\n",
    "\n",
    "end"
   ],
   "id": "d6d92b4ab2a731cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
