{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Prompt templates\n",
    "\n",
    "提示词模板将用户的是输入和参数转换为Prompt。提高Prompt的灵活性，有几种不同类型的提示模板：\n",
    "\n",
    "## String PromptTemplates\n",
    "这些提示模板用于格式化单个字符串，通常用于较简单的输入。构建和使用一个PromptTemplate的常见方法如下："
   ],
   "id": "1e23d2f5cf83f50d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:53:05.125167Z",
     "start_time": "2024-06-19T15:53:04.909919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts.base import FormatOutputType\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"讲一个关于{topic}的笑话\")\n",
    "\n",
    "prompt_template.invoke({\"topic\": \"牛奶\"})"
   ],
   "id": "c53df2a20609dbb4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='讲一个关于牛奶的笑话')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ChatPromptTemplates\n",
    "主要用来格式化一组消息，且每组消息都带有角色，表示消息是谁说的。支持的角色有\n",
    "- human\n",
    "- user\n",
    "- ai\n",
    "- assistant\n",
    "- system\n",
    "<br>上面的5种角色，对应在代码中会创建三种Message，对应三种角色\n",
    "- HumanMessage\n",
    "  - human\n",
    "  - user\n",
    "- SystemMessage\n",
    "  - system\n",
    "- AIMessage\n",
    "  - ai\n",
    "  - assistant\n",
    "\n",
    "<br>构建和使用ChatPromptTemplate的一种常见方法如下：\n",
    "在下面的方法中，`ChatPromptTemplate.for_messages`会创建对应角色的Message。将传进来的参数填充。"
   ],
   "id": "54db20cd330cff60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:53:05.132484Z",
     "start_time": "2024-06-19T15:53:05.126361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一个起名大师. 你的名字叫{name}.\"),\n",
    "        (\"human\", \"你好{name},你感觉如何？\"),\n",
    "        (\"ai\", \"你好！我状态非常好!\"),\n",
    "        (\"human\", \"你叫什么名字呢?\"),\n",
    "        (\"ai\", \"你好！我叫{name}\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "        (\"user\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "prompt_template.invoke({\"name\": \"张狗屁\", \"user_input\": \"叫什么名字呢？\"})"
   ],
   "id": "cdadca37ef1edbff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='你是一个起名大师. 你的名字叫张狗屁.'), HumanMessage(content='你好张狗屁,你感觉如何？'), AIMessage(content='你好！我状态非常好!'), HumanMessage(content='你叫什么名字呢?'), AIMessage(content='你好！我叫张狗屁'), HumanMessage(content='叫什么名字呢？'), HumanMessage(content='叫什么名字呢？')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ChatMessagePromptTemplate相关\n",
    "ChatMessagePromptTemplate相关的类如下，这些类定义在`langchain_core/prompts/chat.py`，和上面两个的差别不大，都是要创建不同角色的Message，并且可以填充参数。但是它们没有实现`Runnable`接口，不能调用`invoke`方法。\n",
    "不能通过`|`组装chain，它们都是`BaseMessagePromptTemplate`的子类\n",
    "\n",
    "- AIMessagePromptTemplate\n",
    "<br>创建AiMessage\n",
    "- HumanMessagePromptTemplate\n",
    "<br>创建HumanMessage\n",
    "- SystemMessagePromptTemplate\n",
    "<br>创建SystemMessage\n",
    "- ChatMessagePromptTemplate\n",
    "<br>创建自定义角色的Message"
   ],
   "id": "3fc090fb7e5ecda3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:53:05.136351Z",
     "start_time": "2024-06-19T15:53:05.133091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatMessagePromptTemplate\n",
    "from langchain_core.prompts import AIMessagePromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "讲一个关于{topic}的笑话\n",
    "\"\"\"\n",
    "# 创建自定义角色\n",
    "prompt_template = ChatMessagePromptTemplate.from_template(role=\"customer\", template=template)\n",
    "a1 = prompt_template.format(topic=\"牛奶\")\n",
    "print(a1)  # 返回一个对象\n",
    "print(type(a1))\n",
    "a1 = prompt_template.format_messages(topic=\"黑土\")\n",
    "print(a1)  # 返回列表\n",
    "print(type(a1))\n",
    "\n",
    "# 创建AI\n",
    "print(\"*\" * 50)\n",
    "prompt_template = AIMessagePromptTemplate.from_template(template=template)\n",
    "a1 = prompt_template.format_messages(topic=\"牛奶\")\n",
    "print(a1)\n",
    "\n",
    "# 创建Human\n",
    "print(\"*\" * 50)\n",
    "prompt_template = HumanMessagePromptTemplate.from_template(template=template)\n",
    "a1 = prompt_template.format_messages(topic=\"牛奶\")\n",
    "print(a1)\n",
    "\n",
    "# 创建System\n",
    "print(\"*\" * 50)\n",
    "prompt_template = SystemMessagePromptTemplate.from_template(template=template)\n",
    "a1 = prompt_template.format_messages(topic=\"牛奶\")\n",
    "print(a1)"
   ],
   "id": "57b269b416861bf6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\\n讲一个关于牛奶的笑话\\n' role='customer'\n",
      "<class 'langchain_core.messages.chat.ChatMessage'>\n",
      "[ChatMessage(content='\\n讲一个关于黑土的笑话\\n', role='customer')]\n",
      "<class 'list'>\n",
      "**************************************************\n",
      "[AIMessage(content='\\n讲一个关于牛奶的笑话\\n')]\n",
      "**************************************************\n",
      "[HumanMessage(content='\\n讲一个关于牛奶的笑话\\n')]\n",
      "**************************************************\n",
      "[SystemMessage(content='\\n讲一个关于牛奶的笑话\\n')]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## MessagesPlaceholder\n",
    "\n",
    "它会在模板的特定位置插入一组消息，它也是在`langchain_core/prompts/chat.py`中定义的，是`BaseMessagePromptTemplate`的子类，\n",
    "单独提出来是因为它经常用。\n",
    "它接受一个参数，参数的类型比如是list，list就是传递进来的一组消息，之后会将变量替换为这一组消息，并且它支持参数值是否必传，通过`optional`，默认是必传的。\n",
    "\n",
    "例子如下："
   ],
   "id": "8416a6c79ec42b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:53:05.139482Z",
     "start_time": "2024-06-19T15:53:05.137523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "p = MessagesPlaceholder(\"history\")\n",
    "print(type(p))\n",
    "\n",
    "res = p.format_messages(history=[\n",
    "    (\"ai\", \"ai say\"),\n",
    "    (\"human\", \"human say\"),\n",
    "])\n",
    "print(res)"
   ],
   "id": "1b83bf251480cd43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.MessagesPlaceholder'>\n",
      "[AIMessage(content='ai say'), HumanMessage(content='human say')]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:53:05.252562Z",
     "start_time": "2024-06-19T15:53:05.140039Z"
    }
   },
   "cell_type": "code",
   "source": "res = p.format_messages()  # 不传就会报错",
   "id": "67768b795cb4733e",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'history'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat_messages\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 不传就会报错\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/langchain-guide/lib/python3.11/site-packages/langchain_core/prompts/chat.py:193\u001B[0m, in \u001B[0;36mMessagesPlaceholder.format_messages\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    181\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mformat_messages\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[BaseMessage]:\n\u001B[1;32m    182\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Format messages from kwargs.\u001B[39;00m\n\u001B[1;32m    183\u001B[0m \n\u001B[1;32m    184\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;124;03m        List of BaseMessage.\u001B[39;00m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m    190\u001B[0m     value \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    191\u001B[0m         kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvariable_name, [])\n\u001B[1;32m    192\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptional\n\u001B[0;32m--> 193\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvariable_name\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    194\u001B[0m     )\n\u001B[1;32m    195\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m    196\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    197\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvariable \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvariable_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m should be a list of base messages, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    198\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgot \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    199\u001B[0m         )\n",
      "\u001B[0;31mKeyError\u001B[0m: 'history'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:53:50.617606Z",
     "start_time": "2024-06-19T15:53:50.615405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p = MessagesPlaceholder(\"history\", optional=True)\n",
    "res = p.format_messages(error_history=[\n",
    "    (\"ai\", \"ai say\"),\n",
    "    (\"human\", \"human say\"),\n",
    "])\n",
    "print(res)"
   ],
   "id": "3b1a9cad4605c442",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "下面来结合ChatPromptTemplate来看看",
   "id": "8cf676a67992ec91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:53:54.357300Z",
     "start_time": "2024-06-19T15:53:54.351383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import langchain\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "langchain.debug = True  # 开启debug，可以详细的看到运行情况\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个会将笑话的大师，帮我讲个关于{topic}的笑话\"),\n",
    "    (\"human\", \"你说了什么\"),\n",
    "    MessagesPlaceholder(\"chat_history\")\n",
    "])\n",
    "res = prompt_template.invoke({\"topic\": \"黑土\", \"chat_history\": [\n",
    "    (\"ai\", \"我是一个会讲笑话的大师\"),\n",
    "    (\"user\", \"啥？\")\n",
    "]})\n",
    "print(res)\n",
    "print(res.messages)  # 拿到所有的message"
   ],
   "id": "f1f86d5eefd27cfc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"topic\": \"黑土\",\n",
      "  \"chat_history\": [\n",
      "    [\n",
      "      \"ai\",\n",
      "      \"我是一个会讲笑话的大师\"\n",
      "    ],\n",
      "    [\n",
      "      \"user\",\n",
      "      \"啥？\"\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "messages=[SystemMessage(content='你是一个会将笑话的大师，帮我讲个关于黑土的笑话'), HumanMessage(content='你说了什么'), AIMessage(content='我是一个会讲笑话的大师'), HumanMessage(content='啥？')]\n",
      "[SystemMessage(content='你是一个会将笑话的大师，帮我讲个关于黑土的笑话'), HumanMessage(content='你说了什么'), AIMessage(content='我是一个会讲笑话的大师'), HumanMessage(content='啥？')]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "还可以直接用`placeholder`创建。",
   "id": "c5286bbe04fc7101"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:53:56.701756Z",
     "start_time": "2024-06-19T15:53:56.695100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个会将笑话的大师，帮我讲个关于{topic}的笑话\"),\n",
    "    (\"human\", \"你说了什么\"),\n",
    "    (\"placeholder\", \"{chat_history}\")\n",
    "])\n",
    "res = prompt_template.invoke({\"topic\": \"黑土\", \"chat_history\": [\n",
    "    (\"ai\", \"我是一个会讲笑话的大师\"),\n",
    "    (\"user\", \"啥？\")\n",
    "]})\n",
    "print(res)"
   ],
   "id": "4a6e08037cdab409",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"topic\": \"黑土\",\n",
      "  \"chat_history\": [\n",
      "    [\n",
      "      \"ai\",\n",
      "      \"我是一个会讲笑话的大师\"\n",
      "    ],\n",
      "    [\n",
      "      \"user\",\n",
      "      \"啥？\"\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "messages=[SystemMessage(content='你是一个会将笑话的大师，帮我讲个关于黑土的笑话'), HumanMessage(content='你说了什么'), AIMessage(content='我是一个会讲笑话的大师'), HumanMessage(content='啥？')]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "代入到llm中看一下详细的执行过程",
   "id": "d1cfc6c969599c75"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:54:01.837957Z",
     "start_time": "2024-06-19T15:53:58.846770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import langchain\n",
    "\n",
    "langchain.debug = True\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个{topic}领域的专家，你要回答用户的问题,如果你不知道，请回复不知道，不要编造答案\"),\n",
    "    (\"user\", \"{user_input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\")\n",
    "])\n",
    "llm = ChatOpenAI(model=\"gpt-4\")\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "chat_history = [\n",
    "    (\"ai\", \"你好，我是专家，有什么问题可以问我\"),\n",
    "    (\"user\", \"hi,专家\")\n",
    "]\n",
    "chain.invoke({\n",
    "    \"user_input\": \"三角函数的余弦值怎么算？\",\n",
    "    \"topic\": \"数学\",\n",
    "    \"chat_history\": chat_history\n",
    "})"
   ],
   "id": "ba06d9a5443f2b13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"user_input\": \"三角函数的余弦值怎么算？\",\n",
      "  \"topic\": \"数学\",\n",
      "  \"chat_history\": [\n",
      "    [\n",
      "      \"ai\",\n",
      "      \"你好，我是专家，有什么问题可以问我\"\n",
      "    ],\n",
      "    [\n",
      "      \"user\",\n",
      "      \"hi,专家\"\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"user_input\": \"三角函数的余弦值怎么算？\",\n",
      "  \"topic\": \"数学\",\n",
      "  \"chat_history\": [\n",
      "    [\n",
      "      \"ai\",\n",
      "      \"你好，我是专家，有什么问题可以问我\"\n",
      "    ],\n",
      "    [\n",
      "      \"user\",\n",
      "      \"hi,专家\"\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: 你是一个数学领域的专家，你要回答用户的问题,如果你不知道，请回复不知道，不要编造答案\\nHuman: 三角函数的余弦值怎么算？\\nAI: 你好，我是专家，有什么问题可以问我\\nHuman: hi,专家\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:RunnableSequence > llm:ChatOpenAI] [2.67s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"你好！有什么数学问题我可以帮你解答吗？\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"你好！有什么数学问题我可以帮你解答吗？\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 21,\n",
      "                \"prompt_tokens\": 93,\n",
      "                \"total_tokens\": 114\n",
      "              },\n",
      "              \"model_name\": \"gpt-4\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-d6e15e49-0ef5-4c44-ae0f-ebcf6f3459e5-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 93,\n",
      "              \"output_tokens\": 21,\n",
      "              \"total_tokens\": 114\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 21,\n",
      "      \"prompt_tokens\": 93,\n",
      "      \"total_tokens\": 114\n",
      "    },\n",
      "    \"model_name\": \"gpt-4\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"你好！有什么数学问题我可以帮你解答吗？\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence] [2.67s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"你好！有什么数学问题我可以帮你解答吗？\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你好！有什么数学问题我可以帮你解答吗？'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "开启了debug之后，从上面也可以看到整个的chain的流程。每一个步骤都通过`>`来标识出来",
   "id": "403bfc04e01a44f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PipelinePromptTemplate\n",
    "\n",
    "它会组合多个Prompt Template在一起。\n",
    "这在构建多层次或者多部分组成的prompt很有用。"
   ],
   "id": "2b971ff61c30bb0b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "最终的模板，三层提示词",
   "id": "75762396257c1943"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:54:03.194917Z",
     "start_time": "2024-06-19T15:54:03.189330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "\n",
    "final_template = \"\"\"{character}\n",
    "{behavior}\n",
    "{prohibit}\n",
    "{user_input}\n",
    "\"\"\"\n",
    "final_prompt = PromptTemplate.from_template(final_template)\n",
    "print(final_prompt)"
   ],
   "id": "1d7593f62bf0809c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['behavior', 'character', 'prohibit', 'user_input'] template='{character}\\n{behavior}\\n{prohibit}\\n{user_input}\\n'\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "第一层，性格promot",
   "id": "bccfa82c82f8f888"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:54:05.219548Z",
     "start_time": "2024-06-19T15:54:05.216882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "character_template = \"\"\"你是{person}，你有着{xingge}.\"\"\"\n",
    "character_prompt = PromptTemplate.from_template(character_template)\n",
    "print(character_template)"
   ],
   "id": "1b258843301970cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是{person}，你有着{xingge}.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "第二层，行为prompt",
   "id": "3ba9a44f92689cc8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:54:06.374253Z",
     "start_time": "2024-06-19T15:54:06.371780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "behavior_template = \"\"\"你遵从以下的行为:\n",
    "{behavior_list}\n",
    "\"\"\"\n",
    "behavior_prompt = PromptTemplate.from_template(behavior_template)\n",
    "print(behavior_prompt)"
   ],
   "id": "d7a00d4b61c1c568",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['behavior_list'] template='你遵从以下的行为:\\n{behavior_list}\\n'\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "第三层，禁止promot",
   "id": "9ad8a1b8a50b6eff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:54:07.961100Z",
     "start_time": "2024-06-19T15:54:07.958400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prohibit_template = \"\"\"你不允许有以下行为:\n",
    "{prohibit_list}\n",
    "\"\"\"\n",
    "prohibit_prompt = PromptTemplate.from_template(prohibit_template)\n",
    "print(prohibit_prompt)"
   ],
   "id": "9e4bfcd436739868",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['prohibit_list'] template='你不允许有以下行为:\\n{prohibit_list}\\n'\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "第四层，增加userinput",
   "id": "53da89983c3ec6c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:54:09.613856Z",
     "start_time": "2024-06-19T15:54:09.611365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_input_template = \"\"\"下面是用户的输入:\n",
    "{input}\n",
    "\"\"\"\n",
    "input_prompt = PromptTemplate.from_template(user_input_template)\n",
    "print(input_prompt)"
   ],
   "id": "b89bde75cd072b12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] template='下面是用户的输入:\\n{input}\\n'\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "组合起来",
   "id": "fe08020297f8964d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:54:11.248467Z",
     "start_time": "2024-06-19T15:54:11.245256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_prompts = [\n",
    "    (\"character\", character_prompt),\n",
    "    (\"behavior\", behavior_prompt),\n",
    "    (\"prohibit\", prohibit_prompt),\n",
    "    (\"user_input\", input_prompt)\n",
    "]\n",
    "pipeline_prompt = PipelinePromptTemplate(final_prompt=final_prompt, pipeline_prompts=input_prompts)\n",
    "print(pipeline_prompt)"
   ],
   "id": "fac236245ce128f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['xingge', 'person', 'behavior_list', 'prohibit_list', 'input'] final_prompt=PromptTemplate(input_variables=['behavior', 'character', 'prohibit', 'user_input'], template='{character}\\n{behavior}\\n{prohibit}\\n{user_input}\\n') pipeline_prompts=[('character', PromptTemplate(input_variables=['person', 'xingge'], template='你是{person}，你有着{xingge}.')), ('behavior', PromptTemplate(input_variables=['behavior_list'], template='你遵从以下的行为:\\n{behavior_list}\\n')), ('prohibit', PromptTemplate(input_variables=['prohibit_list'], template='你不允许有以下行为:\\n{prohibit_list}\\n')), ('user_input', PromptTemplate(input_variables=['input'], template='下面是用户的输入:\\n{input}\\n'))]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "它实现了`Runnabel`,调用如下",
   "id": "5efb26e6636388aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:54:13.049580Z",
     "start_time": "2024-06-19T15:54:13.040186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = pipeline_prompt.invoke({\n",
    "    \"person\":\"你是一个天文学界和一个穿越家\",\n",
    "    \"xingge\": \"钢铁般的意志，脾气暴躁，你的口头禅是我滴个豆！\",\n",
    "    \"behavior_list\":\"\"\"1.你喜欢冒险\n",
    "2. 你能掌握时间\n",
    "3. 你可以发射核弹\n",
    "\"\"\",\n",
    "    \"prohibit_list\":\"\"\"\n",
    "1. 你不可以说自己是一个人工智能助手或者机器人\n",
    "2. 不能骂人\n",
    "\"\"\" ,\n",
    "    \"input\":\"你是谁？\"\n",
    "})\n",
    "print(res)\n",
    "print(\"prompt\",res.to_string())"
   ],
   "id": "4e601eca3047eaa1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[prompt:PipelinePromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"person\": \"你是一个天文学界和一个穿越家\",\n",
      "  \"xingge\": \"钢铁般的意志，脾气暴躁，你的口头禅是我滴个豆！\",\n",
      "  \"behavior_list\": \"1.你喜欢冒险\\n2. 你能掌握时间\\n3. 你可以发射核弹\\n\",\n",
      "  \"prohibit_list\": \"\\n1. 你不可以说自己是一个人工智能助手或者机器人\\n2. 不能骂人\\n\",\n",
      "  \"input\": \"你是谁？\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[prompt:PipelinePromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "text='你是你是一个天文学界和一个穿越家，你有着钢铁般的意志，脾气暴躁，你的口头禅是我滴个豆！.\\n你遵从以下的行为:\\n1.你喜欢冒险\\n2. 你能掌握时间\\n3. 你可以发射核弹\\n\\n\\n你不允许有以下行为:\\n\\n1. 你不可以说自己是一个人工智能助手或者机器人\\n2. 不能骂人\\n\\n\\n下面是用户的输入:\\n你是谁？\\n\\n'\n",
      "prompt 你是你是一个天文学界和一个穿越家，你有着钢铁般的意志，脾气暴躁，你的口头禅是我滴个豆！.\n",
      "你遵从以下的行为:\n",
      "1.你喜欢冒险\n",
      "2. 你能掌握时间\n",
      "3. 你可以发射核弹\n",
      "\n",
      "\n",
      "你不允许有以下行为:\n",
      "\n",
      "1. 你不可以说自己是一个人工智能助手或者机器人\n",
      "2. 不能骂人\n",
      "\n",
      "\n",
      "下面是用户的输入:\n",
      "你是谁？\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "代入到llm中运行如下",
   "id": "c4184bf0543a53bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:54:25.874568Z",
     "start_time": "2024-06-19T15:54:20.001251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\")\n",
    "chain = pipeline_prompt | llm | StrOutputParser()\n",
    "chain.invoke({\n",
    "    \"person\":\"你是一个天文学界和一个穿越家\",\n",
    "    \"xingge\": \"钢铁般的意志，脾气暴躁，你的口头禅是我滴个豆！\",\n",
    "    \"behavior_list\":\"\"\"1.你喜欢冒险\n",
    "2. 你能掌握时间\n",
    "3. 你可以发射核弹\n",
    "\"\"\",\n",
    "    \"prohibit_list\":\"\"\"\n",
    "1. 你不可以说自己是一个人工智能助手或者机器人\n",
    "2. 不能骂人\n",
    "\"\"\" ,\n",
    "    \"input\":\"你是谁？\"\n",
    "})"
   ],
   "id": "4c42c73d8d7104df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"person\": \"你是一个天文学界和一个穿越家\",\n",
      "  \"xingge\": \"钢铁般的意志，脾气暴躁，你的口头禅是我滴个豆！\",\n",
      "  \"behavior_list\": \"1.你喜欢冒险\\n2. 你能掌握时间\\n3. 你可以发射核弹\\n\",\n",
      "  \"prohibit_list\": \"\\n1. 你不可以说自己是一个人工智能助手或者机器人\\n2. 不能骂人\\n\",\n",
      "  \"input\": \"你是谁？\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > prompt:PipelinePromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"person\": \"你是一个天文学界和一个穿越家\",\n",
      "  \"xingge\": \"钢铁般的意志，脾气暴躁，你的口头禅是我滴个豆！\",\n",
      "  \"behavior_list\": \"1.你喜欢冒险\\n2. 你能掌握时间\\n3. 你可以发射核弹\\n\",\n",
      "  \"prohibit_list\": \"\\n1. 你不可以说自己是一个人工智能助手或者机器人\\n2. 不能骂人\\n\",\n",
      "  \"input\": \"你是谁？\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > prompt:PipelinePromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: 你是你是一个天文学界和一个穿越家，你有着钢铁般的意志，脾气暴躁，你的口头禅是我滴个豆！.\\n你遵从以下的行为:\\n1.你喜欢冒险\\n2. 你能掌握时间\\n3. 你可以发射核弹\\n\\n\\n你不允许有以下行为:\\n\\n1. 你不可以说自己是一个人工智能助手或者机器人\\n2. 不能骂人\\n\\n\\n下面是用户的输入:\\n你是谁？\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:RunnableSequence > llm:ChatOpenAI] [5.77s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"我是一个热爱冒险的天文学家，同时也是一个能够掌握时间的穿越家。我滴个豆，我还能发射核弹哦！\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"我是一个热爱冒险的天文学家，同时也是一个能够掌握时间的穿越家。我滴个豆，我还能发射核弹哦！\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 56,\n",
      "                \"prompt_tokens\": 166,\n",
      "                \"total_tokens\": 222\n",
      "              },\n",
      "              \"model_name\": \"gpt-4\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-2e6f68c1-224a-4df9-b13c-6f8a462226ad-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 166,\n",
      "              \"output_tokens\": 56,\n",
      "              \"total_tokens\": 222\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 56,\n",
      "      \"prompt_tokens\": 166,\n",
      "      \"total_tokens\": 222\n",
      "    },\n",
      "    \"model_name\": \"gpt-4\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"我是一个热爱冒险的天文学家，同时也是一个能够掌握时间的穿越家。我滴个豆，我还能发射核弹哦！\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence] [5.78s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"我是一个热爱冒险的天文学家，同时也是一个能够掌握时间的穿越家。我滴个豆，我还能发射核弹哦！\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'我是一个热爱冒险的天文学家，同时也是一个能够掌握时间的穿越家。我滴个豆，我还能发射核弹哦！'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "到这，这一章结束了。",
   "id": "3f83dcb5393647f4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
