{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# happy path",
   "id": "f04300bfc08e0354"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```shell\n",
    "# 启动之前需要在命令行执行\n",
    " pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "# 做什么？\n",
    "让LLM做翻译"
   ],
   "id": "85815e3dc4dcc2e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 使用LLM",
   "id": "bbb710434633ed07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:51:54.152333Z",
     "start_time": "2024-06-19T15:51:53.646379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-********\"  去掉注释\n",
    "# os.environ[\"OPENAI_API_BASE\"] = \"https://ai-yyds.com/v1\"\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4\")"
   ],
   "id": "68830e9fc37b9a15",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "到此，创建了ChatOpenAI的model，他继承了langchain的`RunnableSerializable`接口，`RunnableSerializable`在langchain的表达式中很重要，他重写了 `__or__`方法，使得可以用 | 来实现管道符,并且规定了一系列标准方法，langchain的核心组件都实现了这个方法。之后细讲。在这里，就可以直接通过invoke方法来调用了。",
   "id": "f913afeb2b962a53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:51:59.249653Z",
     "start_time": "2024-06-19T15:51:54.153430Z"
    }
   },
   "cell_type": "code",
   "source": "model.invoke(\"hi,你是谁\")",
   "id": "2b1342e16e5b03b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好，我是OpenAI的人工智能助手。我可以帮助回答问题，提供信息，或者进行各种对话。你有什么需要帮助的吗？', response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 13, 'total_tokens': 68}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8bd37862-d050-4058-aa74-e168c96e44d1-0', usage_metadata={'input_tokens': 13, 'output_tokens': 55, 'total_tokens': 68})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "如上所属，这种方式和之前直接调用openAI的接口是一样的，但是需要注意的是，返回值langchain做了包装，并且将入参也包装了， 将`str`变为`PromptValue`\n",
    "在和LLM交互的时候需要角色扮演，这里也支持，用下面的方式"
   ],
   "id": "c678bc63737fcfe6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:52:06.730793Z",
     "start_time": "2024-06-19T15:51:59.250643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "messages = [\n",
    "    SystemMessage(content=\"将下面的英文歌词翻译为中文\"),\n",
    "    HumanMessage(content=\"\"\"\n",
    "Look how they shine for you\n",
    "And everything you do\n",
    "Yeah' they were all Yellow\n",
    "I came along\n",
    "I wrote a song for you\n",
    "And all the things you do\n",
    "It was called Yellow\n",
    "So then I took my turn\n",
    "Oh what a thing to have done\n",
    "\"\"\")]\n",
    "# 传递给LLM\n",
    "res = model.invoke(messages)\n",
    "print(res)"
   ],
   "id": "dabd1ac3928cac5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='看它们如何为你闪耀\\n和你做的一切\\n是的，它们都是黄色的\\n我来了\\n我为你写了一首歌\\n和你做的所有事情\\n那首歌被叫做黄色\\n然后我轮到我了\\n哦，这是多么伟大的事情\\n' response_metadata={'token_usage': {'completion_tokens': 96, 'prompt_tokens': 87, 'total_tokens': 183}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-74b64201-7eda-41ee-8f3a-42a105be083c-0' usage_metadata={'input_tokens': 87, 'output_tokens': 96, 'total_tokens': 183}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 返回值解析\n",
    "\n",
    "现在需要从返回的`AIMessage`中拿到返回值，langchain已经帮我们封装好了`StrOutputParser`，可以直接读取到`content`属性"
   ],
   "id": "170e9ddb9138c950"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:52:06.742632Z",
     "start_time": "2024-06-19T15:52:06.733742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "parser.invoke(res)"
   ],
   "id": "694bba603eb15c2b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'看它们如何为你闪耀\\n和你做的一切\\n是的，它们都是黄色的\\n我来了\\n我为你写了一首歌\\n和你做的所有事情\\n那首歌被叫做黄色\\n然后我轮到我了\\n哦，这是多么伟大的事情\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "如你看到的一样，`StrOutputParser`也继承了`RunnableSerializable`类，所以也可以通过invoke来调用。\n",
    "到这里已经拿到了结果了。前面说了，继承于`RunnableSerializable`的类，都可以通过 `|` 符号来实现管道流。 上面的代码就可以改写为"
   ],
   "id": "d0e0e599b968d21a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:52:13.175240Z",
     "start_time": "2024-06-19T15:52:06.743637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = model | parser\n",
    "chain.invoke(messages)"
   ],
   "id": "8b37d9290a5256f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'看他们如何为你闪耀\\n以及你做的一切\\n是的，他们都是黄色的\\n我出现了\\n我为你写了一首歌\\n和你做的所有事情\\n这首歌叫黄色\\n那么我轮到我了\\n哦，做这件事真是太棒了'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**体会到chain的意义了吗！！**\n",
    "不需要像之前一样，先组装prompt，在去调用llm的接口，自己做解析。langchain已经做好这样的功能了，我们做的事情是将组件拼接在一块，形成一个chain。快捷开发\n",
    "\n",
    "但是现在还有个问题，prompt不够灵活，如果想翻译为韩文的话，要怎么做"
   ],
   "id": "6329dff8ad0fd579"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Prompt Templates\n",
    "\n",
    "PromptTemplates 是 LangChain 中的一个重要概念，他可以做格式化模板，将消息分类（系统message，人类的message，ai的message）\n",
    "对于上面，需要有两个模板变量\n",
    "- language： 翻译为什么语言\n",
    "- input：要翻译的文本\n",
    "\n",
    "下面用`ChatPromptTemplate`来做，他是`BasePromptTemplate`的子类，用于创建灵活的聊天模型模板prompt"
   ],
   "id": "926383f19de80416"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:52:13.178683Z",
     "start_time": "2024-06-19T15:52:13.176343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 定义system message\n",
    "system_template = \"将下面的文本翻译为{language}:\"\n",
    "# 创建 ChatPromptTemplate，分为user和system\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{input}\")]\n",
    ")   "
   ],
   "id": "cda983a976bd0b4a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`ChatPromptTemplate`继承了`RunnableSerializable`，可以直接调用`invoke`方法",
   "id": "99339df5588013f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:52:13.183821Z",
     "start_time": "2024-06-19T15:52:13.179353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_format_res = prompt_template.invoke({\"language\":\"韩文\",\"input\":\"\"\"\n",
    "Look how they shine for you\n",
    "And everything you do\n",
    "Yeah' they were all Yellow\n",
    "I came along\n",
    "I wrote a song for you\n",
    "And all the things you do\n",
    "It was called Yellow\n",
    "So then I took my turn\n",
    "Oh what a thing to have done\n",
    "\"\"\"})\n",
    "print(prompt_format_res)\n",
    "type(prompt_format_res)"
   ],
   "id": "b80e95a8bd658e42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='将下面的文本翻译为韩文:'), HumanMessage(content=\"\\nLook how they shine for you\\nAnd everything you do\\nYeah' they were all Yellow\\nI came along\\nI wrote a song for you\\nAnd all the things you do\\nIt was called Yellow\\nSo then I took my turn\\nOh what a thing to have done\\n\")]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "langchain_core.prompt_values.ChatPromptValue"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "如上所示，`prompt_template 调用 invoke`之后，得到的类型是`ChatPromptValue`,调用`messages`拿到messages，如下所示，这就和👆🏻是一样的。不过，灵活性大大提升",
   "id": "182fb5ed2d2e4c6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:52:13.186405Z",
     "start_time": "2024-06-19T15:52:13.184475Z"
    }
   },
   "cell_type": "code",
   "source": "prompt_format_res.messages",
   "id": "9ce91ea78691eeef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='将下面的文本翻译为韩文:'),\n",
       " HumanMessage(content=\"\\nLook how they shine for you\\nAnd everything you do\\nYeah' they were all Yellow\\nI came along\\nI wrote a song for you\\nAnd all the things you do\\nIt was called Yellow\\nSo then I took my turn\\nOh what a thing to have done\\n\")]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "它也实现了`RunnableSerializable`接口，所以可以用`|`拼接",
   "id": "4b00a0d568ff806"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:52:22.636317Z",
     "start_time": "2024-06-19T15:52:13.186940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = prompt_template | model | parser\n",
    "invoke_res = llm.invoke({\"language\":\"韩文\",\"input\":\"\"\"\n",
    "Look how they shine for you\n",
    "And everything you do\n",
    "Yeah' they were all Yellow\n",
    "I came along\n",
    "I wrote a song for you\n",
    "And all the things you do\n",
    "It was called Yellow\n",
    "So then I took my turn\n",
    "Oh what a thing to have done\n",
    "\"\"\"})\n",
    "print(invoke_res)"
   ],
   "id": "eff86f1a4ab59853",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And it was all Yellow\n",
      "Your\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "韩文看不懂，把韩文翻译为中文",
   "id": "946984716f6153b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:52:24.647127Z",
     "start_time": "2024-06-19T15:52:22.639152Z"
    }
   },
   "cell_type": "code",
   "source": "llm.invoke({\"language\":\"中文\",\"input\":invoke_res})",
   "id": "f321746aeeeb3e70",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'而所有的都是黄色的\\n你的'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "！！看到了么，一个完整的chain出现了，prompt -> llm -> result parse。并且用`|` 连接了起来，实现了管道流。（是因为他们都继承了`RunnableSerializable`类），和原始的openai的chat api相比，代码简单了很多，灵活性也很高。\n",
    "\n",
    "**到这里happy path 结束了**\n",
    "\n",
    "上面支持开发，langchain是一站式的llm开发框架，下面介绍langsmith和langserver"
   ],
   "id": "914ba8c7d8886ba6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# lang server\n",
    "\n",
    "就是将chain通过REST api的形式暴露出来，并且提供了swagger文档和playground来调试chain"
   ],
   "id": "ccf6c60dae8e1709"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:52:24.649507Z",
     "start_time": "2024-06-19T15:52:24.647981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ! pip install \"langserve[all]\"\n",
    "# 我已经在requirements.txt中已经安装过了，这里不需要了"
   ],
   "id": "a1b1183955736351",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "他是基于FAST API的，这里需要创建fast的app，绑定路由，启动。",
   "id": "b7e21d291f347755"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:52:24.964741Z",
     "start_time": "2024-06-19T15:52:24.650202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from langserve import add_routes\n",
    "\n",
    "# 创建FastAPi app\n",
    "app = FastAPI(\n",
    "  title=\"LangChain Server\",\n",
    "  version=\"1.0\",\n",
    "  description=\"A simple API server using LangChain's Runnable interfaces\",\n",
    ")\n",
    "\n",
    "# 创建chain\n",
    "def translate_chain():\n",
    "    # 将上面的代码包装在这里\n",
    "    import os\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    # os.environ[\"OPENAI_API_KEY\"] = \"sk-********\"\n",
    "    # os.environ[\"OPENAI_API_BASE\"] = \"https://ai-yyds.com/v1\"\n",
    "    \n",
    "    model = ChatOpenAI(model=\"gpt-4\")\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "    parser = StrOutputParser()\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "    # 定义system message\n",
    "    system_template = \"将下面的文本翻译为{language}:\"\n",
    "    # 创建 ChatPromptTemplate，分为user和system\n",
    "    prompt_template = ChatPromptTemplate.from_messages(\n",
    "        [(\"system\", system_template), (\"user\", \"{input}\")]\n",
    "    ) \n",
    "    return prompt_template | model | parser\n",
    "\n",
    "# 绑定chain\n",
    "add_routes(\n",
    "    app,\n",
    "    translate_chain(),\n",
    "    path=\"/chain\",\n",
    ")\n",
    "print(\"这里的代码需要新建一个py文件来跑，因为jupyter-book里面不能再启动event loop了\")\n",
    "# if __name__ == '__main__':\n",
    "#     # 启动\n",
    "#     uvicorn.run(app, host=\"localhost\", port=8000)"
   ],
   "id": "ac3255e570257601",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这里的代码需要新建一个py文件来跑，因为jupyter-book里面不能再启动event loop了\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**上面的代码需要新建一个py文件来跑，因为jupyter-book里面不能再启动event loop了**，具体可以看 src/section_1_lang_server.py\n",
    "\n",
    "他提供了功能如下\n",
    "\n",
    "## 将chain暴露为了REST API并且提供了swagger文档\n",
    "服务地址： http://localhost:8000 \n",
    "接口文档地址：http://localhost:8000/docs\n",
    "\n",
    "![](../resource/img_1.png)\n",
    "\n",
    "## 提供了playground来调试\n",
    "地址：http://localhost:8000/chain/playground/\n",
    "\n",
    "![](../resource/img_2.png)\n",
    "运行调试：\n",
    "\n",
    "\n",
    "\n",
    "![](../resource/img_3.png)\n"
   ],
   "id": "2e5e2cf33828e649"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# lang smith\n",
    "\n",
    "官网：\n",
    "https://docs.smith.langchain.com/\n",
    "lang Smith来监控上面的chain。在使用之前需要安装，配置api_key（api_key 在lang smith官网中配置就行）"
   ],
   "id": "50c9ba7bd9442ceb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```shell\n",
    "export LANGCHAIN_TRACING_V2=true\n",
    "export LANGCHAIN_API_KEY=<your-api-key>\n",
    "```"
   ],
   "id": "28654da3c9b1db40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "配置之后，再次运行上面的结果，可以很清晰的看到chain的运行过程，可以如下<br>\n",
    "![](../resource/img_4.png)"
   ],
   "id": "1edea1d3d552f06f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "到此，happy path已经完成了，回顾一下，在这个例子中，了解到\n",
    "\n",
    "- LangChain Expression Language（LangChain的表达式）\n",
    "- Prompt Template\n",
    "- Chat Models\n",
    "- Output Parsers\n",
    "- Lang Server\n",
    "- Lang Smith\n",
    "\n",
    "在之后的学习中，我会按照上面的顺序来学习分享，此外还会增加一些例子。💪🏻"
   ],
   "id": "b993119b73f2cfea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
